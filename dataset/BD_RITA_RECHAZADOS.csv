doc;authors;institution;title;abstract;keywords;language;status_article;pages;year;date
6141;Rafael Rech   Barcelos;Feevale;Consultoria a Franquias utilizando Tecnologia Móvel;This article presents a Software used as a tool to help on Consulting tasks using Mobile Technology, bringing more satisfactory results to the client. Besides this Software, we present a brief concept on Consulting, Inside and Outside Consultant, and a small Introduction on Mobile Technology and the Velocity Generations of this Technology.;;pt_BR;Declined;0;2008;2008-10-05 23:08:38
6364;Gustavo   Neuberger;UFRGS;Proteção de Circuitos Digitais contra Falhas de Tempo de Hold Devido à Variabilidade do Processo de Fabricação;With the shrinking of CMOS technology, the circuits are more and more subject to variability in the fabrication process. In this work we present an on-chip measurement technique to characterize hold time violations of flip-flops in short logic paths, which are generated by clock-edge uncertainties in synchronous designs. Using a precise programmable clock-to-data skew generation circuit, a measurement resolution of ~1ps is achieved to emulate race conditions. Statistical variations of hold time violations are measured in a 130nm and 90nm low-power CMOS technology for various register-to-register configurations. These violations are a critical issue in large designs with thousands of short paths, as if only one of these fails, the whole circuit will not work at any frequency. The probability of hold time violations considering our measured data and typical clock skews is calculated, showing that the problem of hold time violations is increasing with technologic advances. Finally, an algorithm to protect digital circuits against hold time violations in short paths is presented.;;pt_BR;Declined;0;2008;2008-10-16 16:33:44
6809;Maria Madalena   Dias;Universidade Estadual de Maringá;Using XML to Represent Metadata;In this paper we present a model of metadata for use in registration and control of information about the data that integrate a data warehouse (DW). To support the proposed model, was developed a metadata manager, implemented in Java as a software component that can be used as part of a system for knowledge discovery in database. The model was defined in the XML (Extensible Markup Language) to facilitate interoperability. A case study was conducted to demonstrate the use of the manager in the creation of metadata in XML and the handling of the information contained therein, according to the stages of knowledge discovery in database.;;pt_BR;Declined;0;2008;2008-11-14 18:27:29
7008;Luana   Noguerol;Centro Universitário Feevale;Sistema de Apoio ao Diagnóstico para a Detecção de Parasitas Intestinais;The article seeks to show new ways of applying computer graphics in the health sector, through the automation of the diagnosis of parasitological fecal exams. Thus, it presents the results of software developed by academics at Centro Universitário Feevale, obtained through tests with 204 images of fecal samples.;;pt_BR;Declined;0;2008;2008-12-01 13:37:49
7012;Rafael Rech   Barcelos;Feevale;Software de Consultoria a Franquias utilizando Tecnologia Móvel;This article presents a Software used as a tool to help on Consulting tasks using Mobile Technology, bringing more satisfactory results to the client. In this article, will be going to comment on this Software, besides commenting on the tools that were used and short comments on each one of them.;;pt_BR;Declined;0;2008;2008-12-01 20:17:27
7017;Flávio Henrique   Teles Vieira;1Escola de Engenharia Elétrica e de Computação, Universidade Federal de Goiás, GO.;Modelagem de Tráfego de Redes Utilizando Cascata Multifractal Generalizada;In this paper we propose a multifractal traffic model that is based on a multiplicative cascade presenting specific multiplier distributions in each cascade stage. In the proposed model, the multipliers are obtained through the estimate of their probability densities found in real network traffic by using Kernel and Acceptance/Rejection methods. Statistical analysis and queueing behavior study were carried out for the model validation. Furthermore, we verify the model performance in capturing the traffic trace characteristics in comparison to other multifractal models.;;pt_BR;Declined;0;2009;2009-06-16 15:35:29
7164;Francisco A. S.   Souza;CEFETES;A graphic interface generator as solution for the need for speed in the development of Information Systems;The design and development of graphic user interfaces (GUI) on information systems and commercial systems always was one of most tiring stages of the software development. This paper presents an idea to elaborate an automatization tool to speed the design and development of GUI, using the Java Standard Edition Platform, with the GUI library Java Swing. Future, this tool will be carried to the web platform, for use in the Internet and in Intranets and Extranets, set with web libraries (Java Server Pages – JSP, JSP Standard Tag Library – JSTL, Hypertext Markup Language – HTML, etc.) and others GUI technologies (e. g. JavaFX). ;;pt_BR;Declined;0;2008;2008-12-16 13:08:07
7222;Rafael de Amorim   Silva;UFPE;Uma Taxonomia para Sistemas de Localização em Ambientes;Recently, several localization systems have been investigated and developed by academic institutions and manufacturers with the aim of estimating the physical location of objects and people in external and internal environments. Although such systems are essential for several application domains, few works present a study and classification of the elements and concepts that involve this area of ​​research. In other words, they do not describe the elements necessary to understand these location systems, both for internal and external environments. Therefore, this article proposes a taxonomy for localization systems that offers a more comprehensive view of these concepts and elements. Therefore, this article proposes a more complete taxonomy than those suggested in other works in the literature. The taxonomy is divided into three parts: System characteristics, signaling modes and localization techniques. As a contribution, this work aims to serve as an aid to researchers and developers in localization systems.;;pt_BR;Declined;0;2008;2008-12-31 21:00:40
7291;Luciano Tadeu Esteves   Pansanato;UTFPR;Um Modelo de Navegação Exploratória para a infra-estrutura da Web Semântica;This article presents an exploratory navigation model for the Semantic Web infrastructure, called Navigation and Exploration Model (NAVE). The objective of the NAVE model is to facilitate the design and development of systems that allow the user to perform exploratory navigation while searching for information. The NAVE model is described through a graphic representation of the process of navigation and exploration of the information space, the definition of its elements and design recommendations. A system is also presented, called Exploratory Navigation System (ENS), which was developed to evaluate the feasibility of using the NAVE model in real applications. The ENS system was evaluated using both a qualitative and quantitative approach, which served to refine the research questions and explore the NAVE model.;;pt_BR;Declined;0;2009;2009-01-19 11:17:40
7388;Adriana Soares   Pereira;UNIFRA;Realidade Virtual Aplicada na Disciplina de Linguagens Formais;This article presents educational software for distance or face-to-face education, for the Formal Languages ​​subject. With a simple interface, easy to understand and use, it will present exercises where the student will visualize the automatons in 3D and must develop the corresponding correct Regular Expression and in a second moment they will be able to develop the minimization of the automaton interacting directly with the 3D object. To design the automatons, the software uses 3D tools, such as Blender and VRML and to publish a page on the Internet with proposed exercises, using the PHP programming language. A multiple-choice exercise page in Java Script is also developed. This software aims to take the discipline in question from the classroom to computer labs and will make it more interesting for the student, making learning easier.;;pt_BR;Declined;0;2009;2009-01-28 11:10:09
7412;Lucas Francisco da Matta   Vegi;Faculdade de Minas - FAMINAS;Desenvolvimento de um software para controlar reservas de laboratório utilizando computação nas nuvens;This article presents the development process of the forLAB software carried out at Faculdade de Minas, Muriaé campus. forLAB is an application based on the concept of cloud computing and aims to automate laboratory reservation control, making this process more practical, portable and organized. It was designed using software engineering techniques and implemented using the PHP programming language, the MySQL DBMS and the Apache web server, all free software technologies.;;pt_BR;Declined;0;2009;2009-01-30 13:38:42
7445;Paulo Domingos   Rodrigues;Universidade de Sorocaba;Gestão de Desenvolvimento de Software - Técnicas de custo e tempo de desenvolvimento;Society's growing dependence on IT has shown several problems related to the software development process. The estimates made are very different from reality when it comes to time and cost. I present the result of calculating the time and cost of developing the Admission Request Management software, with the help of the APFPlus tool, showing how the Point by Function metric can help the manager and the software developer to make decisions.;;pt_BR;Declined;0;2009;2009-02-03 16:39:18
7460;Marcia maria   Castro Cruz;Universidade Federal do Rio Grande do Norte;Morfologia para imagens Binárias Intervalares;This work presents a binary interval model, where the interval representation means the presence of uncertainty between exact values ​​of the binary set {0,1}. For this, the set of pixels W={[0,0][0,1], [1,1]} will be introduced, where [0,1] represents the uncertainty information. The set W and its algebraic properties will be studied here, and on this set the elementary morphological operations of dilation and erosion will be defined. It is also shown that both W and the class of morphological operations on W form a complete lattice. Furthermore, it will be demonstrated that the algebraic structure of W, unlike the binary case, does not constitute a Boolean algebra, but a weaker algebraic structure called pseudo Boolean algebra. In other words, introducing an uncertainty value into the universe of binary pixels affects (weakens) the algebraic structure of the binary pixel algebra {0,1}. Thus, the concept of binary images is generalized, allowing the mapping of a coordinate into the uncertainty value represented by the interval [0,1], that is, the model will be able to express the uncertainties in the respective coordinates. Or, the value coordinate [0,0] represents the color black, the value coordinate [1,1] represents the color white, and the value [0,1] represents uncertainty.;;pt_BR;Declined;0;2009;2009-02-05 15:44:10
7524;Gustavo   Pessin;USP-São Carlos;Evolução de Estratégias e Controle Inteligente em Sistemas Multi-Robóticos Robustos;The objective of this article is to detail the model, implementation and efficiency assessment of Artificial Intelligence (AI) techniques applied in a multi-agent system that operates in a realistic simulation virtual environment, Robombeiros. In this system, a team of autonomous agents works cooperatively to successfully identify and combat fires in forest areas, without human intervention. The environment supports a series of fundamental characteristics for realistic operation simulation, such as irregular terrain, natural processes and physical restrictions in the creation and use of mobile robots. The multi-agent operation essentially depends on two steps: planning and action. In planning, we use Genetic Algorithms (GA) to evolve positioning strategies for the fire robots. For the action, physically simulated combat robots were created, with the sensory information from each robot (e.g. GPS, compass, sonar) being used at the input of an Artificial Neural Network (ANN). This ANN that controls the vehicle's actuators allows navigation with obstacle avoidance. The simulation results demonstrate that the ANN satisfactorily controls the mobile robots, that the use of the GA configures the fire fighting strategy satisfactorily and that the proposed multi-agent system can play a very important role in the planning and execution of real forest firefighting operations. The objective of this article is to detail the model, implementation and efficiency assessment of Artificial Intelligence (AI) techniques applied in a multi-agent system that operates in a realistic simulation virtual environment, Robombeiros. In this system, a team of autonomous agents works cooperatively to successfully identify and combat fires in forest areas, without human intervention. The environment supports a series of fundamental characteristics for realistic operation simulation, such as irregular terrain, natural processes and physical restrictions in the creation and use of mobile robots. The multi-agent operation essentially depends on two steps: planning and action. In planning, we use Genetic Algorithms (GA) to evolve positioning strategies for the fire robots. For the action, physically simulated combat robots were created, with the sensory information from each robot (e.g. GPS, compass, sonar) being used at the input of an Artificial Neural Network (ANN). This ANN that controls the vehicle's actuators allows navigation with obstacle avoidance. The simulation results demonstrate that the ANN satisfactorily controls the mobile robots, that the use of the GA configures the fire fighting strategy satisfactorily and that the proposed multi-agent system can play a very important role in the planning and execution of real forest firefighting operations.;;pt_BR;Declined;0;2009;2009-02-10 16:26:21
7843;Lucia Norie   Enami;Universidade Estadual de Maringá;Um Modelo de Gerenciamento de Projetos para um Ambiente de Desenvolvimento Distribuído de Software;This article presents a project management model, called DiSEN-PMM (Diztribuited Software Engineering Environment – ​​Project Management Model) for a distributed software development environment (ADDS), more specifically for the DiSEN environment. The objective of the DiSEN-PMM model is to provide people interested in software project management (PM) with information that assists management control in an ADDS. DiSEN-PMM was based on the PMBOK (Project Management Body of Knowledge) and CMMI (Capability Maturity Model Integration) Staged Level 2 models and contains the following elements: stakeholder management, knowledge management, risk management, requirements and a GP support tool. DiSEN-PMM elements address two aspects in distributed software development (DDS): human and computational resources. The human aspects are addressed by the orientation/team building meeting and intellectual property and the aspects related to computational resources are presented as tools that support the PM within an ADDS.;;pt_BR;Declined;0;2009;2009-03-04 17:16:46
7911;Klaus   Wehmuth;;Shadow Mapping em ambientes de realidade aumentada;In this work, the dynamic generation of shadows in an augmented reality environment will be discussed. Initially, some basic ideas will be presented regarding the importance of shadows for the realism of the scene. Next, the algorithms used for shadow projection and augmented reality environments will be discussed, considering applications that can benefit from the addition of virtual shadows in real time. Finally, the main objective of this work will be realized, which is to adapt one of the algorithms discussed previously for use in an augmented reality environment based on the ARToolKit library. The result to be obtained is the projection of shadows in time real, originating from virtual objects added to the scene. These shadows will be projected from a virtual light source onto real objects, as well as onto other virtual objects present in the scene.;;pt_BR;Declined;0;2009;2009-03-10 19:42:06
8095;Antonio Ricardo   Cavalcanti;;Voice Traffic Stochastic Modeling through Poly-Exponential Distributions for Planning and Scenario Evaluation;In this paper we present a model for performance evaluation of voice traffic on the Voice over Internet Protocol (VoIP) networks. We describe the steps for data collection as well as requirements for evaluation and validation of the proposed model. The presented model is based on the Generalized Stochastic Petri Nets (GSPN) and aims supporting infrastructure planning and complex scenario evaluation. In order to illustrate the proposed model a case study is presented.;;pt_BR;Declined;0;2009;2009-03-24 20:01:10
8118;Daniel Gouveia   Costa;Universidade Estadual de Feira de Santana;MobDAP: Localização de Usuários em Ambientes Móveis Utilizando Bases de Dados LDAP;Wireless communication environments are becoming increasingly common. This new scenario has enabled the emergence of demand for mobility on the Internet. In order to support user localization in mobile environments, a new communication service is proposed, supported by LDAP servers. The aim is to create a generic solution that can be used in different mobility architectures in IP networks.;;pt_BR;Declined;0;2009;2009-03-27 9:56:36
8325;Jorge   Kinoshita;EPUSP;O Minix é mais robusto por ser um sistema operacional microkernel?;In 2006, Professor Tanenbaum launched Minix3 with a textbook [15] and articles [14, 9, 8] that claimed that drivers running as user-mode processes made Minix, a microkernel operating system, more robust than monolithic operating systems. We tested Minix3 in an operating systems course at the University of São Paulo and unfortunately, we refuted some of Professor Tanenbaum's statements, but we highlighted Minix3 as a powerful teaching tool in operating systems courses.;;pt_BR;Declined;0;2009;2009-04-15 16:24:38
8395;Cinthia Obladen de Almendra   Freitas;PUCPR;Reconstrução de Documentos Mutilados em Formato “Spaghetti” Utilizando Modelos de Cores;This article addresses one of the problems in the area of ​​forensic sciences, which is the reconstruction of mutilated documents in “spaghetti” format. The proposed method considers the extraction of features from the edges of document fragments, using two color models to represent the information, namely, RGB and HSV. Thus, the Nearest-Neighbor algorithm, using a distance matrix, determines the probable pairs of fragments. One can, therefore, reduce the complexity of the problem, since a small set of features is extracted from the images. Applying the RGB model, a hit rate of 97.68% was achieved and with the HSV model the rate achieved was equal to 98.53%, with the database containing 200 documents from different origins. The results reported in this article show that the use of RGB and HSV color models as primitive extractors can be applied to the problem of reconstructing regularly mutilated documents, being of interest to documentoscopy experts.;;pt_BR;Declined;0;2009;2009-04-21 12:29:53
8483;Vivian Santos   Silva;Programa de Pós-Graduação em Informática - Universidade Federal do Rio de Janeiro;Uma Interface para Busca Exploratória: Estudo de Caso no Setor Elétrico;The electricity sector is an area whose operation involves a large volume of information, generated and exchanged by organizations that perform different functions in the system, and which, consequently, have different views of the business and varied information needs. Finding information of interest among this vast collection is a very complex task. There is, therefore, a need for interfaces that facilitate this task. This article presents a proposed search interface that aims to allow each type of user to more easily identify information of interest. The prototype presented explores different forms of access: it allows search or navigation, in business documents, classified into categories according to a hierarchy of facets, and in technical documents, associated with concepts arranged in a hyperbolic tree. Thus, both professionals and less specialized users can explore documents from their perspective, in a simple and interactive way.;;pt_BR;Declined;0;2009;2009-04-28 15:48:50
8543;Inaldo Capistrano   Costa;Universidade Federal do Maranhão - UFMA;Uma Abordagem Para Apoiar a Modelagem de Sistemas Multiagentes;Methodologies for developing Multi-Agent Systems (SMAs) have been attracting the interest of several research groups. Despite this interest and ongoing research, some aspects can be improved. The paper presents an approach to support the consistency of SMA modeling under the Goal Orientation paradigm. To this end, techniques based on scenarios and objectives are proposed together with heuristics for consistency of the artifacts produced throughout the modeling, from the requirements phase to the detailed design. The approach was applied to Multi-Agent Systems, where preliminary results indicate the achievement of the expected benefits.;;pt_BR;Declined;0;2009;2009-05-06 7:45:25
8570;José Alexandre   de França;Universidade Estadual de Londrina;Um novo algoritmo de calibração de um conjunto binocular com um gabarito 1D que realiza deslocamentos irrestritos;In computer vision, camera calibration is a necessary process when you want to retrieve information such as angles and distances. The present work deals with the problem of calibrating cameras with single-dimensional templates. Currently, this problem can only be solved if restrictions are imposed on the movement of the template or if some camera parameters are already known in advance. However, it is demonstrated that a different approach can be applied if, instead of a single camera, a binocular array is considered. In this case, calibration is possible with a 1D template that performs an unknown and unrestricted displacement, even without any prior information about the cameras. This method is based on the estimation of a transformation that, after estimating the system's fundamental matrix, allows updating a projective calibration to a Euclidean calibration. Experiments on real and synthetic images validate the new method and show that its accuracy is comparable to that of other classic calibration methods, already well known in the literature.;;pt_BR;Declined;0;2009;2009-05-09 23:17:52
8818;Marcus Sousa   Lemos;;A IMPORTÂNCIA DOS SISTEMAS DE INFORMAÇÃO NA GESTÃO DE EMPRESAS;The objective of this article is to present a theoretical view on the use of information systems that enables a better understanding of their role within organizations. It highlights some concepts such as e-Commerce - electronic commerce systems, CRM - customer relationship management, SCM - supply chain management, ERP - company resource planning and e-Business, which are powerful tools to assist an organization to be quick and efficient in managing your information and applying Intelligence in business management.;;pt_BR;Declined;0;2009;2009-06-02 13:48:41
9042;Mauricio Rodrigo   dos Santos;Centro Universitário Feevale;Implementação de Honeynets virtuais com Honeyd;Honeynets are research systems that consist of networks specifically designed to be compromised. These networks are made up of several hosts called honeypots, which are security resources prepared for the purpose of being probed, attacked or compromised and to record these activities. This work aims to present the Honeyd virtualization tool and demonstrate some possible configurations in the construction of virtual honeypots and honeynets.;;pt_BR;Declined;0;2009;2009-06-22 19:58:28
9374;Wanderson Santiago dos   Reis;Instituto Federal Minas Gerais;Virtualização de serviços baseado em contêineres: alta disponibilidade de serviços em redes de pequeno porte;In this work we present and implement a proposed low-cost solution for hardware, system and communication fault tolerance using server virtualization based on GNU/Linux containers and the Heartbeat solution for high availability clusters. This proposal was made possible by the use and combination of some FLOSS (Free/Libre and Open Source Software) systems that provide a highly stable environment for essential applications. The implementation of the proposal demonstrated adequate response time in simulated failure situations that activated failover. Other advantages of this structure were perceived as optimizing the use of hardware, even using redundant components, adding benefits to the use of free software such as low acquisition and implementation costs and the use of innovative technologies in creating high availability solutions.;;pt_BR;Declined;0;2009;2009-07-08 23:46:50
9428;Maria Madalena   Dias;Universidade Estadual de Maringá;Using the Zachman Framework to Design a Data Warehouse Architecture;This article presents a discussion on the origin of DW architecture based on the information systems architecture proposed by Zachman. This article also includes: an example of a DW architecture, a description of the construction of a DW and the results of a case study carried out using the presented DW architecture.;;pt_BR;Declined;0;2009;2009-07-13 13:05:29
9485;Rúbia Eliza de Oliveira Schultz   Ascari;Faculdade Mater Dei;TECNOLOGIA APLICADA NO ENSINO DE E-COMMERCE;Abstract: Technology is currently one of the biggest responsible for the transformations and discoveries that have been taking place in the world. In the context of education, it can be said that it introduces a paradigm and interferes with the production of knowledge. Therefore, the educator needs to keep up with technological developments, so that the teaching-learning process occurs effectively. Considering that the capacity for learning and assimilation can be quite high and stimulated through practical activities, it was seen as opportune to use resources from the Information Technology area, to increase the understanding of the concepts studied in an E-Commerce discipline. To this end, this document reports on carrying out a case study focused on the creation of Virtual Stores in a laboratory – one of the pillars of e-commerce – using the functionalities provided by a free tool, called osCommerce.;;pt_BR;Declined;0;2009;2009-07-17 11:00:39
9495;Lucio Geronimo   Valentin;Universidade Tecnológica Federal do Paraná;Arquitetura de Software Sob Diferentes Visões: Uma Aplicação Prática;This article presents a practical application of how a software architecture can be documented using different views. For this, a reference architecture was used, with its functional and non-functional requirements represented in the views. The evaluation of the reference architecture, presented in this article, was carried out through the construction of a knowledge discovery system in a database that uses a software architecture and a framework to define the components necessary to implement this type of system.;;pt_BR;Declined;0;2009;2009-07-17 16:41:46
9503;Eustáquio São José de   Faria;PUC Minas e Universidade Federal de Uberlândia;Aprendizado Extremo de Programação (Extreme Learning of Programming) – Uma Metodologia Baseada na Programação Extrema Para Ensino de Programação;Information technology has evolved very quickly in recent decades, especially the science of architecture and hardware development. This has demanded more robust and reliable software. On the other hand, it has become increasingly difficult to find software development professionals skilled in computer programming techniques. What appears to be increasingly noticeable in computing and similar courses is the high failure and dropout rate in programming subjects. The reasons are diverse. From this work, a methodology for teaching programming was developed and named Extreme Learning of Programming (eXtreme Learning of Programming – XLP). XLP is based on an agile software development methodology known as eXtreme Programming (XP). To justify the use of the methodology, it is argued that the use of programming in pairs (or programming in pairs) contributes to reducing student dropout rates in computing and related courses through motivation, a sense of responsibility and the exchange of knowledge. provided by the socio-cognitive conflict arising from pairings. Experiments were carried out in an Information Systems course at PUC Minas in Arcos, MG. Results obtained can be seen at the end of the article.;;pt_BR;Declined;0;2009;2009-07-20 12:44:31
9537;Diogo Fernando   Trevisan;Universidade Federal da Grande Dourados;Transmissão de Parâmetros Agrometeorológicos via Satélite;Agricultural production is constantly affected by fungi, whose development depends on climatic conditions. To reduce the application of fungicides, there are mathematical prediction models that provide an infection rate based on climatic parameters. Warning systems normally consist of meteorological stations spread across the field, sending climate data, via a cell phone network, to a computer that runs the model. Where there is no cellular network coverage, the system is compromised. The objective of this work was to develop a system for satellite transmission. To this end, an application responsible for receiving, viewing and storing data was developed, as well as firmware for a microcontrolled module equipped with a temperature sensor, which was used to simulate a weather station. In tests, 63 messages containing weather data were sent, one every 2 minutes. All messages were received by the application without error, and it can be concluded that modules, primarily used in vehicle tracking applications, can be used to transmit weather data.;;pt_BR;Declined;0;2009;2009-07-22 20:53:01
9550;Nize Campos   Pellanda;Universidadede Santa Cruz do Sul;Reflexões sobre cognição/subjetivação no ciberespaço na perspectiva da complexidade;The article deals with theoretical reflections as a contribution to broadening the approach to the topic of the cognition process in the digital space and its relationship with the assumptions of the complexity paradigm. The focus of the article is placed on Spinoza's idea of ​​the Unique Substance with the justification that this, being an integrative and therefore complex thought, can help to break with the Cartesian legacy responsible for strong fragmentation. From these seminal ideas, the text unfolds into considerations about the emergence of cybernetics, with an emphasis on II Cybernetics, mainly with regard to Von Foerster's contribution to the development of the complex biological theories of H. Atlan, H. Maturana and F. Varela. The concepts involved in these theories, such as complexification through noise and autopoiesis, are thought of in the light of Spinoza's ideas and, considering the author's empirical experience, are illustrated by brief examples. Keywords: single substance- digital space- complexity- autopoiesis – complexification by noise Abstract:             The article deals with theoretical reflections as a contribution to wide the approach to the theme of the cognition process in a digital space and its relationship with the assumptions of the complexity paradigm. The article focus is placed on the Idea of ​​the Unique Substance from Spinoza with the argument that this philosopher had an integrative thought and, therefore, complex, can help in breaking with the strong Cartesian tradition of fragmentation. From these seminal ideas, the text makes considerations on the development of the complex biological theories by H. Atlan. H. Maturana and F. Varela. The concepts involved in these theories such as complexity from noise and autopoiesis are thought in the light of de ideas of Spinoza as well as is considered the empirical experience of the author, are illustrated briefly. Key-words: unique substance- digital space – complexity-autopoiesis – complexification from noisy;;pt_BR;Declined;0;2009;2009-07-25 19:52:35
9692;Rodrigo Pereira dos   Santos;COPPE/UFRJ;An Approach Based on Maintainability Criteria for Building Aspect-Oriented Software Design Model;Software modeling corresponds to an activity that is important for maintenance as it can facilitate the understanding of soft­ware and its activities towards evolution, correction and adaptation. In this sense, maintainability and its sub-characteristics as presented in the ISO/IEC 9126 standard should be incorporated to the artifacts produced in the modeling activity aiming at projecting soft­ware with characteristics that render its maintenance less costly due to the complexity and to the costs involved in this stage. Especially in the organization of non-trivial software products, such as those that are aspect-oriented, the importance of the research on the maintenance process and the need to consider it during the development process is remarkable, as these types of software aim at the maintainability and the reusability as they provide the separation of concerns. Thus, in seeking to reduce the transition effort to the artifacts generated during the Aspect-Oriented Software Development between the different abstraction levels, this paper presents a proposal for maintainability criteria for building aspect-oriented software design models based on the Maintainability Criteria for Implementation Models, on the aSideML language modeling conventions and on the ISO/IEC 9126 standard.;;pt_BR;Declined;0;2009;2009-08-07 16:53:18
9784;Luciano Antonio   Digiampietri;Universidade de São Paulo;Uma infraestrutura para o uso de jogos na educação;One of the biggest challenges in education is to engage, motivate and encourage students. Aiming to face this challenge, this article presents an infrastructure for the use of games in education that is being used in some subjects of the Information Systems course at the University of São Paulo (USP). In particular, this infrastructure was developed to try to reverse two negative trends in computing-related courses. The first refers to the decrease in candidates per place in these courses, which, in a certain way, contradicts the needs of the job market, which still lacks qualified personnel in this area. The second trend concerns the dissatisfaction of undergraduates with some subjects, mainly because they are unable to envisage the practical application of the various theoretical concepts, which can, in extreme cases, increase dropout rates from these courses. The objective of this article is to help solve these problems through the development of a computational environment for the implementation and management of computer games that can be used by teachers from different disciplines as a practical example of the theoretical concepts taught in the classroom.;;pt_BR;Declined;0;2009;2009-08-18 10:56:55
9931;Miriam Lúcia Campos Serra   Domingues;Universidade Federal do Pará;Portuguese Part-of-Speech Tagging: Toward High Accuracy in Texts of Different Genres;Part-of-speech tagging is a basic task used in natural language processing applications to label words of a sentence with their grammatical categories. To perform this task, tools called taggers apply machine-learning techniques. In this paper, our main goal is to evaluate our proposed tagging model of high accuracy in two dimensions first, the tagger was originally developed from text of the journalistic genre, whereas here it is evaluated on texts of the scientific genre, achieving an accuracy rate of 98.07%. To achieve high accuracy, we worked to overcome these critical issues: 1) training corpus size, 2) unknown words, 3) presence of noise, 4) tag set, 5) textual genre, and 6) tagging approach. Second, having gathered the results for the scientific genre, we reevaluated the test sets for the journalistic genre. These results were also positive, achieving their best accuracy at 98.30%. As a result of our efforts to obtain high accuracy on tagging, our combined approach guided by the critical issues and the adjustments presented here led us to move more than 2% of the state-of-the-art tagging accuracy (95-96% on average in Portuguese), thus validating our method of finding a more reliable tool.;;pt_BR;Declined;0;2009;2009-08-24 17:09:01
9981;Tiago Agostinho   Almeida;Universidade Estadual de Campinas;Redução de Dimensionalidade Aplicado na Filtragem Automática de Spams;In recent years, spam emails have become an important problem with a huge economic impact on society. Fortunately, there are different methods capable of automatically detecting and removing most of these messages, with the best known techniques being based on Bayesian Decision Theory. On the other hand, most probabilistic proposals present the same difficulty: manipulating data in a space with very high dimensions. To overcome this problem, many techniques for term selection have been proposed in the literature. In this article, we review the most popular methods used as term selection techniques, such as: document frequency, DIA association factor, information gain, mutual information, ?2 statistics, relevance score, odds ratio and GSS coefficient, used in conjunction with seven different versions of Bayesian naïve anti-spam filters. Additionally, we present an analysis of the measures used to evaluate the quality of anti-spam classifiers. In this sense, we evaluate the benefits brought by using the Matthews correlation coefficient as a performance measure.;;pt_BR;Declined;0;2009;2009-08-31 17:51:01
10176;Douglas   da Silva;PUCRS;Semantic Web and Knowledge Management in User Data Privacy;This paper discusses knowledge representation for privacy and accountability issues.;;pt_BR;Declined;0;2009;2009-09-22 14:20:36
10677;Marcos Proença de   Almeida;Universidade Estadual Paulista "Júlio de Mesquita Filho" Campus de São José do Rio Preto;Eliminação de Ruído Impulsivo Usando um Filtro Mediano Adaptativo Seletivo e Difusão Isotrópica;In this work, we propose an algorithm combining an impulsive noise detector, proposed by Chen, Yang and Cao, with a modification of the standard median filter and an isotropic diffusion process to remove salt and pepper noise. Consequently, applying the algorithm separately to each color channel, a filter is proposed to eliminate impulsive noise in color images. Experiments indicate that the proposed method is a robust filter for restoring images with large noise densities.;;pt_BR;Declined;0;2009;2009-10-09 23:23:51
10785;Elisa Yumi   Nakagawa;Universidade de São Paulo - USP;Using Architectural and Design Patterns in the Development of a Reactive System Simulator;Software systems have become more and more complex and have been inserted in diverse segments of the society. In order to develop these systems, software patterns have been regarded as an important element to provide an more adequate solution in the system architecture and design. Thus, experiences reporting the use of software patterns are interesting, aiming at contributing to reply the same experience in similar situations. The main objective of this paper is to present an experience of using software patterns, specifically architectural and design patterns, in the development of the HVDC-Sim, a simulator of a reactive system that controls a HVDC (High Voltage Direct Current) power system. As an result, we can point out that the adopted patterns were essentially important in order to achieve facilities in the development.;;pt_BR;Declined;0;2009;2009-10-13 13:23:18
10886;Luciano Vitoria   Barboza;Instituto Federal de Educação, Ciência e Tecnologia Sul-rio-grandense;Incertezas em Fluxo de Potência: Abordagem com Matemática Intervalar e Números Fuzzy;Power flow is an important tool in electrical systems supervision centers in order to assist operators in making decisions about the operation of the electrical network. The analysis of a power flow provides the voltage profile of the electrical network, which is the starting point for the planning and operation of the power system. This study is based on knowledge of active and reactive power demands in all buses of the electrical system. These demand values ​​are normally obtained using mechanical measuring equipment or, in some cases, they are estimated through load prediction. In this context, the main objective of this work is to present and discuss a computational tool for analyzing load flow that considers the influence of measurement errors and errors generated by numerical computation itself. In scientific computing there are two possible solutions: (i) Interval Mathematics, and (ii) Fuzzy Logic. With the simultaneous use of these mathematical techniques, robust software was developed to deal with uncertain and vague information. To test and validate the performance of the proposed methodology, the approach was applied to a real equivalent electrical system in the South-Southeast region of Brazil.;;pt_BR;Declined;0;2009;2009-10-15 11:33:21
11069;Celso   Liczbinski;Diretoria de Serviço Geográfico do Exército Brasileiro (DSG);Uma Nova Abordagem na Estimação de Probabilidades a Priori na Classificação de Imagens Digitais;Recently, an adaptive classifier aimed at classifying high-dimensional data was proposed in the literature. The contribution in that study consisted of a methodology for obtaining semi-labeled samples using an iterative approach inserted into the classification process itself. The semi-labeled samples thus obtained are added to the set of available labeled samples, thus increasing the total number of training samples and consequently the reliability of the estimates for the classifier parameters. In the present study, the introduction of an additional step in this iterative process is investigated, for the purpose of estimating values ​​for the a priori probabilities of the classes under consideration. The approach proposed here uses the same methodology used to obtain semi-labeled samples, which makes it computationally efficient and easy to implement. The tests developed using hyperspectral image data showed that the process proposed here contributes to an increase in the accuracy of the classification process. Keywords: a priori probability, semi-labeled samples, high-dimensional image data.;;pt_BR;Declined;0;2009;2009-10-24 15:46:22
11410;Marluce Rodrigues   Pereira;Universidade Federal de Lavras;Análise de desempenho de um algoritmo de particionamento estático de redes de restrições utilizando multithreads;The evolution of hardware technology has led to the emergence of processors with increasingly greater processing capacity. Multicore processors can make better use of their processing capacity when applications are implemented in parallel using multithreaded programming. Thus, problems that require high processing capacity and have a large volume of data can be executed more quickly. This work presents a performance analysis of a static partitioning algorithm for applications modeled in constraint graphs, called Grouping-Sink, on different hardware and software platforms. The sequential algorithm was parallelized using multithreaded programming and experiments were carried out with Constraint Satisfaction Problems or a network of constraints. The results showed that parallelization using multithreads can achieve speedups of up to 473.19, using execution on Linux, with maximum priority and the scheduling of threads by the operating system and the characteristics of the hardware architecture used can greatly influence the execution time of a parallel application.;;pt_BR;Declined;0;2009;2009-11-19 19:08:27
11478;Bruno Rabello   Monteiro;UFOP - Universidade Federal de Ouro Preto;Uma Taxonomia de Aplicações de SIG Móveis para   Governo Eletrônico em Administrações Municipais;This  article  presents  a  taxonomy of  Mobile Geographic Information Systems (Mobile GIS) applications, according to the areas or sectors of a municipal public administration and  also the actors involved in electronic government (e-gov) activities. This  taxonomy  aims to  show  the potential that Mobile GIS applications can have in the development of municipal e-gov.;;pt_BR;Declined;0;2009;2009-11-24 18:21:39
11515;Weber   Martins;Universidade Federal de Goiás - UFG;Estudo Empírico de Avaliação Inteligente Computadorizada de Questões Abertas Baseada em Colaboração;The Connectionist and Collaborative Intelligent Assessment System (SAICO), tested by Guimarães [2004] in simulation, is empirically evaluated in a real environment, using web technology in all phases: preparation, execution, “ranking”, correction and synthesis of grades. SAICO explores Kolb's Theory [1984], being able to apply and correct assessments with open questions. The results confirm the secondary hypotheses expressed in the good acceptance of the system by teachers and students. A strong correlation (0.81) was obtained between the grades awarded by SAICO and the human grades (reference), confirming the great potential of the system. Specific points of improvement were identified for future work.;;pt_BR;Declined;0;2009;2009-11-29 23:48:35
11540;Mario Meireles   Teixeira;UFMA;Definição e Avaliação de um Protocolo de Reputação para Redes Peer-to-Peer;Peer-to-peer (P2P) networks very often face the problem of dealing with ill-behaviored nodes, which do not partcipate collaboratively in the network and sometimes hinder the community activities in various ways, either by generating unnecessary traffic, tampering with the network's protocol, disseminating polluted content or simply by not sharing resources obtained from other nodes. This work defines a protocol for reputation management in P2P networks aiming at identifying the nodes or resources that might be jeopardizing or polluting the network. The protocol employs a distributed algorithm which, when computing the current node reputation, takes into account its history of interactions in the network, besides introducing mechanisms for minimizing the number of management messages generated. The protocol's assessment demonstrates that it can closely follow the reputation of nodes and resources in the network, thus favoring cooperative and clean nodes and isolating the malicious or selfish ones, without significantly impacting application performance.;;pt_BR;Declined;0;2009;2009-12-01 19:20:07
11763;Francieli   Zanon Boito;Universidade Federal do Rio Grande do Sul;Avaliando o desempenho do sistema de arquivos Lustre;Applications running in cluster environments often use Distributed File Systems (SADs) to access large amounts of data. Depending on your design options, these systems can exhibit varying behaviors under different access patterns. Thus, studying how the performance of a SAD behaves for different ways of carrying out I/O operations verified in practice is an important task, as it provides tools so that applications can adapt their I/O operations to take better advantage of the system used. In this work, test classes are used to evaluate the performance of the Luster file system. The results obtained indicate, among other things, that for writing operations to exclusive data with large numbers of clients, using node-independent files has better performance than using a shared file. However, for other situations, this approach proves to be equivalent and even less efficient than the single-file approach. Furthermore, it is observed that the granularity of access does not affect performance when accessing large contiguous areas, and that caching on clients and data servers is effective in avoiding repeated requests for the same data.;;pt_BR;Declined;0;2010;2010-01-04 17:46:30
11803;Manoel Agamemnon   Lopes;UFAL;Convergência de Processos Evolutivos:;In this article, some considerations are made about the general ideas that should guide the convergence of evolutionary processes. In this sense, an outline is presented for a study of the convergence of evolutionary processes within evolutionary environments. Then, the genetic algorithm GAADT (Genetic Algorthm by Abstract Data Type), developed in Vieira (1999), Vieira (2003), is framed to present proof of its convergence.;;pt_BR;Declined;0;2010;2010-01-09 13:18:22
11841;Alexandre de Assis   Mota;Pontifícia Universidade Católica de Campinas;APLICAÇÃO DE LÓGICA NEBULOSA NA ANÁLISE DA ATENUAÇÃO DE SINAL DE REDES SEM FIO EM AMBIENTES INDOOR;Currently, wireless networks (RSF) are an interesting technology for providing services, such as video, voice and video conferencing. In order for these services to be used effectively, it is necessary to estimate some parameters related to signal transmission, including the power of the reception signal and, consequently, the attenuation of the transmitted signal. The signal is affected by environmental and infrastructure conditions, such as the layout of the building, materials used in construction, movement of people, separations between rooms, etc., and it is therefore necessary to consider these factors when determining signal attenuation. However, considering all the factors mentioned can make this calculation quite complex. This work proposes a methodology for determining the attenuation of the signal transmitted in indoor environments (AI) based on the application of Fuzzy Logic (LN). This method basically consists of using fuzzy logic and a set of rules that allow the inference of the parameter ? used in the Shadowing Signal Propagation Model (MPSS), commonly used to determine signal attenuation and quite widespread in the literature. The results obtained from the application of the proposed methodology proved to be quite satisfactory, as they were very close to those obtained through experimental methods.;;pt_BR;Declined;0;2010;2010-01-14 12:06:45
11923;Beatriz Terezinha   Borsoi;Universidade Tecnológica Federal do Paraná;Java RMI e Web Services na Implementação de um Jogo Multiusuário Distribuído para Desktop;Games are used for different purposes, including entertainment, learning and therapy, and at different stages of human life. Computer networks, especially the Internet, have expanded the market for computer games, especially multi-user games aimed at entertainment. The diversity of applicability of games and user audiences motivated the development of this work, which refers to the use of Web Services and RMI in the development of a distributed multi-user game. It is a game for a desktop environment using the Java language.;;pt_BR;Declined;0;2010;2010-01-26 11:16:58
11924;Beatriz Terezinha   Borsoi;Universidade Tecnológica Federal do Paraná;Um Modelo de Arquitetura para RIA Baseada em Plug-in;The expansion of the Internet - due to the increase in users and the use of its services for the most diverse purposes, from large commercial applications to entertainment - contributed to users demanding more interactive web applications with an interface with more resources, including because they are used to the standard desktop applications. However, web applications based on HTML and hypertext have presented limitations in meeting these new requirements. Therefore, other technologies and methodologies have emerged for web applications to provide ways to overcome these limitations and meet users' new interests. These technologies and methodologies are quite recent, so it is common for a form of representation of the architecture of applications called Rich Internet Application to still be necessary. Thus, this work aims to propose an architecture to represent a plug-in-based RIA that has an interface built through computational objects.;;pt_BR;Declined;0;2010;2010-01-26 11:32:54
11996;andre barbosa   verona;Universidade Estadual de Maringá;Análise comparativa entre os protocolos de roteamento AODV e DSDV nas redes de sensores sem fio aplicadas à viticultura;Analyze the behavior of wireless sensor networks for monitoring vines using the AODV and DSDV routing protocols in order to evaluate energy consumption and the delay time in delivering data from devices in these networks.;;pt_BR;Declined;0;2010;2010-02-01 17:20:17
12003;Maurilio   Hirata;UEM - Universidade Estadual de Maringá;Modelagem de Conhecimento Usando CommonKADS: Estudo de Caso em Instituição de Ensino Superior;This article presents a case study of the use of the CommonKADS methodology applied in the management of activities inherent to postgraduate course programs maintained by the State University of Maringá (UEM), carried out by the Postgraduate Division of the State University of Maringá (DPG ). Through this study, it was possible to verify that the current communication system between the DPG and the secretariats of each Postgraduate Program is redundant, increasing the costs and performance of the system, from which a response cannot always be expected. quickly. This work presents the results of applying the CommonKADS methodology in specifying the architecture of a system that maintains a centralized knowledge base, minimizing the costs involved with the use of a more effective communication system.;;pt_BR;Declined;0;2010;2010-02-01 20:57:58
12032;Lucelene   Lopes;PUCRS;Ontologias e Extração Automática: Um Tutorial;This tutorial formally presents the concept of ontologies and the steps for extracting ontologies from texts. Like the entire ontology construction process, ontology extraction from texts also aims to build a representation of conceptual knowledge of a domain specific that can be used in different areas for different applications. However, in this approach, ontology construction is done through automatic and semi-automatic knowledge extraction methods. These methods seek to reduce the cost of ontology construction, as well as its structural representation.;;pt_BR;Declined;0;2010;2010-02-08 12:06:15
12096;Miriam Lúcia Campos Serra   Domingues;Universidade Federal do Pará;Improving Part-of-Speech Tagging Accuracy for Portuguese;Part-of-speech tagging is an important task required by many applications of natural language processing such as grammar checking, machine translation and others. Although these applications need to be over 99% accurate for the disambiguation of words, state of the art taggers are less than 97% accurate in Brazilian Portuguese texts. In this study, we aim to investigate strategies for improving tagging accuracy and to explore issues regarding methods and corpora that need to be considered in the development of a tagger toward 99% accuracy. Our proposal uses a hybrid approach that employs probabilistic methods in conjunction with rule-based methods in a corpus-based tagging model. Under three experimental strategies: consult a lexicon of proper nouns, add hand-coded rules, and use a very large lexicon in training, we achieve accuracy of 98.08% and 98.27%, respectively, for Mac-Morpho and Bosque CETENFolha, two Brazilian Portuguese corpora. Besides improving tagging accuracy, we also identify and address the major problems raised in the study. These findings are relevant because they represent steps toward achieving 99% accuracy.;;pt_BR;Declined;0;2010;2010-02-19 0:45:04
12679;Naidson Clayr   Santos Ferreira;Instituto Federal de Educação, Ciência e Tecnologia;A SEGURANÇA FÍSICA COMO FATOR INFLUENCIADOR NA SEGURANCA DA INFORMAÇÃO NAS EMPRESAS;This work seeks to present and analyze physical security as a factor influencing information security in companies. The subject of Information Security appears to organizations and, in general, to all interested parties, as a way of preventing invasions of systems, privacy and security in the access and processing of information. It raises awareness and the importance of Information Security in the Strategic Management of Companies. It shows the physical security factor and the controls necessary to protect incidents, defining practical means and ways to resolve or minimize impacts and losses of strategic information, which may harm the functioning of the Management of a Company or Institution.;;pt_BR;Declined;0;2010;2010-04-04 20:15:52
12737;Naidson Clayr   Santos Ferreira;Instituto Federal de Educação, Ciência e Tecnologia;A SEGURANÇA LÓGICA COMO FATOR INFLUENCIADOR NA SEGURANCA DA INFORMAÇÃO NAS EMPRESAS;This work aims to show and analyze logical security as a factor influencing information security in companies. The topic of Information Security is presented to companies and, in general, to everyone who is interested, as a way of guarding against invasions of systems, privacy and security in the access and processing of information. Describes the purpose of information security and the way in which logical security is implemented as a chosen strategy in a company. It reminds us of the need for technical training as a crucial measure used by companies to ensure the functioning of a company's management.;;pt_BR;Declined;0;2010;2010-04-08 9:12:42
12791;Ellison Cleyton   Barbosa dos Santos;Museu Paraense Emílio Goeldi;Sistemas Gerenciadores de  Banco de Dados Multimídia: com ênfase no Sistema Acadêmico da Esamaz;With the considerable growth in the use of multimedia information as a form of application in Information Systems, we see the effectiveness of the system as the organization of data: indexing and storage, this being a direct characteristic of data recovery. In this context, the article addresses a study on the organization of multimedia data, specifically in the multimedia functions of the Esamaz Academic System. The system was developed to store images and biometric identification of students at Escola Superior da Amazônia. Its functionalities produced satisfactory results for managing this type of information.;;pt_BR;Declined;0;2010;2010-04-12 20:53:49
12966;Naidson Clayr   Santos Ferreira;Instituto Federal de Educação, Ciência e Tecnologia;AMEAÇAS, VULNERABILIDADES, ANÁLISE DE RISCOS, POLÍTICA DE SEGURANÇA, AUDITORIA E PLANO DE CONTIGÊNCIA COMO FATORES INFLUENCIADORES NA SEGURANCA DE INFORMAÇÃO NAS EMPRESAS;This work seeks to present concepts and general principles about threats, vulnerabilities, risk analysis, auditing, security policies and contingency plans so that they can improve information security management in companies.             It raises awareness and the importance of Information Security in Strategic Management of Companies presenting the means to solve problems related to information protection and risks related to vulnerabilities. In this way, this work presents, as a whole, a study on the market's vision regarding threats, vulnerabilities, risk analysis, as well as access policy, its concessions, audits and contingencies.;;pt_BR;Declined;0;2010;2010-04-25 11:10:28
13140;Raphael Silva   Marques;Universidade Estadual de Feira de Santana - UEFS;Implementação de Técnicas de Processamento Digital de Imagens para Auxílio na Detecção de Pontos Cefalométricos;This work presents the implementation of digital image processing techniques applied in the development of a CAD Scheme (Computer Aided Diagnosis) for carrying out cephalometric tracings and analyses. The objective of implementing these techniques is to provide orthodontic specialists with tools to assist them in marking cephalometric points. As results, routines for manipulating digital dental images and a local image magnification system are presented to assist in marking and better visualizing the points to be used in a cephalometric analysis.;;pt_BR;Declined;0;2010;2010-05-05 16:10:25
13190;Fabio Gomes   Rocha;SergipeTec;AMBIENTE VIRTUAL DE APRENDIZAGEM: UM MODELO PARA ANÁLISE DO;Teaching in a virtual environment is increasingly adopted by institutions and establishes a differentiated environment for educational relationships that do not rely on the physical presence of those involved. This fact implies pedagogical proposals and teaching strategies that use resources and tools to fill the gap of non-face-to-face presence implicit in distance education. This work addresses the characteristics of the environments in which virtual classes are developed, and establishes parameters of an empirical-experimental nature for address the potential that is offered for interaction between teacher and student. By analyzing the frequency, significance and scope that the materials used for teaching offer learning, a mathematical model is presented as a result of the experience with 4,326 students, observed over 12 months in professional development courses. The proposed mathematical model describes the interaction potential of the investigated students with virtual classes and its application is indicated as a basic means for improving learning results in distance learning courses mediated by the Internet.;;pt_BR;Declined;0;2010;2010-05-10 8:38:27
13262;Marcia Maria   Savoine;PUCCAMP;Análise da Eficiência Espectral para Bandas Licenciadas WiMAX Considerando a Duplexação e o Pérfil de Tráfego;Abstract: This work presents the comparison carried out through discrete event simulations, carried out with the ARENA software, of the Time Division Duplexing (TDD) and Frequency Division Duplexing (FDD) techniques, techniques present in the IEEE 802.16 standard and used by WiMAX on bidirectional uplink and downlink channels. The simulation model considered the FIFO (First-In, First-Out) concept in the service arrival queue and the simulations were carried out considering five applications (Streaming, Download, Web, E-mail and Small-Transaction) for downlink and uplink . The efficiency parameter considered was the minimum number of channels required in each of the standard channels. The analysis carried out made it possible to identify, given these traffic conditions, which of the techniques would be the most suitable. It was also found that in asymmetric data traffic the TDD technique was more efficient even without considering the guard time and it was observed that there was spectrum idleness in the FDD technique.;;pt_BR;Declined;0;2010;2010-05-17 11:07:36
13267;Taufik   Abrao;UEL - Universidade Estadual de Londrina;Análise de Complexidade de Detectores Heurísticos DS/CDMA Implementados em Plataforma DSP;This work investigates issues related to the computational complexity of multi-user receivers in code division multiple access and direct sequence systems (DS/CDMA -- \emph{Direct Sequence/Code Division Multiple Access}) based on heuristic detection techniques and implemented from commercial digital signal processing (DSP) platform (Texas TMS320C6713). The heuristic multi-user detection algorithms implemented in baseband were based on the heuristic principle of local search ($LS-$ \textit{local search}) and simulated annealing (SA - \textit{Simulated Annealing}). Figures of merit related to the increase in computational complexity due to the increase in processing load (in this case, number of active users in the DS/CDMA system) are discussed, as well as the baseband receiver design/implementation methodology is briefly presented. using DSP platform.;;pt_BR;Declined;0;2010;2010-05-17 15:21:27
13285;Vanessa Siqueira   Melo;Universidade Federal de Mato Grosso;Arquitetura e modelo de simulação de rede de distribuição de água em um SIG;The population increase and the scarcity of water resources is a worrying issue for public managers and organized entities. The development of tools that assist in the maintenance, monitoring and analysis of systems that use water resources is essential for efficient and sustainable management of this natural resource. This work presents research on water simulation in treated water supply networks, which resulted in a model based on a Geographic Information System (GIS) that, based on information stored in a geographic database, performs flow simulations and network pressure. This type of system can help with activities such as network monitoring, evaluation of expansion projects and increased demand. The research developed was based on real data from a neighborhood in the city of Barra do Garças/MT and the simulation was based on the Hazen-Williams mathematical model. The simulation system developed showed consistency and good results when compared with the Epanet software. In continuation of this work, the simulation system will be made available in a web environment, the Darcy-Weisbach mathematical model will also be implemented, as an alternative to the Hazen-Williams model, and the graphical interface will be improved to facilitate user use of the system. .;;pt_BR;Declined;0;2010;2010-05-19 11:45:49
15055;André Luiz   Pires Guedes;Universidade Federal do Paraná;Comparação entre três algoritmos exatos para a coloração de grafos;New methods for accurate graph coloring have recently been published. Among the published works, the Cutting Planes algorithm, the Branch and Cut algorithm, which is a sequence of the first, and the Lucet algorithm, stand out. The first two use an integer programming approach and the third a structured programming approach to the problem. Although each one has a different approach to the coloring problem, in this work we will draw a parallel between them and point out differences and similarities between the articles mentioned.;;pt_BR;Declined;0;2010;2010-07-27 21:53:09
15699;Priscila   Cembranel;Sociedade Educacional Três de Maio;A Influência da Engenharia Social na Gestão de Pessoas;Large investments are made every year by organizations with the aim of improving their security using the most modern technologies. However, the most vulnerable aspect of the company is being left aside: human resources. Social engineers have been exploiting this vulnerability for decades and yet, organizations continue to invest in misguided security initiatives. By carrying out comparative bibliographical research, it becomes possible to observe that the aspects of recruitment and selection, training and development of people, performance and potential assessment and management models that provide accessibility to information are the aspects most affected by engineering actions. that end up exploring both the physical environment of the company and the emotional aspects of its employees. The best way to face this situation is to invest in awareness and constant training, preparing your employees to face random attacks and guaranteeing the security of business information, which is currently the biggest differentiator for business.;;pt_BR;Declined;0;2010;2010-08-20 11:01:19
15741;Jamir Alexandre Ferreira   Fernandes;Universidade do Estado do Pará;Criptografia: Da Cifra de César à Inquebrável RSA;The objective of this article is to present cryptography since its inception. The main focus will be the mathematical description of RSA Cryptography, which is used on the internet as a fundamental piece in the security of banking transactions and purchases involving passwords and credit card numbers. The art of encryption was born with Julius Caesar, but over the centuries several ways to protect documents emerged, after the Second World War the Enigma encryption machine appeared, after that a cryptographic algorithm called Lucifer and so on other methods, such as the Diffie-Hellman-Merkle system and then RSA, which guarantees greater security for carrying out all types of transactions on the large network. To date, there is no news of a cryptographic method that is as effective as RSA. Only with the discovery of a quick way to decompose a number to find which primes generated it will RSA no longer be secure.;;pt_BR;Declined;0;2010;2010-08-20 21:07:31
16134;Marcos Antonio   Quináia;Universidade Estadual do Centro-Oeste - UNICENTRO;Aplicação de Padrões de Projeto em um Mecanismo de Notificação de Controle Holônico;This article presents the application of established design patterns known as Observer and Singleton in a Holonic Control notification mechanism that aims to make modern production systems agile. The article initially shows a contextualization of the use of design patterns, the execution of the Observer pattern and the benefits of its application. Subsequently, the holonic control architecture is presented, identifying the application points of the standards. To show the efficiency of patterns in architecture, a simulator built in Java is presented in this work.;;pt_BR;Declined;0;2010;2010-09-08 18:43:24
16150;Giani Carla   Ito;UNIPAR;Mobile computing: Proposal for a Development Environment for Multiple Devices;This article presents architecture for the Generation of Adaptative Interfaces (GAI) and its objective is to allow an implementation directed to a multi-platform environment, which starts from a generic description of the interface. Moreover, the idea is that the specialists, such as   software programmers and   interface designers can implement interfaces for desktops and mobile devices, without the necessity of additional programming. One of goals of the GAI approach is to attend multiple users in a dynamic way, covering a wide range of devices. GAI architecture aims to reduce the development time of a mobile device application by using a methodology less dependent on   single device properties. Therefore, that architecture is addressed to a multi-platform environment and is able to acquire user context information in a dynamic way, using the repository of profiles.  At the end of the paper, some tests are demonstrated with cellular phone and palm simulators.;;pt_BR;Declined;0;2010;2010-09-09 21:56:37
16654;Suian Boff   Menegas;Universidade Feevale;O PROCESSO DE DESCOBERTA DE CONHECIMENTO EM BASES DE DADOS NO AUXÍLIO À SAÚDE PÚBLICA;This work presents a proposal to create a model for applying the Knowledge Discovery process in Databases using the municipal databases of the DATASUS system. The proposal aims to provide health managers in municipalities that have financial constraints and, therefore, the impossibility of acquiring expert systems to aid decision-making, a quick, cheap and effective alternative to knowing the health profile of their municipality and raising the health needs of its population and create or reform health policies. Furthermore, the proposal aims to provide assistance to health managers in the task of adapting the distribution of health resources according to the needs of the population in accordance with the principles of equity, accessibility and universality, which form the basic principles of the SUS.;;pt_BR;Declined;0;2010;2010-10-08 14:47:50
16737;Marina Teresa Pires   Vieira;UNIMEP;Apoio ao Uso da Classificação na Ferramenta de Mineração de Dados Kira;Existing data mining tools require a lot of knowledge from the user to carry out the knowledge discovery process in databases (KDD). Teaching how to prepare data, how to choose the appropriate data mining task for the intended purpose, and how to analyze the generated rules transcend the objectives of current tools. The Kira tool was developed based on a set of guides to instruct the user to carry out this process more easily. This article presents the module that was incorporated into the tool, to teach how to carry out the data mining process, focusing on the classification task.;;pt_BR;Declined;0;2010;2010-10-15 18:16:25
16954;Elaine   Hayashi;IC - UNICAMP;Perspectives on the Evaluation of Affective Quality in  Social Software;Enormous changes in the computing field are being experienced, altering the way we relate ourselves with computational technology. If computers had at first limited functions and limited presence in our lives, they are now being used everywhere, all the time, for a multitude of purposes and presenting a multitude of means for interactivity. Computer applications are now important not only for their ability with specific tasks, but also for presenting characteristics that support our social relations. This shift calls for new ways of evaluating systems, demanding attention not only to usability and accessibility issues but also to the emotional and affective ones. This paper presents a brief review on theory and methods for affective evaluation of computer systems, as a preliminary discussion on the suitability of existing methods for social software applications. The discussion is instantiated in inclusive social software ? Vila na Rede, a system developed under a participatory design approach with the purpose of fostering a digital culture among the less favored segment of the Brazilian society.;;pt_BR;Declined;0;2010;2010-10-27 21:18:12
16978;Bruno   Merlin;UFPA;Improving Implicit Social Bookmarking by Increasing the Expressiveness of Navigation Task;Observing that social bookmarking became a popular way to share and publish bookmarks, but a way exposed to anti-social and spamming behaviors, we proposed the concept of implicit social bookmarking. The main purpose of implicit social bookmarking is improving the indexation of pages by making the indexation beneficing of a collaborative participation to the evaluation of web contents.  But, to avoid an active and judicative participation of spammers, the collaboration is performed implicitly through an automatic analyze of the users behaviors towards the content during his web browsing. Thus, an algorithm evaluates the users’ interest for web contents. We proposed an implementation of the concept (Djinn) and evaluated it. We observed that, unless encouraging results, the valuation of users’ interest for contents could be improved. We suggested two axis of improvement and evaluated a first one: an HMI (Djinn-I) helping to turn the users’ navigation more expressive. Djinn –I appeared to be a pertinent tool for re-find contents.;;pt_BR;Declined;0;2010;2010-10-29 11:04:16
17198;Ana   Cervigni;Centro de Tecnologia da Informação Renato Archer-CTI;Aplicação de Data Mining a Dados de Avaliação da Qualidade de Produtos de Software;This article describes how data mining tools were applied to data stored in a relational database that contained the results of evaluations of software products from three award periods organized by the Association of Software Production Companies (ASSESPRO). These assessments were carried out at the Renato Archer Information Technology Center – CTI, using the MEDE-PROS® methodology. The assessment of the quality of software products that took place at the ASSESPRO Awards generated a large database with many variables involved. The possibility of generating information from hidden knowledge motivated this work. Automatic and intelligent data analysis uses multidisciplinary concepts for its functions. The data was processed and transformed into useful information.;;pt_BR;Declined;0;2010;2010-12-28 11:20:23
17699;Bruno da Rocha   Braga;Universidade de Brasília;UMA METODOLOGIA DE MODELAGEM DA ARQUITETURA DE PROCESSOS PARA A GESTÃO DA ESTRUTURA DE CUSTOS: teoria e prática em um estudo de caso no Banco Central do Brasil;In recent years, the industrial economy has been losing relevance and value to a new information economy, so that modern organizations are required not only for better results and performance of their operations, but also for timely and effective adaptation to the changes arising. of an increasingly dynamic environment. In this context of increasing complexity in the decision-making process, we have a conflict between the relevance of cost systems for managerial decision-making and the new challenges for the management of these systems, particularly with regard to the construction and updating of the cost model. Through large and complex organizations, not just one, but several value chains can pass, allowing some degree of activity sharing and product integration. To manage resources, products, their respective value chains and relationships with suppliers and customers, it is necessary to build a Process Architecture. Therefore, this research aims to establish a model and methodology for mapping products and their respective value chains. To this end, we adopted an approach consisting of two complementary steps. In the first, a study of the literature on known methodologies, languages ​​and modeling paradigms, whose purpose is to establish the language and relationships between concepts, constituting the basis of the conceptual model. In the second, a prospective study to identify process modeling patterns, using data collected on the structure, products and activities of the Central Bank of Brazil.;;pt_BR;Declined;0;2010;2010-12-10 16:20:16
17962;Daniel Saverio   Spozito;Faculdade de Engenharia de Ilha Solteira - FEIS - UNESP;GeoMon_IPv4: Sistemas de informações geográficas na gestão de redes TCP/IP;With globalization and technological evolution, the use of computer networks in public or private institutions is an irreversible reality. In this context, there is a need to interconnect computer systems with the aim of exchanging information regardless of geographic region. With technology and infrastructure available to carry out communication between remote points, there is also a need to ensure that communication is active for as long as possible, as activities in institutions begin to depend on the interaction between computer systems, regardless of the point on the planet in which they are located. that they are. This article presents the results obtained in the simulation of a tool developed in Java language for monitoring points interconnected by long-distance data communication networks over the TCP/IP protocol, using geoprocessing concepts. The model consists of monitoring one or more points, plotted on a map outlining the geographical political perimeter of the area served. The status of each monitored point is constantly updated, allowing possible faults to be detected in a short space of time.;;pt_BR;Declined;0;2010;2010-12-27 21:10:12
17976;Luiz Gustavo Cunha   Barbato;Centro de Tecnologia da Informação Renato Archer-CTI;METODOLOGIA DE IDENTIFICAÇÃO DE VULNERABILIDADES - SEGURANÇA E AUDITORIA EM SISTEMAS DE INFORMAÇÃO;Based on the need for security in payment applications using computer technology, this article aims to present a methodology to identify vulnerabilities, with the aim of reducing the risks of exploitation in payment requests by malicious people. Payment card purchases have been steadily increasing. This type of operations allows users to make purchases of these resources without the need for money, and even without physically being in a store. E-commerce brings convenience and financial advantages to consumers. However, this type of transaction is also a risk of information leakage, mainly because, in possession of certain authentication data for payment, you can make purchases without knowing the real customer. To contribute to improving the security of information systems and guarantee the confidentiality and integrity of data, as well as the availability of the same methodology can be used by software developers and security professionals, complementing some existing security standards in this segment.;;pt_BR;Declined;0;2010;2010-12-29 11:24:45
18289;Dorival Moreira   Machado Junior;LIBERTAS - Faculdades Integradas;Questões de design e estética no uso de realidade aumentada para ensino e análise de funcionamento das regras de um firewall;It makes a brief theoretical review on the concept of semiotics, signs and crucial factors in the creation of such signs, also going through firewall concepts and information pertinent to this, artoolkit as an augmented reality tool for data visualization, discusses the representation of content internal to a firewall with previously defined rules, dynamically displaying the established paths as well as the data packets traveling over them.;;pt_BR;Declined;0;2011;2011-01-23 22:55:03
18341;Idomar Augusto   Cerutti;Universidade Estadual de Ponta Grossa-PR;Otimização de memória em componente Delphi para redes neurais artificiais do tipo Mlp: Utilizando vetor dinâmico;This study addresses the use of a new data structure to implement the TMlp component, available in [9]. This component allows implementations of Artificial Neural Networks of the Multi-Layer Perceptron or MultiLayer Perceptron (MLP) type for pattern recognition. It was possible to verify that by replacing the linked list data structure, used by the original component, with a dynamic vector, the memory savings were significant. This savings varied according to the size of the MLP network, saving memory usage by up to 43%.;;pt_BR;Declined;0;2011;2011-01-25 7:43:53
18432;andre barbosa   verona;Universidade Estadual de Maringá;Análise Comparativa Entre os Protocolos de Roteamento AODV e DSDV nas Redes de Sensores Sem Fio Aplicadas à Viticultura;Environmental monitoring is a strategy that is increasingly used every day, providing means to predict and enable the control of adverse situations during vegetable cultivation, such as lack of water resources or the possibility of pest attack. An interesting option that has recently emerged for environmental monitoring is wireless sensor networks (WSN), which are devices capable of sensing the environment and that can communicate with each other, forwarding the collected data between all devices to a point centralized collection. In this work, several WSN configurations were simulated and analyzed, aiming to identify the lifetime and delay in delivery and loss of data for the WSNs applied to monitoring grape plantations, serving a large number of farmers in the city of Marialva – PR, city ​​that stands out for its large grape production. As a final result of this work, the best routing protocol among those considered (AODV and DSDV) was found, showing which one performed better in each simulated scenario.;;pt_BR;Declined;0;2011;2011-01-28 16:19:36
18468;José Luís   Sorokin;IPT;Um ambiente de simulação virtual de algoritmos anti-colisão para apoio ao desenvolvimento de aplicações de RFID;Among the technical aspects to be considered in the design of a system based on RFID (Radio Frequency Identification), one of the most important is the analysis of the information collision process, that is, the succession of events that occur when RFID tags enter the zone of coverage of a reader device and transmit their information simultaneously, making correct identification difficult. To avoid the harmful effects that would be caused by such events, it is necessary to integrate an algorithm – called ‘anti-collision’ – into transmitting and receiving devices – responsible for isolating communication between each tag and the reader. This work proposes the development of a simulation environment for anti-collision algorithms for RFID systems that allows their comparative analysis in varied situations, facilitating the performance evaluation of these algorithms and their subsequent selection, in order to meet the characteristics of the intended application. . Some experiments carried out with the anti-collision algorithms implemented in the simulation environment are also presented and analyzed in light of the adopted performance metrics.;;pt_BR;Declined;0;2011;2011-02-03 0:03:53
18623;Alexandre Wagner Chagas   Faria;Universidade Federal de Minas Gerais;Um Estudo Sobre Fluxo Óptico;Movement is a powerful feature in image sequences, revealing the dynamics of the scene, through the spatial relationship of image characteristics, according to temporal change. The task of motion analysis remains a challenging and fundamental problem in computer vision. The apparent movement of objects, on an image plane, is a strong visual cue for understanding 3D structure and movement. Optical Flow then emerges as a powerful tool for estimating this movement in a scene. Supporting one of the main objectives of computer vision, which is to infer properties and characteristics of a 2D scene that help us reconstruct the original scene - “the 3D world”. In this work the main characteristics of this technique will be presented, the two main methods for calculating Optical Flow will be detailed, and finally one of the methods will be implemented, aiming at understanding and analyzing its results.;;pt_BR;Declined;0;2011;2011-02-15 11:02:49
18644;José de Oliveira   Guimarães;UFSCar;Translations between Object-Oriented Languages;There are several aspects to consider when analyzing an object-oriented language: support for single or multiple inheritance, dynamic or static typing, definition of subtyping, and differences between subtyping and subclassing. So different are the languages that apparently it is very or even extremely difficult to translate code in one language to any other. We show how to translate code from and to several simplified object-oriented languages. Although the languages used lack the complexities of real languages, the translations achieve three objectives: a) help us to better understand inheritance and subtyping in real languages, b) supply algorithms for refactoring code, and c) supply algorithms for translating a real language to instructions of virtual machines of another language.;;pt_BR;Declined;0;2011;2011-02-17 17:19:22
18978;Gerson Geraldo H.   Cavalheiro;Centro de Desenvolvimento TecnológicoUniversidade Federal de Pelotas;Simulação de algoritmos de escalonamento de lista em ambiente de execução multithreaded dinâmico usando a ferramenta AKSim;List scheduling algorithms are known for their efficiency in scheduling DAGs (Directed Acyclic Task Graphs). This type of scheduling, however, has been used by dynamic multithreaded programming tools as a resource to raise the level of abstraction in managing processor usage. AKSim is a tool that allows you to transform DAGs into graphs that represent the same program in a multithreaded programming model. It also allows simulating the execution of both graphs in multiprocessed architectures according to heuristics exploring the critical path. The results obtained indicate that a dynamic strategy based on a list scheduling algorithm can be as efficient as static strategies. The study was conducted considering Anahy's programming and execution model.;;pt_BR;Declined;0;2011;2011-03-10 14:01:09
19046;Pedro Luis   Alfonzo;Universidad Nacional del Nordeste.Facultad de ciencias Exactas y Naturales y Agrimensura.;Aplicación de SCRUM para gestionar el proceso de mantenimiento del software. Estudio preliminar.;Summary: Software maintenance is an integral part of the life cycle. The objective is to keep the software operational for as long as possible, maximizing the organizations' investment. A preliminary study is presented in order to provide theoretical considerations that support the application of SCRUM, an agile methodology, in software maintenance projects. The work is based on addressing the management activities proposed by the IEEE, given that this standard explains “what” to do, without accounting for “how.”;;pt_BR;Declined;0;2011;2011-03-15 9:43:58
19903;Adenilton José da   Silva;Centro de InformáticaUniversidade Federal de Pernambuco;Algoritmo de Aprendizado de Única Apresentação para Redes Neurais Quânticas;Quantum algorithms with better performance than classical equivalents have been proposed in recent years, the best-known examples being Grover's search algorithm and Shor's factorization algorithm. The main objective of this article is to verify the number of executions needed to train a neural network using a quantum training algorithm. A training algorithm called Single Presentation Learning Algorithm (AAUA) based on superposition is defined in this work. AAUA has a computational cost similar to other quantum algorithms based on superposition, but requires only two executions of the neural network.;;pt_BR;Declined;0;2011;2011-04-19 15:01:51
20822;José de Oliveira   Guimarães;Universidade Federal de São Carlos - UFSCar;Translations between Object-Oriented Languages;There are several aspects to consider when analyzing an object-oriented language: support for single or multiple inheritance, dynamic or static typing, definition of subtyping, and differences between subtyping and subclassing. So different are the languages that apparently it is very or even extremely difficult to translate code in one language to any other. We show how to translate code from and to several simplified object-oriented languages. Although the languages used lack the complexities of real languages, the translations achieve three objectives: a) help us to better understand inheritance and subtyping in real languages, b) supply algorithms for refactoring code, and c) supply algorithms for translating a real language to instructions of virtual machines of another language.;;pt_BR;Declined;0;2011;2011-06-14 17:27:13
21154;Kleyton Pinto   de Almeida;;METAHEURÍSTICA GRASP COM FASE CONSTRUTIVA UTILIZANDO APRENDIZAGEM POR REFORÇO;In this work, a hybrid method will be presented that uses the Q-learning algorithm in the construction phase of the GRASP metaheuristic. In the traditional GRASP metaheuristic, iterations are independent, that is, in the current iteration the information obtained in previous iterations is not used. The basic idea of ​​the method proposed here is to make use of the information contained in the Q-value matrix, as a kind of memory that makes it possible to repeat the good decisions made in previous iterations, and avoid those that were not interesting, thus facilitating the exploration process. /explotation.;;pt_BR;Declined;0;2011;2011-07-01 13:28:20
21393;Disraelly Hander Gurgel   Pereira;Universidade do Estado do Rio Grande do Norte - (UERN)Universidade Federal do Semi-Árido (UFERSA);Sistema de Visão Computacional para Digitalização de Sensores com Mostradores;Due to technological advances, there has been a great interest in new applications on the market, which seek innovation and cost reduction simultaneously. It is with this aim that new applications emerge to overcome this deficiency and improve the quality of these applications. It was based on this requirement that a system based on computer vision was developed for the digitization of display sensors, which will automate the process of reading a display sensor with precision and show its behavior on a computer.;;pt_BR;Declined;0;2011;2011-07-10 10:50:02
21559;Cinthia Obladen de Almendra   Freitas;PUCPR - Pontificia Universidade Catolica do Parana;Assédio Moral em Mensagens Eletrônicas no Ambiente de Trabalho: Identificação e Emoções Associadas;This article presents a method for identifying moral harassment in electronic messages written in Portuguese, as well as the emotions associated with the message texts. Moral harassment is briefly presented through its concepts and characterizing elements. The method of identifying bullying is based on a lexical ontology specially written for this purpose. The system achieved a success rate of 77.5% in real cases of bullying. Furthermore, it was found that bullying is associated with two basic emotions: disgust and anger.;;pt_BR;Declined;0;2011;2011-07-18 17:59:01
21560;Fernanda Francielle de Oliveira   Malaquias;Universidade Federal de Uberlândia;Sistema de Gerenciamento de Workflow baseado em Redes de Petri e Algoritmos Genéticos;In order to face new challenges, companies have adopted technological tools that allow them to deal with information efficiently. The development of Workflow Management Systems (SGW) has been particularly important in this context. However, for the implementation of these systems to be successful, companies need to invest both in the appropriate modeling of their business processes and in the use of optimization techniques for scheduling tasks in real time. Given this, this article aims to propose an SGW that is based on Petri nets for the formal modeling of processes, and on Genetic Algorithms, for the real-time scheduling of the modeled processes. Furthermore, the proposed SGW has a 3D interface that aims to assist managers in the decision-making process.;;pt_BR;Declined;0;2011;2011-07-18 18:07:28
22005;Kleyton Pinto   de Almeida;;METAHEURÍSTICA GRASP COM FASE CONSTRUTIVA UTILIZANDO APRENDIZAGEM POR REFORÇO;In this work, a hybrid method will be presented that uses the Q-learning algorithm in the construction phase of the GRASP metaheuristic. In the traditional GRASP metaheuristic, iterations are independent, that is, in the current iteration the information obtained in previous iterations is not used. The basic idea of ​​the method proposed here is to make use of the information contained in the Q-value matrix, as a kind of memory that makes it possible to repeat the good decisions made in previous iterations, and avoid those that were not interesting, thus facilitating the exploration process. /explotation.;;pt_BR;Declined;0;2011;2011-07-28 13:08:16
22321;Kiran   Mantripragada;IPT - Instituto de Pesquisas Tecnológicas do Estado de São Paulo;Análise do algoritmo de reconhecimento de objetos em imagens baseado na Transformada de Características Invariantes a Escala;Since it was proposed by Lowe in 1999, the so-called Scale Invariant Feature Transform, which in this article will be designated by the original acronym SIFT (Scale Invariant Feature Transform), has been widely used in the construction of object recognition algorithms in images. . Despite its wide use, the literature is reticent in providing information about the influence of SIFT parameters and the geometric and photometric characteristics of images on the performance of object identification algorithms based on this technique. Aiming to identify these effects, a tool dedicated to analyzing the performance of a SIFT algorithm for identifying objects in images was built. Using this tool associated with an experimental project, systematic variations of the algorithm parameters and the characteristics of the reference image were carried out. These experiments allowed us to verify that the algorithm suffers considerable performance degradation as images are subjected to affine transformations or are affected by the presence of noise.;;pt_BR;Declined;0;2011;2011-08-11 17:13:12
22451;Marcelo Lopes   Kroth;Universidade Federal de Santa Maria;Serviço de Colaboração para a Arquitetura ClinicSpace;Ubiquitous or Pervasive Computing is a new paradigm that aims to provide information and communication technology anywhere, accessible by anyone, available all the time, where computing resources must be integrated into the physical environment in a transparent way. One of the areas of research on pervasive computing infrastructure is related to clinical environments, due to the characteristics of mobility, interruption and collaboration. Within this context, the ClinicSpace project, under development at GMob/UFSM, uses the concepts of Pervasive Computing to assist doctors in carrying out their tasks in a hospital environment. The objective is to allow doctors to personalize the execution of their tasks, which are managed by a computational infrastructure in a pervasive environment. This article presents the Collaboration Service created to support asynchronous collaboration through the delegation of tasks that have not yet been completed, in an integrated way with the ClinicSpace architecture. A performance analysis was carried out after the modifications made and the conclusion was that, after the introduction of a caching mechanism for the tasks, the changes in the architecture maintained performance when executing applications in the pervasive environment.;;pt_BR;Declined;0;2011;2011-08-17 11:39:57
22575;Renata Alves   Campos;Universidade Federal Rural do Rio de Janeiro;Handoff na passagem de serviço: Problemas de comunicação na passagem de serviço – foco: Hospitalar;Service passes are common in many areas that work with shift changes such as hospitals, air traffic control, oil platforms, prisons, software development, among others. These transfers of information from one person to another are crucial to the effective performance of the work team, but they are often considered a way to introduce errors, risks and inefficiencies, which can lead to disasters. This motivated the investigation looking for failures during the service handover. Making appropriate sense of information during work transition is key to efficient shift change. This work aims to examine the different existing types of service passage, defining criteria to better support them with the use of technologies so that this information is used efficiently, providing better human-information interaction. For this work, the Hospital setting was chosen where data for the research will be collected.;;pt_BR;Declined;0;2011;2011-08-22 14:26:12
22607;Mário   Leite;Universidade de Uberaba (UNIUBE);SciLab - Uma opção de ferramenta para auxílio nas tomadas de decisão;Although there is already a huge range of modern calculators on the market that provide various types of functions, they cannot be considered computational tools in the broadest sense of the word. A numerical computing tool, working in a computational environment that provides the user with precise answers and that generates management information for decision making, cannot be considered just another “good calculator”, it is much more than that. In companies where correct decision-making becomes crucial elements even for their survival in the market, a tool of this type is essential. A great alternative numerical computing tool to assist in decision making (free and open source) that can be downloaded for free from the Internet and used freely without the need to pay royalties is, without a doubt, SciLab (Scientific Laboratory. This tool was created in 1990 by the Institut de Recherche en Informatique et en Automatique - INRIA - through the MÉTALAU Project (Méthods, algorithms et logiciels pour l'automatique) and by the Ecole Nationale des Ponts et Chaussées - ENPC -.;;pt_BR;Declined;0;2011;2011-08-24 11:40:57
22819;Barbara, Chirstiano, Evelyn Magalhães, Grieco, Neves   Karina, Philipe;Faculdade Pitagoras;Soluções de Segurança no Ambiente Corporativo;This work aimed to carry out a study on security solutions in the corporate environment. The growth of problems due to lack of security is constant, companies that have information systems must prioritize, in their strategies, the concern with preventing these problems. The corporate environment needs to be prepared, as in reality no system or service is 100% secure, what exists are several security measures that, implemented in conjunction with a product, will reduce the risks of these problems. Every day, more and more people access computer networks, the most popular of which is the Internet. Shared computer networks have several security problems. This work includes solutions such as Firewall, Proxy and Security Policies, explaining how they work and how it is possible to protect computers without weakening any access to data for internal and external attackers. It is important to emphasize that a security policy is not intended to hinder people, but rather to protect and support the company's needs. It should not be forgotten that there are no completely secure systems and that relative security cannot be achieved in a short space of time or without the appropriate techniques, which are generally expensive.;;pt_BR;Declined;0;2011;2011-09-02 13:13:43
22864;Michelle Denise   Leonhardt Camargo;Universidade Federal do Rio Grande do Sul;Apresentando um Modelo de Objetivos Ocultos de Comunicação Baseados em Facetas de Personalidade para Comunicação Afetiva em Agentes Conversacionais Incorporados;Embedded Conversational Agents (ECAs) are software entities that communicate in natural language and have a representation. Their goal is to exhibit human-like behavior in the way they communicate. Developing an ECA therefore requires understanding that aspects such as personality, emotions and appearance are extremely important. This work seeks to increase credibility in such agents through the use of personality as a central point of interaction between humans and agents. A model is proposed that relates personality facets to hidden communication goals that influence an ECA's attitudes. The article also describes the application of the model to agents that interact in a “puzzle” style game.;;pt_BR;Declined;0;2011;2011-09-05 17:14:15
23028;Rubens   Barbosa Filho;Universidade Estadual de Mato Grosso do Sul;Desenvolvimento de um Equipamento de Detecção e Localização On-Line de Furtos de Cabos e Equipamentos Elétricos.;The problem of theft of copper and aluminum cables, as well as electrical system equipment in general, has transcended the initial thefts that occurred mainly in neutral cables in the electrical energy distribution networks. The problem of this type of theft has become widespread globally, where, currently, even in advanced countries such as the United States and Japan, an annual loss of more than a billion dollars is estimated from the theft of copper cables alone. This work presents an alternative towards eradicating the theft of cables and electrical equipment. The development of online theft detection equipment based on GPRS data transmission technologies, Radio Frequency identification technologies and the implementation of a multi-thread specialist server in open functional language is presented. This detector equipment comprises an electronic circuit that is installed in equipment and/or cables, and communicates in real time with a centralized receiver, indicating the integrity and functioning of the protected equipment or cable. Tests are carried out to verify the validation of the concept.;;pt_BR;Declined;0;2011;2011-09-13 23:17:57
23676;Raquel   Dias;Pontifícia Universidade Católica do Rio Grande do Sul;Otimizando Simulações Estatísticas da Evolução Humana em Arquiteturas Multicore;Statistical model simulations have been used to validate theories about events that occurred in the past of species evolution. Studies on human evolution are important to understand our history and biodiversity. However, these approaches involve simulations of complex statistical models, resulting in high computational costs. This article proposes an optimization technique using Hyper-Threading to improve the computational performance of simulations. Our technique improved simulation performance by more than 30% compared to common parallel execution (standard parallelization applied by users). Performance was evaluated using a complex example of studies on human evolution [1]. For this example, our techniques reduce the execution time from 50 days (sequential execution time) to less than 5 execution days. Furthermore, the evaluation was extended to simulations on multiple nodes in a cluster. The tests show a high speed-up, close to the theoretical maximum, 139 times faster for 160 computing cores.;;pt_BR;Declined;0;2011;2011-10-11 16:51:15
23937;Giovana Angélica   Ros Miola;Faculdade de Tecnologia de Presidente Prudente;TECNOLOGIA DA INFORMAÇÃO COMO MECANISMO PARA A GESTÃO RURAL;Currently, the evolution of Information Technology resources is very intense, whether for hardware or software, which means constant changes are necessary. Thus, the objective of this work is to present the integration of technologies for the construction of an Information System for the web, developed to manage socio-economic data collected from owners of rural properties in the Municipality of Álvares Machado-SP, which allows the visualization of maps themed. The materials used to develop the system were: socio-economic data, georeferenced vertices, Eclipse as a development environment, GeoServer as a server for editing and sharing geographic data, Tomcat as a web server for Java technologies such as Servlet and JSP, Hibernate and Spring frameworks as facilitating means of implementation, PostGIS as support for geometric data, being an extension of PostgreSQL as a relational database and the OpenLayer, CQL, OL4JSF, SDL tools used to manipulate spatial data. The system provided knowledge of the rural reality, which enables efficient territorial management, offering means to facilitate the identification of properties within the municipality in a visual and textual way to assist rural public management in decision-making, and other applications can also be added .;;pt_BR;Declined;0;2011;2011-10-25 9:01:37
23944;Kristiane Silva Vasconcelos de Pina   Adorno;UNIVALI;Jogo Educativo para Apoiar a Aplicação das Áreas de Processos do CMMI-DEV: Níveis de Maturidade 2 e 3;Process improvement is approached as an agent that increases the quality of software products, reduces the costs and time of development projects and also increases companies' productivity. The process improvement learning process can be motivated with the use of games, given their close relationship with the construction of knowledge. Playfulness makes it possible to develop cognitive skills and is a technique recognized in the field of education for facilitating the learning of concepts, allowing difficulties to be perceived and encouraging discussions in order to discover solutions to overcome them. To this end, a board game was built based on the CMMI-DEV reference model, considering maturity levels 2 and 3, to be used as a complement to traditional process improvement training. This work presents the results of an evaluation of the use of the 123SPI game in an educational environment through experiments with a group of professionals, working in software development organizations and undergraduate and specialization students in IT, in order to demonstrate the benefits of using the game as a complement to traditional training, comparing those who used and did not use the game.;;pt_BR;Declined;0;2011;2011-10-28 11:04:51
23952;Fábio A. Procópio de   Paiva;Instituto Federal do Rio Grande do Norte - IFRN;Uma Pesquisa dos Sistemas de Recomendação na WUM;Every day, a huge number of pages are published on the Web and, consequently, the difficulty faced by users in locating them is increasing. The challenge, then, is to facilitate this location and, above all, select only information that is, in fact, relevant. Therefore, there is a clear need for users to use personalized mechanisms that present adequate information, make coherent recommendations and offer customized environments. In an attempt to offer this to countless web users, in recent years, several researches have been carried out in the areas of Web Usage Mining (WUM) and Web Personalization. In this article, we researched some approaches to web recommendation systems that are available in the literature and one of our objectives is to contribute to the work of other researchers in this area.;;pt_BR;Declined;0;2011;2011-10-25 17:04:21
24071;Ana   Cervigni;Centro de Tecnologia da Informação Renato Archer-CTI;MEDIDAS E PONTUAÇÃO DA SEGURANÇA DE APLICATIVOS DE SOFTWARE;In real life, it is often necessary to measure or transform data from complex systems into numbers, which are not possible to obtain with formal measurement concepts, for example, speed is equal to space divided by time. Measuring the security of software systems is very valuable without saying that it is useful for managing these systems and consequently protecting them. In metrology “Broad and satisfactory knowledge about a process or phenomenon will only exist when it is possible to measure it and express it through numbers.” said Lord Kelvin, in 1883. In cases where it cannot be measured due to complexity, an estimate can then be made from these data. This work aims to develop a framework to measure the security of software systems, decomposing security characteristics into measurable components necessary in software security. The difficulties begin, as "computer security" is not a well-defined term and from then on other difficulties accumulate. Defining what “security” means and how secure a system is is rarely simple. Furthermore, as software systems are increasingly complex, it is increasingly difficult to make claims about the security characteristics of systems. In this proposal, a process will be presented to measure and score security requirements using decomposition into measurable components of low complexity, thus transforming complex systems into smaller and simpler systems, thus being able to estimate properties that will help in their knowledge and measurement.;;pt_BR;Declined;0;2011;2011-10-31 13:03:45
24240;Davis Elias   Arosemena;Universidad Tecnológica de Panamá;Formación de Grupos de Trabajos para la Enseñanza de la Programación basado en Análisis Estático de Código;The use of work groups for teaching programming can be effective within the classroom, since it helps students generate and acquire new knowledge in a shorter time; however, these groups are formed without taking into account some aspects, it can cause a counterproductive effect on the teaching-learning process. This work proposes a tool for the formation of working groups based on the semantics of the source code (SOFORG). This semantics is based on metrics extracted from preferences, styles and good programming practices. All this is obtained through a static analysis of the code that each student develops. In this way, there will be a record of the students with the information extracted, this allows evaluating the best formation of work groups in a given course. Group formations are based on programming styles, abilities, peer group or with a tutor.;;pt_BR;Declined;0;2011;2011-11-10 14:26:28
24307;Bruno Antonio   Duarte;Universidade de Uberaba;METODOLOGIAS SEO: OTIMIZAÇÃO DE SITES PARA MECANISMOS DE BUSCAS;The article analyzes the importance of applying Search Engine Optimization – SEO procedures, given that the number of consumers using the internet increases considerably every day. The use of SEO methodologies is one of the factors that enable better positioning (ranking) of websites in web search engines. These are characterized as a trend on the Internet, as they focus their efforts on content analysis and information processing. It will analyze the standards that must be followed so that websites are better positioned. These standards are already widespread on the internet, but only a small portion of websites make use of them. There is also another portion of websites that partially use the methodologies, not achieving their objective, which is to have a good position. The use of SEO is simple and must be planned together with the development of the website. It is important to note that using SEO is not a guarantee of good positioning, as the search engine needs to analyze the information contained on the website. If SEO methodologies are used incorrectly, even if unintentionally, it is subject to punishment from some of the mechanisms. These methods will also be analyzed and are known as black hat SEO.;;pt_BR;Declined;0;2011;2011-11-16 21:53:43
24357;Yasmim Vasconcelos   Oliveira;Splenda Consultoria;Uma Análise Competitiva das Abordagens Relacional e Orientada a Objetos para Modelagem e Projeto de Bancos de Dados;Despite numerous publications in the literature, there is still no consensus on the most appropriate approach to be used for modeling and designing databases, especially corporate databases. In this context, this article aims to carry out a competitive analysis of the two best-known approaches: Relational and Object-Oriented. In addition, an overview of the Object-Relational approach and a discussion of the most popular Database Management Systems (DBMS) are also presented. Finally, questions that are still open are addressed and can be used to develop future work.;;pt_BR;Declined;0;2011;2011-11-21 14:30:59
24395;Mário   Leite;Faculdade de Engenharia e Inovação Técnico Profissional (FEITEP);METODOLOGIA DE DESIGN DE CÓDIGO E ARMAZENAMENTO DE DADOS: BASES PARA A CRIAÇÃO DE SOFTWARES COM QUALIDADE;Despite the great abundance of computer programs for all segments, software design is still largely deficient. Programmers and developers of commercial, scientific, educational or even gaming programs often produce systems that, despite being functional, are not necessarily correct and of quality. Many products, although efficient, do not have an adequate programming structure to withstand an increasingly competitive market. This competitiveness necessarily involves a very important issue regarding software: its maintenance. Another issue, also very serious, is the storage of data in databases, since more than 75% of all systems make intensive use of this type of file for storage. Therefore, the design of the software and the type of data storage are fundamental for a system to be considered cutting-edge, with total quality to satisfy the customer.;;pt_BR;Declined;0;2011;2011-11-23 12:34:10
24434;Belen   Bonilla;Universidad Tecnológica de Panamá;Reutilización de Diagramas de Casos de Uso: Un Enfoque basado en Ontologías y Tecnologías de Web Semántica;Software reuse is defined as the use of any type of artifact, or part thereof, previously created, in a new project. This practice has important benefits in terms of reducing costs and increasing quality and productivity in software development. Numerous approaches have been proposed, mostly aimed at reusing source code; however, reusing source code has its limitations because development technologies and platforms are constantly changing. It is necessary, then, to apply software reuse on artifacts created at higher levels of the software life cycle, such as the requirements specification. This article presents a tool for the reuse of use case diagrams through the storage of their information in an OWL ontology and the use of Semantic Web technologies.;;pt_BR;Declined;0;2011;2011-11-25 1:05:26
24733;Kiran   Mantripragada;IPT - Instituto de Pesquisas Tecnológicasdo Estado de São Paulo;Análise do algoritmo de reconhecimento de objetos em imagens baseado na Transformada de Características Invariantes a Escala;Since it was proposed by Lowe in 1999, the Scale Invariant Feature Transform, which in this article will be designated by the original acronym SIFT (Scale Invariant Feature Transform), has been widely used in the construction of object recognition algorithms in images. Despite its wide use, the literature is reticent in providing information about the influence of SIFT parameters and the geometric and photometric characteristics of images on the performance of object identification algorithms based on this technique. Aiming to identify these effects, a tool dedicated to analyzing the performance of a SIFT algorithm for identifying objects in images was built. Using this tool associated with an experimental project, systematic variations of the algorithm parameters and the characteristics of the reference image were carried out. These experiments showed that the algorithm suffers considerable performance degradation as images are subjected to affine transformations or are affected by the presence of noise.;;pt_BR;Declined;0;2011;2011-12-08 15:39:24
24788;Marcelo Alves   Franco;Faculdade de Tecnologia de São Caetano do Sul/estudante;Development of a Mobile Agent Móvel based on Java e  MuCode to Distributed Environment;This work aims to demonstrate that the mobility of code can be an alternative for the implementation of large-scale distributed systems. Mobility, being the main feature of mobile agents, is classified as low mobility (not store context) and strong (capable of storing context). The MuCode is an Application Programming Interface (API) that provides various Java primitives mobility and has among its main characteristics: small code, modular design and support compression. These characteristics favor the development of applications for devices of small sizes. In this context, a study is made to implement a mobile agent for remote playback of audio media stored in distributed servers. The result is satisfactory proving the application of Mucode in mobile distributed system that employs small devices like smart phone and Personal Device Assistant (PDA).;;pt_BR;Declined;0;2011;2011-12-11 16:18:52
24835;Mário   Leite;Faculdade de Engenharia e Inovação Técnico Profissional (FEITEP);Determinando as Datas Móveis com Ferramenta RAD em Interface Amigável;RAD (Rapid Application Development) tools define a tool model widely used in systems development in which the design/implementation period must be very short: around a maximum of ninety days. Although there are tools of this type that also generate system code, their most popular use is in relation to the system-user interface, creating high interactivity between them. An example of this type of tool is DelphiTM, which is a systems development package composed of a compiler, an IDE (Integrated Development Environment) and a programming language based on Object Pascal. This article presents an application based on DelphiTM, to calculate the so-called Moving Dates of the Gregorian calendar. The application is very simple, but very functional and highly interactive with the user, showing the practicality of RAD tools.;;pt_BR;Declined;0;2011;2011-12-14 11:31:51
24845;Irapuan   Glória Júnior;Universidade Nove de Julho (UniNove);A Aplicação da Análise de Stakeholders em Projetos de Tecnologia da Informação;Companies are constantly evolving and, especially since the 90s with globalization, several IT projects have been requested. The need to identify stakeholders that influence projects can be obtained through the Stakeholder Analysis method. On the other hand, there is project management, specified by the Project Management Institute, where best management practices are applied. Using bibliographical research as a way of substantiating these aspects is the basis of this article, as well as the suggestion of a unified model and the identification of the items that influence and their impacts on IT projects are its objectives.;;pt_BR;Declined;0;2011;2011-12-20 16:58:30
24923;Roberto Angelo Fernandes   Santos;UFPE;RISKSEG: Um Método para Segmentação de Preditores;This work proposes a method for segmenting predictive models. Your goal is to combine different predictors, one for each segment of the data, in order to look for specific models that make the final combined answer more accurate. There are several ways to combine predictive methods, the most common are: Bagging, Boosting and Stacking. Data segmentation is particularly interesting because, in addition to improving the results of individual classifiers, it allows preserving some of their characteristics. Normally, data segmentation is based on the experience of experts or uses metrics to separate the classes to be predicted (entropy, for example), as is done in Decision Tree training. The proposed method segments the database into exclusive samples in a model tree. The results of the experiments show that the proposed method has several advantages over other classifier combination methods.;;pt_BR;Declined;0;2011;2011-12-18 2:24:51
24985;Julio C.   Furtado;Universidade Federal do Pará - UFPA;Experimentação de Uso da Ferramenta Spider-ACQ: Um Relato de Experiência;Acquisition is a process that is concerned with ensuring the quality of the product or service purchased, that is, ensuring that it is suitable for the needs raised by the acquiring organization. It is necessary, therefore, for organizations acquiring their needs to aim for a mature acquisition process, based on good practices and recommendations in the area. Therefore, this article reports the experimentation on the learning support provided by the Spider-ACQ tool, with this tool aiming to support the execution of acquisition projects based on quality models.;;pt_BR;Declined;0;2011;2011-12-21 17:44:14
25151;Leonardo Bisch   Piccoli;UFRGS;Desenvolvimento de uma Plataforma Web para Contabilização e Gestão de Contas dos Serviços de PAD;With the growth in access to PAD services and the consequent increase in computational demand, there is a need to develop a system, which is proposed in this article, to evaluate the performance of an organization, structure mechanisms capable of promoting improved management of quality, system auditability and efficiency of internal processes. The Account Management proposal allows for gains such as centralized visualization of resource appropriation, navigability, among others. Another result is the use of tools that can work integrated with the platform in management and control and that have no license cost.;;pt_BR;Declined;0;2012;2012-01-03 17:09:48
25173;Thiago   Ribeiro;Grupo Educacional Uninter/Fatec Internacional;VARIÁVEIS ECOLÓGICAS NA ELABORAÇÃO DE UM JOGO EDUCACIONAL AMBIENTAL;This article seeks environmental education, the interdisciplinarity of pedagogical processes and digital technology to base urban awareness in relation to the environment on both ecological principles and digital simulatory processes. In this sense, the idea of ​​listing ecological variables in the development of an environmental educational game is sought. Having a simulative strategic character, we will lead the user to understand the importance of environmental processes in urban management, as ecologically correct cities are a milestone of good management today. In this way, it highlights important issues relating to the functioning of cities and, at the same time, does not impose barriers to the imagination of each user. The idea of ​​this game is for the player to build his city, taking as a backdrop the municipality of Pelotas, not urbanized, where he must manage it financially and environmentally, taking into account the balance of finances and the lowest environmental impact in the area. addressed.;;pt_BR;Declined;0;2012;2012-01-03 19:34:06
25204;Cícero Augusto de S.   Camargo;Universidade Federal de Pelotas;A Graph Grammar to Transform a Dataflow Graph into a Multithread Graph and Scheduling Studies;The scheduling of tasks in a parallel program is an NP-complete problem, where scheduling tasks over multiple processing units requires an effective strategy to maximize the exploitation of the parallel hardware. Several studiesfocus on the scheduling of parallel programs described into DAGs (Directed Acyclic Graphs). However, this representation does not describe a multithreaded programsuitably. This paper shows the structure and semantics of a DCG, an abstraction which describes a multithreaded program, and proposes standards to map structures found inDAGs into segments of a DCG. A graph grammar has been developed to perform the proposed transformation and case studies using DAGs found in the literature validatethe transformation process. Besides the automatic translation and precise definition of the mapping, the use of a formal language also allowed the verification of the existence and uniqueness of the out coming model.;;pt_BR;Declined;0;2012;2012-01-05 15:33:08
25429;Clávison Martinelli   Zapelini;Universidade do Vale do Itajaí;Medição da Intensidade da Dor com a Utilização de Redes Bayesianas;Pain is subjective and personal, and knowing the intensity of the pain a person is feeling makes it possible to adapt the necessary medical interventions, so as not to overmedicate them or allow them to remain in pain. This article presents a proposal to measure the intensity of pain in human beings, based on the development of a computational system, based on Bayesian Networks, which is capable of analyzing data from biomedical signals, in addition to other variables related to pain. With the certainty of the occurrence of any variable, the computational system makes the inference to probabilistically measure the intensity of the pain that the person is feeling. Pain was simulated by immersing the arm in ice of people communicating verbally and analyzing the biomedical and emotional changes that occurred as a result. From the comparison between the responses on the analogue pain scales and the results presented, a causal network was modeled and probabilistic values ​​were established. The results obtained proved the efficiency of the Bayesian Network to infer pain intensity, however, for greater probabilistic representation, a sample with a larger number of participants is necessary.;;pt_BR;Declined;0;2012;2012-01-19 10:01:11
25726;Antonio Pires   de Almeida Junior;Universidade Estadual de Maringá;Uma metodologia de Gerência de Projeto no Desenvolvimento de Sistemas Web em Ambiente Geograficamente Distribuído;The development of Web software becomes more complex when the software development occurs in a geographically distributed environment, called Distributed Software Development (DDS). In these systems, the people who participate in the project are geographically separated. DSD brings communication difficulties due to cultural differences and geographic distances. This entire scenario contributes to the development of a project management methodology, which operates in the development of Web systems in a geographically distributed environment, making it possible to meet the diverse requirements of a project. This work presents a proposal for developing a methodology for managing web projects in a distributed environment. The methodology contains the items: Human Resources Management, Costs and Risks, Feedback and documents to assist in project management using the methodology.;;pt_BR;Declined;0;2012;2012-02-02 15:11:32
25749;Fabrício de Novaes   Kucinskis;Instituto Nacional de Pesquisas Espaciais (INPE);Uma Arquitetura de Software Embarcado em Satélites para a Operação de Missões Baseada em Objetivos;This article presents a satellite-embedded software architecture, developed to enable the operating paradigm of objective-based space missions. In this new paradigm, the satellite receives objectives to fulfill, instead of sequences of commands. It is up to him to replan his tasks and determine the best way to achieve his objectives. A case study for a mission from the National Institute for Space Research (INPE) was created and executed on a prototype satellite onboard computer. The study is summarized in this article, accompanied by performance data.;;pt_BR;Declined;0;2012;2012-02-03 23:42:29
25812;Murilo Oliveira   Machado;Universidade Federal do Rio de Janeiro;Um modelo nebuloso para compensar a deriva de aves migrantes;﻿ This paper describes a new fuzzy simulator capable of compensating for the drift of migrant birds at high altitudes. The simulator presented here has been used to predict the adjustment of direction and speed depending exclusively on the direction of the coplanar winds found in its migratory journeys, of a bird of the species, Apus apus, normally migrating at night. The focus of this computational model is to show the robustness of a fuzzy model in representing the strategy chosen by a bird in seasonal migration. For comparative purposes, the mathematical model proposed by Felix Liecht will be used, for the optimal adjustment of direction and speed depending on wind direction and energy costs, as well as the equation of motion obtained here via the Lagrange formalism. In validating this computational model, the simulated measurements will be correlated with the measurements found and published by Håkan Karlsson's work, Compensation for wind drift by migrating swifts 2010, obtained from observations in nature. In this way, the robustness of this fuzzy model in simulating the compensatory behavior in the seasonal migration of nocturnal birds is demonstrated.;;pt_BR;Declined;0;2012;2012-02-07 2:28:25
25892;Antonio Carlos   Vilanova;Instituto Federal de Educação, Ciência e Tecnologia de Mato Grosso - IFMT;Frequência e Altura Otimizadas por Algoritmo Genético em um Modelo de Propagação Terrestre;This work presents a methodological evaluation to optimize parameters in a well-known radio wave propagation model in the troposphere. The propagation model is based on the Fourier Step Divider to solve parabolic equations. Our approach uses a genetic algorithm to determine parameter values ​​that maximize field strength at a given observer position. Using a genetic algorithm, the time required to search for optimal parameters is significantly reduced. Preliminary evaluation of the results through simulation shows that our approach is promising.;;pt_BR;Declined;0;2012;2012-02-10 18:19:18
25909;Carlos dos Santos   Portela;Universidade Federal de Pernambuco;xSPIDER_ML: Uma Proposta de Linguagem para Execução de Processos de Software aderente ao Padrão SPEM 2.0;Although SPEM (Software & Systems Process Engineering Meta-Model) is the modeling standard established by OMG (Object Management Group), it has many shortcomings when it comes to process execution. This article presents a critical analysis of this SPEM approach to process execution. It then presents a proposal for executing software processes modeled from SPEM 2.0 using a language called xSPIDER_ML. Finally, it presents a case study based on the use of the elements and rules of this language in the execution of a RUP (Rational Unified Process) process.;;pt_BR;Declined;0;2012;2012-02-13 18:57:22
25979;Joao Porto de   Albuquerque;Universidade de Sao Paulo;Educação em Sistemas de Informação no Brasil: Uma Análise da Abordagem Curricular em Instituições de Ensino Superior Brasileiras;Bachelor of Information Systems (BSI) courses emerged in the 1980s in Brazil and have expanded considerably since then. Being a relatively recent academic training in the country, it is necessary to investigate the structures/curricular matrices of these courses, mainly taking into account the prescriptions/indications of scientific societies in the area and the demands of the job market. In this sense, this article has the general objective of developing an analysis of the curricular approach of BSI courses offered in higher education institutions (HEIs) in Brazil, using a sample of 50 BSI courses offered by HEIs in the country, whose selection procedure prioritized courses of regional and/or national relevance proven by quality indicators. One of the main findings of this work is that the curricular matrices of BSI courses in Brazil differ largely from the guidelines defined by the Brazilian Computing Society in relation to the thematic emphases of its set of disciplines. In addition, there is little emphasis on disciplines related to specific training in the IS area, which points to a certain lack of definition in the identity of these courses in Brazil. Bachelor of Information Systems (BSI) courses emerged in the 1980s in Brazil and have expanded considerably since then. Being a relatively recent academic training in the country, it is necessary to investigate the structures/curricular matrices of these courses, mainly taking into account the prescriptions/indications of scientific societies in the area and the demands of the job market. In this sense, this article has the general objective of developing an analysis of the curricular approach of BSI courses offered in higher education institutions (HEIs) in Brazil, using a sample of 50 BSI courses offered by HEIs in the country, whose selection procedure prioritized courses of regional and/or national relevance proven by quality indicators. One of the main findings of this work is that the curricular matrices of BSI courses in Brazil differ largely from the guidelines defined by the Brazilian Computing Society in relation to the thematic emphases of its set of disciplines. In addition, there is little emphasis on disciplines related to specific training in the IS area, which points to a certain lack of definition in the identity of these courses in Brazil.;;pt_BR;Declined;0;2012;2012-02-16 10:58:04
26033;Fabrício Jailson   Barth;Faculdade de Tecnologia Bandeirantes;Uma introdução ao tema Recuperação de Informação;The topic of Information Retrieval has always been a widely explored topic in academia and the market. The way in which academic events are conducted demonstrates a very high maturity in the area, including a very strong connection with the market. Numerous books on this topic have already been published. However, there are few books published in Portuguese. This tutorial attempts to fill this gap by presenting an introduction to the topic of Information Retrieval, covering: the main definitions and concepts of the area, the main models that govern the development of Information Retrieval Systems, and the methods usually used in the evaluation of Retrieval Systems of information.;;pt_BR;Declined;0;2012;2012-02-17 20:57:51
26096;Yandre Maldonado e Gomes   Costa;Universidade Estadual de Maringá;Preservação de Informação Local na Extração de características de Textura de Espectrogramas para o Reconhecimento de Gêneros Musicais;This article describes results obtained in experiments aimed at recognizing musical genres using spectrogram images extracted from musical titles taken from the Latin Music Database. Previous work described in the literature indicated the potential for obtaining good results using texture features extracted from spectrograms. However, many questions remained open and based on them, experiments were developed using multiple classifiers created from the zoning of spectrogram images. In the best case, a recognition rate of 70.78% was achieved, a rate approximately 10% higher than the best case in previous results, in which multiple classifiers were not created. For the extraction of texture features, the Gray Level Co-occurrence Matrix was used, a statistical approach successfully used in different application domains. Additionally, the “artist filter” was used in the experimental protocol. As a result, correct classification tends to be more difficult and the classifier produced is more robust.;;pt_BR;Declined;0;2012;2012-02-24 12:20:26
26108;Eduardo   Lopes;Universidade de Évora;A Quantification of the Rhythmic Qualities of Salience and Kinesis;From a cognitive point of view, it is easily perceived that some music rhythmic structures are able to create saliences (i.e. pulses perceived as louder). Depending where in a metrical grid these salient pulses are located, a sense of stability or instability will arise. When instability is present in a rhythmic structure one will tend to psychological feel kinesis (i.e. a sense of motion). Salience and kinesis can then be identified as basic rhythmic qualities. Inspired by the theoretical construct Just in Time - an empirical based music theoretical construct for the analysis of rhythm - we decided to quantify some of its analytical output more specifically the measure of salience and kinesis of a rhythmic sequence. We then developed a web-based tool that calculates the amount of salience and kinesis for a particular rhythmic sequence. We conclude this article pointing how this tool can be used in analysis and music education as well as other possible applications, and future research.;;pt_BR;Declined;0;2012;2012-02-26 6:29:46
26262;Francisco   Miranda Soares da Silva Neto;Centro de Informática - UFPE;Hamster: an AOP solution for Fault Tolerance in grid middleware;Grid computing is useful in several organizations, from research endeavors in parallelizing algorithms, to serving as a backbone to cloud computing platforms. However, grid computing infrastructures are still liable to faults which, depending on the application being executed, might have serious consequences. In this paper we present Hamster, a software architecture that attempts to maximize resource usage by monitoring grid middleware components and making them capable of recovering from failures. We present the aspect-oriented implementation of Hamster. It extends the OurGrid grid middleware, making it capable to recover from a number of failure scenarios that would otherwise halt the execution of an entire grid. In addition, our implementation of Hamster is pluggable and reusable we integrated it with four different versions of OurGrid without modifying the latter. We evaluate memory and CPU consumption of the solution using both load-time-weaving (LTW) and source-code-weaving (SCW). The SCW solution imposes an acceptable memory and CPU consumption overhead, differently from LTW that shows a massive use of both.;;pt_BR;Declined;0;2012;2012-03-06 23:25:31
26292;Fernando Parra dos Anjos   Lima;UNESP - Universidade Estadual Paulista "Júlio de Mesquita filho", Departamento de engenharia elétrica, Faculdade de engenharia de Ilha Solteira.;Sistema computacional em Delphi 7.0 para o reconhecimento de padrões de som com uma rede neural artificial de Kohonen;The objective of this article is to use a neural network to recognize and classify sound patterns with the Delphi 7.0 application. Specifically, DTMF (Dual Tone Multi Frequency) tones are used, [9], or rather, the sound signals from the telephone keypad. This work presents a methodology for recognizing sound patterns with a Kohonen neural network, or as they are also known, Kohonen self-organizing maps. [5], [6]. With the method proposed in this article, tests are carried out with sound patterns known and unknown by the system in the training process in order to investigate and analyze its performance in the task to be performed. Modifications to the structure of the neural network are also proposed to verify possible improvements in results.;;pt_BR;Declined;0;2012;2012-03-08 8:29:13
26402;Paulo Afonso   Parreira Júnior;Departamento de ComputaçãoUniversidade Federal de São Carlos;Um  Estudo  da  Eficiência  de  Técnicas  de  Mineração  de  Interesses;Interest  mining  is  an  activity  that  aims  to  discover  and reveal  potential  interests  existing  in  the  systems. It  is  widely used  during  the  maintenance  phase  of  information  systems, especially  when  the  objective  is  to  understand  the  structure  of  these  systems  and reimplement  them  in  new  programming  paradigms. Currently,  there  are  many  techniques  for  mining  interests,  mainly  those related  to  the  identification  of  transversal  interests,  interests  that  are  not  completely  modularized  using  only  object  orientation,  but  it  is  possible  to  observe  the  scarcity  of  studies  on  these  techniques  with  a  quantitative focus. This  article  presents  the  planning and  execution  of  an experiment that evaluates the efficiency of two techniques “type and text analysis” and “exploratory  analysis”. The  type  and  text  analysis  technique  showed better  efficiency  than  the  exploratory  analysis  techniques,  however  both  techniques  presented  unsatisfactory  results  in  relation  to  the  incidence  of false positives and false negatives.;;pt_BR;Declined;0;2012;2012-03-13 19:49:59
26799;Beatriz   Wilges;Universidade Federal de Santa Catarina/Pós-Graduação em Engenharia e Gestão do Conhecimento;Um estudo comparativo entre soluções serializadas e paralelizadas para a etapa de pré-processamento de texto de um sistema CADT;This work presents a comparison between a serialized and a parallelized solution for developing text pre-processing in an Automatic Text Document Categorization (CADT) system. The serialized implementation was carried out by RapidMiner and to explore the parallelization potential, Hadoop technology was used, through the MapReduce programming paradigm. The motivation for this comparison is the exploration of a large set of text documents from the Web to build a base of categories. In the literature, solutions that adopt distributed processing in unstructured documents have shown efficient results when using Hadoop.;;pt_BR;Declined;0;2012;2012-03-29 18:12:11
26986;Mário   Leite;Universidade de UBERABA (UNIUBE) E Faculadade de Engenharia e Inovação Técnico Profissional (FEITEP);Implementação de Uma Aplicação Didática com OOP;Despite being much talked about in academic centers and systems development environments, Object Oriented Programming (OOP) technology has not been applied satisfactorily and as intensely as it should be. Perhaps due to ignorance of its real potential, or even ignorance, the fact is that OOP is still feared by many students studying Information Systems, Data Processing, Computer Science and similar courses. The objective of this article is to implement a small application in the Object Oriented Programming paradigm, demonstrating its practicality in using Inheritance and Polymorphism mechanisms, demystifying the use of this technology. From the ancestral class called TFigurePlana, three subclasses are derived: TCirculo, TQuadrado and TTriangulo, where these classes (derived) inherit the characteristics of the primitive class (TFigurePlana) and redefine the Draw(), CalcPerimeter() and CalcArea() methods, therefore, these Classes become specialized.;;pt_BR;Declined;0;2012;2012-04-04 17:05:13
27076;Renato   Ramos;Universidade Federal do Paraná;Processo de Refatoração para Identificação dos Pontos Comuns e de Variabilidade da Camada de Visão do Framework de Preço de Venda (FrameMK);This work proposes a process of refactoring the vision layer of a Desktop application to a Web platform, in which it was possible to identify the common points and variability between applications in a given domain. For the refactoring process, the Struts and Tiles frameworks were used. Struts allowed the integration of the vision layer with the business rule and persistence layers. Tiles were used to better divide common and variability points in the vision layer.;;pt_BR;Declined;0;2012;2012-04-09 23:16:45
27335;Rodrigo Luis de Souza da   Silva;Universidade Federal de Juiz de Fora;Calibração Automática de Múltiplos Marcadores em Ambiente de Realidade Aumentada;This work aims to develop an approach for Augmented Reality systems that use multiple markers for information redundancy, aiming to maintain projection stability and alignment even when some markers are occluded. The proposed approach allows such a scenario to be constructed without the need for the calibration step of the rotation and translation relationships between the markers, normally adopted in the pre-execution of this type of system. The developed method stores the relationships between visible markers and a base marker, which is responsible for dictating the transformations of the projected virtual object. Methods will be proposed to choose the base marker, among the visible markers.;;pt_BR;Declined;0;2012;2012-04-17 18:18:55
27703;Mário   Leite;Universidade de Uberaba (UNIUBE) e Faculdade de Engenharia e Inovação Técnico Profissional (FEITEP);Como Validar CNPJ e CPF;The Tutorial teaches you how to validate a CNPJ/CPF through Module 11. It shows an example of an application where the Delphi tool is used to demonstrate the theory.;;pt_BR;Declined;0;2012;2012-04-24 17:46:22
27773;Mário   Leite;Universidade de Uberaba (UNIUBE) e Faculdade de Engenharia e Inovação Técnico Profissional (FEITEP);Aprendendo Fisica com o Visual Basic;Programming languages ​​currently constitute a wide set of options in the area of ​​electronic computing, and can be classified in different ways. However, among them, there are some packages that integrate development tools that form the RAD (Rapid Application Development) type. This type of tool typically consists of a programming language on a development platform hosted with features that allow a system to be developed very quickly, creating products that are highly interactive with the end user. Among these tools, Microsoft Visual Basic stands out, known simply as VB. This tool is one of the most used around the world, and it is very easy to learn when combined with other tools of its kind, and can be used in all areas of activity, including education.;;pt_BR;Declined;0;2012;2012-04-25 17:43:59
28208;Fábio A. P. de   Paiva;Instituto Federal do Rio Grande do Norte - IFRN;Uma Visão Geral de Agrupamento de  Usuários Através de Web Usage Mining;Every day, a huge number of pages are published on the Web and, consequently, the difficulty faced by users in locating the ones that meet their needs is increasing. The challenge for web designers and e-commerce companies is to identify groups of users who have similar interests in order to personalize browsing environments that meet these interests. In an attempt to offer this to countless web users, in recent years, several researches have been carried out in the area of ​​clustering applied to Web Usage Mining. In this article, we made a comparison between some proposals that use clustering methods to group web users with similar interests. The work discussed can help companies make decisions, such as changes to website layouts and improvements to product recommendation systems.;;pt_BR;Declined;0;2012;2012-05-03 22:45:04
28438;Pedro Santos   Neto;UFPI;Requisitos para Ferramentas de Migração de Dados;This work presents a catalog of requirements associated with data migration tools. It captures the needs, desires and expectations related to users of migration tools and can be used to facilitate the work of developing new tools that assist in this process. Furthermore, the catalog can be used as a basis for comparing existing tools, facilitating the identification of products that are most appropriate for certain projects. To this end, a comparison of six tools available on the market is presented, using the developed catalog as a basis.;;pt_BR;Declined;0;2012;2012-05-11 7:43:55
29524;Luciano Tadeu Esteves   Pansanato;UTFPR;Um Modelo de Busca de Informação com Sistemas Web para Busca Exploratória;In this article, an information search model with web systems for exploratory search is proposed, called the Navigation and Exploration Model. The main objective of this model is to provide an understanding of the information search process with a focus on the interaction between the user and exploratory search web systems in order to assist the developer of these systems in deciding which computational support to offer the user. A classification of information search techniques on the Web is also presented, which is used to associate the categories of techniques with exploratory search activities represented in the model. In the interaction proposed by the model, the user devises and executes a search strategy, evaluating the results found and the strategy used, modifying or not the adopted strategy until the objectives are achieved. The proposed user-system interaction process can be seen as activity cycles involving alternating stages of execution and evaluation. During the development and evaluation of a research prototype, the concepts underlying the model were explored and tested. Furthermore, through the analysis of data collected in an evaluation of this research prototype with its potential users, some elements of the model were refined considering the knowledge acquired.;;pt_BR;Declined;0;2012;2012-06-05 16:49:17
29704;Onildo Ribeiro   de Assis II;Universidade Federal da Paraíba;Utilização do Radio Frequency Identification (RFID) como Sistema de Informação Logístico em Hipermercados;Global competition highlights the need for greater agility, efficiency and security in the flow of information, between manufacturers and distributors, throughout the supply chain. The company's adoption of an information system focused on logistics can bring benefits in productivity and quality of work, facilitating relationships with customers and suppliers. In view of the above, the objective of this article is to describe the current process of using the RFID system in the companies Pão de Açúcar, Carrefour and Wal-Mart Stores, with the justification for choosing the fact that they occupy the top of the 250 largest retailers in the world , according to the 15th edition of “The Powerful People of Global Retail”, an annual study developed by Deloitte in partnership with Stores Media. The research methodology used consisted of an exploratory multi-case study with a qualitative approach. The research was carried out by accessing company websites and publications related to them, in addition to their annual reports. Among the results, it was mainly verified that although RFID is characterized as something innovative, companies are in the initial stages of testing and obtaining the potential of this technology. However, there is confidence that the knowledge acquired so far will serve as a basis for the growth and perpetuation of RFID.;;pt_BR;Declined;0;2012;2012-06-12 15:13:23
29721;Mitchel Soni   Felske;Universidade Federal do Rio Grande - FURG;Desafios Computacionais dos Massively Multiplayer Online Games: um experimento sobre a plataforma SIM3D;In this work, a hybrid architecture is proposed to be used in the development of Massively Multiplayer Online Games (MMOGs). This model is derived from the Server Cluster architecture and aims to reduce the costs of deploying and maintaining the physical infrastructure necessary to support the game. To do this, it aims to remove some of the load from the servers, as it only updates some players, who are responsible for passing on this new information to the others. To validate the solution, an experiment was carried out on the SIM3D platform. Comparing the response times obtained between the proposed architecture and the traditional Client-Server, it was found that they were similar for players in both models.;;pt_BR;Declined;0;2012;2012-06-12 20:24:58
29727;Marcos Vinicius de Andrade   Lima;Universidade do Estado do Rio Grande do Norte - UERN / Universidade Federal Rural do Semi-Árido - UFERSA;Audiodescrição Virtual: Acessibilidade para Vídeo Produções Utilizando Voz Sintetizada;This article presents a simple and efficient proposal that allows access to video productions, which were previously inaccessible, to people with visual impairments: virtual audio description. Virtual audio description is a technique that uses software that combines and synchronizes a text file containing descriptions of a given work with voice synthesis, facilitating understanding when there is no dialogue between characters, similar to what occurs in the traditional audio description process. A difference is that in addition to being able to choose the type of synthesized voice that suits them best, the user can count on the support of virtual communities to describe the most varied titles, making them quickly accessible and adapting them to Federal Decree No. 5,296 of December 2, 2004. As a result, ADVplayer was developed, a tool that allows the display of video productions using virtual audio description technology. Tests with visually impaired users showed a high level of acceptance, showing that Virtual Audio Description pleased the majority of participants and that the idea is promising. The first results were the development of a tool (ADVplayer), the audio description of a series episode and the beginning of the construction of a collaborative website for this proposal.;;pt_BR;Declined;0;2012;2012-06-12 23:44:37
29906;Leonardo Bisch   Piccoli;UFRGS;Modelamento de objetos reais através de linguagem VRML e visualização com Realidade Aumentada;This work presents the development of a methodology for modeling real objects using VRML language and visualization with Augmented Reality - RA through a case study of the Sun Fire cluster at CESUP at UFRGS. The necessary steps are presented with a detailed description and use of the files produced in an AR application. To make the content available on the CESUP website, a personalized marker was developed, an executable was compiled from the ARToolkit library and a tutorial was created to guide users with the procedures for visualizing the cluster in AR. The experiments show that modeling real objects using the VRML language allows reducing the complexity of objects with many details and that the quality of the generated files is strongly dependent on photos that are representative of the views to be shown. Compared to software that only visualizes files with the wrl extension, the use of AR proved to be a computational resource that allows users to interact more with the content.;;pt_BR;Declined;0;2012;2012-06-19 14:18:39
30466;Felipe Alves da   Louza;Universidade de São Paulo;Estruturas de indexação para casamento exato de sequências biológicas;The exact matching of biological sequences plays an important role in similarity searches, acting as a filter in the sequence alignment step. This article aims to investigate indexing structures for the exact matching of biological sequences, focusing on the suffix tree and suffix vector indices. Furthermore, suffix bitmap, a new index for exact matching based on bitmap index, is proposed in this paper. The comparative analyzes carried out highlight the advantages and disadvantages of the three indexes in relation to the construction and query stages in the indexing of biological sequences.;;pt_BR;Declined;0;2012;2012-07-05 16:34:08
30495;Juan Sebastian   Beleño Diaz;Universidad Industrial de Santander;Computing logarithms using binary search;This work shows an interesting and new way to solve the logarithm problem over positive integers, using the binary search algorithm and another fast algorithm such as fast exponentiation. This work does not use Taylor series or logarithm tables.;;pt_BR;Declined;0;2012;2012-07-06 23:34:15
30875;Alexandre Rodizio   Bento;Faculdades Santa Cruz;A Utilização da Tecnologia da Informação Aplicada Como Suporte a Link MPLS;Information technology is constantly evolving and professionals must follow this evolution to achieve professional career growth. Multiprotocol Label Switching (MPLS) technology is one of the technologies that stands out in the global market and is used by companies that want to always be connected. In this context, this work presents the migration of the MPLS link of a company with several branches that seeks greater availability in data traffic. The MPLS link migration is presented step by step, which is carried out in an effective and transparent way, using the concept of static routes. The results of this migration enable greater security, agility and flexibility in data traffic at a reduced cost.;;pt_BR;Declined;0;2012;2012-07-23 11:56:34
31193;Marcus Vasconcelos de   Castro;UNINOVE;Uso de jogo computadorizado para melhorar o nível de conhecimento aritmético de crianças com desempenho escolar inferior.;Traditional educational methods applied in the teaching process prove to be insufficient for children who have not reached the normally expected learning levels. Therefore, the game presented aims to improve the level of arithmetic knowledge of children with lower academic performance through playful methods that can involve them, so that they acquire through play the knowledge considered necessary for their age group, improving their self-esteem, and helping their inclusion in the classroom. A testing method was carried out to check the learning level of a group of children. The results showed that there was an improvement in the children's performance in terms of arithmetic knowledge and the children demonstrated enthusiasm when using this game.;;pt_BR;Declined;0;2012;2012-08-06 17:18:08
31236;Jean Felipe   Felsky;Pontificia Universidade Católica do Paraná;A Geometria Fractal na Atribuição de Autoria de Manuscritos;Attributing authorship of a manuscript is one of the many activities carried out by experts in carrying out expertise aimed at elucidating issues relating to a legal claim. Graphoscopy, the science that establishes the standards of expert practice in manuscripts and signatures, offers the base set of metrics for any method intended for this purpose. As in other areas of knowledge, computing has been offering important resources for the assisted execution of this activity over the last few decades. The main objective, in this case, is to offer stable computational metrics, from the perspective of graphoscopy, that can be used to associate or dissociate authorship. Therefore, this article presents an approach based on Fractal Geometry, in establishing such metrics. To validate the studies carried out, two manuscript databases were used, one national, with texts in Portuguese and another international, with texts in English. The results presented by the proposed method were promising, thus providing an additional set of characteristics that can be used with stable measurement elements for this purpose.;;pt_BR;Declined;0;2012;2012-08-08 9:53:51
31313;Rodrigo Duarte   Seabra;Centro Universitário Filadélfia - UniFil;Considerações sobre Interfaces 3D: Uma Abordagem sobre a Ótica do Projeto de uma Ferramenta Inovadora de Realidade Virtual para o Ensino de Geometria;Although a wide variety of devices and interaction techniques in virtual environments are available, designing a 3D interface represents a challenging step in the development of Virtual Reality systems. The main difficulty lies in selecting the most appropriate devices for the user interaction process, mainly due to the lack of a standard methodology for the design and construction of spatial interfaces. This work aims to present the 3D interface design of an innovative teaching tool to support the teaching of geometry based on Virtual Reality techniques, especially stereoscopy. The solution achieved is a low-cost and viable alternative for use by large groups. A group of subjects were subjected to experimental research and the data collected in the qualitative evaluation of the tool indicated that there was better acceptance of the system by students, compared to conventional teaching methods. The results showed that the technology used in the design of the solution presents itself as an alternative to be explored in the classroom, contributing to the learning of the topic.;;pt_BR;Declined;0;2012;2012-08-09 17:05:11
31356;Shirlei Magali   Vendrami;;Proposta de um mecanismo de busca baseado na web semântica para objetos de aprendizagem no domínio da Matemática;In this work, an ontology for Mathematics OAs is proposed as support for a search mechanism developed during this work. The ontology was developed in the Protégé tool, using the OWL language (Web Ontology Language) and the concepts for it were based on the National Curricular Parameters, a document made available by the MEC. From the comparison between the defined metrics, results were obtained to evaluate the use of an ontology in the search engine to obtain more relevant results in less time. The results obtained proved the efficiency of this form of research for OAs, which allows its use by the school community.;;pt_BR;Declined;0;2012;2012-08-12 22:54:41
31467;Lívia Naiara   Andrade;Universidade Federal de Lavras;Aplicação de Redes Neurais Artificiais na Identificação Automática de Áreas Cafeeiras na Região de Três Pontas-MG;Coffee growing is an activity of fundamental importance in the southern region of the state of Minas Gerais, Brazil. Techniques for estimating the planted area, aiming at reliable harvest forecasts, are being intensely researched. This study presents an application of Artificial Neural Networks (ANNs) for the automatic classification of remote sensing data, with the objective of identifying coffee growing areas in the region of Três Pontas, South of Minas Gerais. A complicating factor is the high similarity of the coffee's spectral pattern with native forest areas. To improve the performance of the implemented system, masks were created in the drainage network and in the urban area. The result of the classification carried out by ANN was superior to the results found in the literature, obtaining a Kappa index of 0.69.;;pt_BR;Declined;0;2012;2012-08-15 11:09:35
31549;Luciano Jose   Senger;Universidade Estadual de Ponta Grossa;Framework para computação distribuída em redes P2P com suporte a passagem de mensagens;This paper presents a framework for developing and executing parallel and distributed applications using the peer-to-peer computing model.The framework - called P2PComp - follows the pure peer-to-peer model, since there is no hierarchy among the peers, all peers have the same functions and there is no central authority server responsible for the system organization.  SPMD parallel applications can be implemented by extending the framework functionalities, which includes functions for starting and monitoring processes, searching resources and communicating by message passing.  This paper presents a detailed description of the framework and examples of its utilization for building and executing parallel applications. The results obtained show that the framework can be effectively used for executing computational programs in a flexible peer-to-peer environment.;;pt_BR;Declined;0;2012;2012-08-16 9:41:43
31696;José Luiz   Silveira;UNIVALI;SPI City: Jogo Educacional para Apoiar o Ensino de Melhoria de Processo de Software com Foco no Nível G de Maturidade do MPS.BR;Research has shown that the main difficulty in implementing software process improvement is related to the competence of the team at the company where the improvement is being implemented. The main difficulties stand out as the lack of knowledge about the basic techniques of Software Engineering and the lack of understanding in software process capability models. These difficulties show the importance of establishing appropriate training strategies for those involved in improvement initiatives. This article presents a game developed, in digital media, to support software process improvement training, which simulates day-to-day situations in software development companies in which the expected results of MPS.BR are explored. The game developed was evaluated through experiments that made it possible to prove that it helps in learning how to improve software processes.;;pt_BR;Declined;0;2012;2012-08-21 0:00:07
31740;Djoni Antonio   da Silva;Univali;UMA ABORDAGEM COM APOIO FERRAMENTAL PARA APOIAR AS ATIVIDADES DE GARANTIA DA QUALIDADE DE SOFTWARE;In recent years, software organizations have become more concerned about the quality of their products. However, to obtain quality products, organizations must seek well-defined processes, since the quality of the process is directly linked to the quality of the products. However, just defining an organization's processes does not guarantee its quality. Therefore, it is necessary to carry out software quality assurance activities with the aim of ensuring that the processes defined in an organization are followed. Therefore, this article presents an approach and a computational tool to support quality assurance activities. This approach automatically extracts checklists for quality assurance from an organization's modeled processes. The tool developed imports the checklists generated by the approach and supports the entire quality assurance process. As additional results, evaluations of the approach and the tool are presented.;;pt_BR;Declined;0;2012;2012-08-21 19:43:40
32125;Douglas   Melo;Universidade do Vale do Itajaí;Interface de Rede Extensível para Integração de Núcleos a uma Rede-em-Chip;Technological advances have allowed the development of systems integrated on a single chip (SoCs – Systems-on-Chip) with a high level of complexity and with different requirements in relation to traditional systems, such as, for example, the use of Networks-on-Chip. Chip (NoCs – Networks-on-Chip) as an alternative for providing high performance in communication and project scalability. To integrate the cores of an integrated system into a NoC, it is necessary to use communication interfaces that adapt the core protocol to that of the network and that offer the necessary communication services to the cores. This article describes an architecture of an extensible network interface for integrating cores into the SoCIN (System-on-Chip Interconnection Network) NoC. As a difference, the proposed interface uses a three-layer architecture that performs protocol adaptation, packaging/unpacking and sending/receiving packets, among other services. The article describes the architecture of the network interface and presents the results of its validation and synthesis in silicon.;;pt_BR;Declined;0;2012;2012-08-31 14:32:35
32221;Thiago   Felski Pereira;UNIVALI - Universidade do Vale do Itajaí;Mecanismos para Provimento de Tolerância a Faltas em uma Rede-em-Chip;The constant reduction in the size of system components integrated into a single chip, as well as the increase in operating frequency, makes such systems increasingly susceptible to internal and external noise sources. These noises can cause a component to fail, affecting the functioning of the system as a whole. Future integrated systems with dozens of cores will be based on Networks-on-Chips and will require networks that are capable of detecting a fault and preventing it from leading to a system failure and application malfunction. In this context, this work seeks to evaluate solutions to increase the reliability and availability of a Network-on-Chip, the SoCIN – System-on-Chip Interconnection Network, implementing mechanisms for detecting and correcting errors in this network. The article presents the implementation of spatial and information redundancy techniques in the SoCIN network router in order to protect it against transient faults of the SEU type – Single Event Upset.;;pt_BR;Declined;0;2012;2012-09-03 19:54:20
32239;Rafael Ferraz   Romeiro;Universidade de São Paulo;Análise de ferramentas de ataques a redes ad-hoc sem fio no contexto de sistemas embarcados críticos;This work aims to analyze, through case studies, attack tools in the context of critical embedded systems using the Gumstix Overo EVM Pack hardware and ad-hoc wireless networks as a communication channel, verifying the behavior of each technique and/or tool through real attacks on this means of communication, in order to assess the damage and suggest plausible countermeasures for each scenario.;;pt_BR;Declined;0;2012;2012-09-25 17:16:31
32882;Rober   Mayer;UTFPR;Uma Revisão de Propostas de Sobrevivência para Redes Multicasting P2P;The success of peer-to-peer or P2P multicast in overlay networks for critical data streams depends on its scalability. The distribution of data over an overlapping path consisting of shifting pairs, due to the dynamism of entry and exit nodes in a network, is inherently subject to problems compared to routers. Survivability or fault tolerance is a key requirement for peer-to-peer data distribution architectures. Currently, several techniques have been proposed to improve survivability, exploiting the diversity of paths to reduce dependency between nodes and data redundancy. In this article, a review of proposals in recent literature is presented, which can be applied to data distribution in P2P multicasting overlay networks in order to keep the network active and reduce data redundancy.;;pt_BR;Declined;0;2012;2012-09-15 13:05:11
33024;Liliane S.   Machado;Federal University of Paraíba;Um Serious Game para o Ensino de Biossegurança em Odontologia;The literature points to the potential of serious games to address specific knowledge through teaching, training new skills or even raising awareness about important issues, especially in practical disciplines. Health practices such as biosafety correspond to the adoption of safe and appropriate standards and procedures for maintaining the health of patients and professionals, and the proper internalization of such knowledge by professionals is essential. This work aims to propose a serious game, based on the classical logic decision model, to assist in teaching biosafety practices in Dentistry;;pt_BR;Declined;0;2012;2012-09-19 14:09:14
33230;Fabio Aiub   Sperotto;;Interoperabilidade na Comunicação de Agentes: um Modelo utilizando Ontologia e Sinônimos;This article describes the development of a model in the area of ​​communication between agents. This study involves the concepts of agents and communication problems in their interactions. Using ontology as a knowledge classification technique, the model includes an approach to build an intermediate software component between the agents and the ontological knowledge base, utilizing fuzzy application in handling imprecision information based on synonyms. The editor Protégé is chosen to develop the ontology in OWL. The software component uses Jena and SPARQL for ontology manipulation. For validation, the case study used is the multi-agent system model that represents the urban garden of Parque San Jerónimo (Spain).;;pt_BR;Declined;0;2012;2012-09-28 16:20:18
33245;Eduardo N.   Borges;Universidade Federal do Rio Grande;Um Mecanismo de Busca para Sistemas de Bibliotecas Baseado em Critérios de Relevância Extensíveis;Library management systems allow users to query the metadata that describes a collection. Spelling errors can make it impossible for the system to find a desired item. Additionally, users may not know which of the returned items best suit their profile. This article presents ARGOsearch, an information retrieval system based on relevance criteria that orders the results of queries considering textual similarity, statistical data and the user's profile. Experiments presented in previous work were refined, analyzing the configuration of parameters to improve the quality of searching in library administration systems. The proposed approach is evaluated using the vector space model.;;pt_BR;Declined;0;2012;2012-09-29 18:38:24
33252;Emanuel da Silva Diaz   Estrada;Universidade Federal do Rio Grande - FURG;Comparative Study of Genetic Algorithm and Exhaustive Search for Constructal Design Optimization of Y-Shaped Cavities;In the present study, we rely on the Constructal Design in association with Genetic Algorithm to optimize the geometry of a Y-shaped cavity embedded into a solid conducting wall. The structure has four degrees of freedom. The purpose here is to minimize the global thermal resistance between the solid and the cavity without the requirement to simulate all combinations of existing geometries, which is required in an exhaustive search. The results showed that Genetic Algorithm proved successful in the search for the minimal thermal resistances, as well as, for the optimal shapes. Moreover, the number of iterations required to find the optimal shapes was nearly 4 and 6 times lower than that required for the exhaustive search.;;pt_BR;Declined;0;2012;2012-09-29 16:26:41
33840;Ivar   Vargas Belizario;Instituto de Ciências Matemáticas e de Computação - USP;Avaliação de medidas de similaridade no agrupamento em grafos para segmentação de imagens;This work presents an approach for image segmentation using graph clustering algorithms, suitable for segmenting images of natural scenes. The work presents the evaluation of 7 similarity measures and, quantitatively, demonstrates which of these measures and which grouping algorithms are most suitable for the image segmentation process. The evaluation is carried out by comparing the segmentation produced by the method with manual segmentations. The experiments demonstrated that two algorithms stand out in the process (FG and LP), while 6 of the 7 similarity measures can, in fact, be used for segmentation.;;pt_BR;Declined;0;2012;2012-10-09 16:28:22
33910;Eduardo Batista de Moraes   Barbosa;Instituto Nacional de Pesquisas Espaciais (INPE);Avaliação de Desempenho de Banco de Dados por meio de uma Abordagem Estatística;Technological development and the rapid growth of data collections in Organizations have placed database technology at the forefront. Currently, there are different options for database systems and among the factors that can influence your choice, system performance stands out. In the database context, performance measurements are carried out through benchmarks, such as the Transaction Processing Performance Council (TPC), widely recognized for its rigor in evaluation criteria, price metrics and communication of results. This article aims to present a study on database performance through the methodology for planning and analyzing experiments (DoE). Within the scope of this study, the application of DoE will be illustrated based on a case study with a set of queries from the TPC-H benchmark in a database implemented in PostgreSQL. The results obtained by carrying out different experiments reveal the influence of a list of parameters on the queries under study and suggest that work_mem, shared_buffers and effective_cache_size, respectively, are the relevant parameters for PostgreSQL performance. Through this study, it can be concluded that the use of the DoE methodology, within the database, is valuable to assist tuning activities. However, it should be noted that to be successful, its application must be associated with the experience and intuition of database administrators, since subjective factors can influence the performance of the systems.;;pt_BR;Declined;0;2012;2012-10-11 9:57:22
34835;Andres Fernando   Solano;Universidad del Cauca (Colombia);Diseño de Interfaces Gráficas Usables para Aplicaciones Interactivas en Entornos de Televisión Digital;With the implementation of Digital Television in the coming years, and considering the advantages of interactivity, it is necessary to study the usability of interactive applications, so that a user can actively participate in broadcasting a television program. This study aims to find the most appropriate way to design applications usable in Televisión Digital Interactiva – TDi. In this article, we present a set of guidelines for creating applications usable in TDi, which were proposed based on usability evaluations developed at the TDi Laboratory at the University of Cauca (Colombia).;;pt_BR;Declined;0;2012;2012-10-30 15:47:18
34943;Macilon Araújo   Costa Neto;Universidade Federal do Acre;Um experimento para validação do método de inspeção de modelos ALaDIM;Using usability inspection methods during the development process – formative assessment – ​​can reduce costs if it can prevent problems from being detected before the system is even built. One of the ways to carry out formative assessment is using models created at project time. Inspection of interaction models aims to allow potential usability problems to be identified. However, for the method to be reliable and allow the identification of usability problems that may occur when the system is ready, it must be validated and calibrated. This article describes an experiment to verify the reliability of the interaction model inspection method described in the ALaDIM language. The experiment consisted of carrying out an inspection of an ALaDIM model, using the method guidelines, whose objective is to identify potential usability problems. The results of this stage were compared to the results of a usability test performed on the user interface of the same system.;;pt_BR;Declined;0;2012;2012-11-01 0:16:47
35144;Valdir Donizetti de   Sousa;USP - Universidade de São Paulo;MoVER: Serious Game aplicado à reabilitação motora usando sensor de movimento Kinect;Making physiotherapy sessions more fun is one of the factors that can contribute to patient adherence and improved rehabilitation results. In this sense, several games have been developed to make sessions more enjoyable. This article presents MoVER (Movement in Virtual Environment for Rehabilitation), a Serious Game that simulates physiotherapy movements through challenges to perform virtual tasks using the human body. The main contribution of this work is the use and evaluation of a Natural Interface that allows the personalization, in real time, of the movements to be performed by the patient during the physiotherapy session. With MoVER, the physiotherapist defines measures that allow the definition of the range of movements within the patient's limits and with resources to define the moment and characteristics of the movements in order to make the physiotherapy session more stimulating and suited to the needs of each patient. . The initial evaluation showed that the game with Natural Interfaces offers enough help for the therapist to personalize the therapy, becoming an allied tool for the health professional.;;pt_BR;Declined;0;2012;2012-11-05 14:33:50
35151;André Luís   Silva;Universidade Federal de Ouro Preto;Avaliação do emprego de sistemas de informação no setor hoteleiro: o caso de uma região turística em Minas Gerais;The use of Information Systems (IS) is seen in various activities in the hotel sector. However, there are still some accommodation options that do not use these in their management. In view of this statement, this work presents a statistical survey that investigated the use of technologies and software dedicated to the management of accommodation facilities located in the district of Lavras Novas (Ouro Preto/MG/Brazil). The methodology was on-site research via questionnaires.;;pt_BR;Declined;0;2012;2012-11-05 12:14:11
35817;Diana Francisca   Adamatti;Universidade Federal do Rio Grande - FURG;Performance Evaluation of BRISK Algorithm on Mobile Devices;The great number of researches about local features extraction algorithmsin the last years, allied to the popularization of mobile devices, makes desirableefficient and accurate algorithms suitable to run on such devices. Despite this, thereare few approaches adequate to run efficiently on the complexity-, cost- and powerconstrainedmobile environments. The main objective of this work is to evaluate theperformance of the recently proposed BRISK algorithm on mobile devices. In thisway, a mobile implementation, named M-BRISK, is proposed. Some implementationstrategies are considered and successful applied to execute the algorithm in areal-world mobile device. As evaluation criterion repeatability, recall, precision andrunning time metrics are used, as well as the comparison with the classical well establishedalgorithm SURF and also with the more recently proposed ORB. The resultsconfirm that proposed mobile implementation of BRISK (M-BRISK) performs welland it is adequate to mobile devices.;;pt_BR;Declined;0;2012;2012-11-21 16:12:29
36601;Kelly Lais   Wiggers;Universidade Estadual do Centro-Oeste;Um Sistema Computacional para Classificação das Configurações de Mão da Língua Brasileira de Sinais;This work consists of developing a computational system that is capable of classifying the hand configurations of the Brazilian Sign Language (LIBRAS). The method chosen to carry out this classification is through the Kohonen Artificial Neural Network. The system consists of the following steps: extraction of features from hand configurations (images), training of the Artificial Neural Network, tests and computational results.;;pt_BR;Declined;0;2012;2012-12-28 14:41:14
36741;Johnnatan   Messias;Universidade Federal de Ouro Preto;Como robôs podem se tornar pessoas influentes no Twitter?;Systems that classify influential users on social networks have been used with great frequency, being referenced in scientific articles and in the media as an ideal standard for evaluating influence on the social network Twitter. We consider this measurement to be something complex and subjective and therefore suspect the vulnerability and ease of manipulation in these systems. Based on this, we carried out experiments and analyzes on two influence classification systems: Klout and Twitalyzer. We create simple robots capable of interacting through Twitter accounts and measure their influence. Our results show that it is possible to be influential through simple strategies. This suggests that systems do not have ideal metrics for classifying influence.;;pt_BR;Declined;0;2013;2013-01-09 19:02:22
36800;Rafael Ballottin   Martins;Universidade do Vale do Itajaí - UNIVALI;A utilização de IA em Jogos?;The area of ​​Artificial Intelligence applied to games receives more attention every day, with this vast number of researchers and developers in the area demonstrating different opinions on how the technique should be approached and even whether it should be approached at all. Among the discussions, a common issue among developers is that the techniques applied do not use their full potential, being limited to a set of rules or simplified adaptations of the techniques mainly because they do not consider them to have a great loss compared to a more complex AI. for the same purpose, often leaving aside a more elaborate treatment of AI to make the game more “intelligent”. This work seeks to demonstrate the opinions and justifications of researchers and developers in the field of games in relation to the application of AI in them, in order to assist researchers in formulating their own questions.;;pt_BR;Declined;0;2013;2013-01-15 15:25:46
37374;Vinícius Afonso   Ferreira;Universidade Federal de São Carlos;Expandindo Experiências Sociais utilizando Recursos do Facebook: uma análise de casos de sucesso;With the massive use of online social networks, many companies and developers are using the resources available on these platforms to create applications that support interaction between and among users. Among the social platforms that provide these resources, Facebook stands out with the largest number of active users. In this context, this work investigated social applications that are successful references on the Facebook platform, in order to find trends in these applications, which can then be analyzed and considered references for the development of guidelines that aim to enrich interactions in computing environments.;;pt_BR;Declined;0;2013;2013-02-26 14:52:05
37508;Roni   Apaza;Universidade de São Paulo, Instituto de Ciências Matématicas e Computacionais;Aplicação da metodologia AIM-CID sobre os conceitos no gerenciamento de processos;The use of tools, objects and other elements to teach subjects in the Computer Science course makes learning concepts more effective for students. The construction of educational elements is necessary due to their importance. The first step to creating an educational tool is to use a robust and valid methodology in this case related to the topic of Operating Systems process management. In this way, the Integrated Approach of Conceptual, Instructional and Didactic Models (AIM-CID) methodology was applied, a methodology previously applied in the area of ​​mathematics teaching known as NUMRAC. The set of concepts of the discipline is large, it can be seen that, through the use of this methodology, a new vision of what should be taught is achieved and the creation of new educational elements is supported.;;pt_BR;Declined;0;2013;2013-03-01 14:33:06
37540;Celso Antonio Alves   Kaestner;Universidade Tecnológica Federal do Paraná;Support Vector Machines and Kernel Functions for Text Processing;In this work we present kernel functions that can be used in conjunction with the SVM (Support Vector Machine) classifier to solve the automatic text classification task. Initially we present the Vector Space Model for text processing, in which text is seen as a set of vectors in a high dimensional space then we derive some extensions and alternative models, and discuss preprocessing procedures. The SVM algorithm, largely employed for text classification, is presented as a solution of an optimization problem we also discuss the so-called ``kernel trick'', that allows the algorithm to be applied in non-linearly separable cases. To use the kernel trick a function that computes the inner-product between problem instances must be obtained we present some kernel functions that are currently used in text applications. Finally we conduct some text classification experiments employing the SVM classifier, in order to illustrate some text preprocessing techniques and the presented kernel functions. ;;pt_BR;Declined;0;2013;2013-03-04 13:53:51
37834;Pedro Calais   Guerra;UFMG;Caracterização de Padrões Estruturais de Redes Polarizadas;Polarized networks are social networks that are increasingly gainingattention from researchers, social scientists and marketing agents. Such networksare found in many contexts in which individuals organize themselves into opposinggroups, since they have ideas, goals and viewpoints which are coniting. Such networksare found in relevant contexts such as Politics, Sports and many polemic topicsdebated on our society. However, in the literature we do not nd an accurate andcoherent denition of what a polarized network is. In this work, we show that thecurrently accepted conceptualization of a polarized network  networks which exhibitcommunities with high degree of cohesion  is not enough to classify a network asa polarized network, since that non-polarized networks (such as friendship networks)also exhibit such property. Our major contribution is to demonstrate that polarizednetworks exhibit an additional structural characteristic  low density on the overlap ofpolarized communities.;;pt_BR;Declined;0;2013;2013-03-14 15:46:12
37888;Anderson Silva de Oliveira   Góes;UNIVERSIDADE FEDERAL DO PARÁ;AmanaEdu: A nuvem educacional do Estado do Pará;This article presents the computing cloud called AmanaEdu, which was developed to help solve the serious problems of public education in the State of Pará. These problems involve adverse factors linked to geographic and social issues. The best practices for developing computing clouds were used in the research and, depending on the needs detected, its application layer incorporates three portals: SEUTED, for centralized access to all AVAs available in the cloud, PROTV, for using multimedia streaming and PROA , a portal of learning objects. These elements, used together, provide the basis of a new educational approach, which can be put into practice at all levels of education.;;pt_BR;Declined;0;2013;2013-03-18 19:38:19
37922;Rober   Mayer;UTFPR;Uma Revisão de Propostas para Sobrevivência em Redes de Sobreposição Multicasting P2P;The success of peer-to-peer or P2P multicast in overlay networks for critical data streams depends on its scalability. However, as multicast functionality, in this case, is associated with unpredictable end systems, the high degree of entry and exit of network nodes can result in a significant loss of performance when compared to routers. Survivability or tolerance to unexpected events is a key requirement for peer-to-peer data distribution architectures. In this article, a review of proposals in recent literature is presented, which can be applied to data distribution in P2P multicasting overlay networks in order to keep the network active and reduce data redundancy.;;pt_BR;Declined;0;2013;2013-03-19 19:44:59
38170;Victor Orlando   Gamarra-Rosado;UNESP – Universidade Estadual Paulista “Júlio de Mesquita Filho”Faculdade de Engenharia de GuaratinguetáDepartamento de Engenharia MecânicaAv. Ariberto Pereira da Cunha, 333Bairro: Pedregulho12.516-410 - Guaratinguetá, SP;Biomodelagem virtual para diagnóstico e  planejamento cirúrgico usando softwares livres;This work aims to present an alternative proposal to virtual biomodeling through the use of free software installed on conventional computer equipment, effectively contributing to reducing the costs of the technique. To achieve the objective, it was necessary to identify dedicated free software and CAD that were capable of being applied together to develop biomodeling projects. Among the available programs, it was observed that the Invesalius 3.0 and FreeCAD 0.11 software had the basic characteristics for applying the technique. Thus, case studies were addressed in diagnostic and surgical planning situations, assisting the doctor in decision-making. The results demonstrated that virtual biomodeling through the use of these free software, installed on conventional computer equipment, is viable for use in routine medicine in various diagnostic and surgical planning situations. The main advantages of the present proposal are the reduction of biomodeling costs and the possibility of disseminating the technique, which facilitates the inclusion of a greater number of patients undergoing 3D technologies.;;pt_BR;Declined;0;2013;2013-03-26 20:42:07
38252;Geycy Dyany   Lima;Universidade Federal de Uberlândia;Um Overview Sobre Dependabilidade em Computação nas Nuvens;This overview presents the characteristics of Cloud Computing, including aspects of dependability. There is an overview of Cloud Computing, the service models recognized by NIST and the description of a proposal for building a new service model that integrates the concepts of dependability. The key attribute of dependability described in this overview is availability, which is one of the main attributes when signing contracts between service providers and users.;;pt_BR;Declined;0;2013;2013-03-28 16:50:19
38319;Juan Manuel   Adán;PUC-Campinas;Avaliação da Estabilidade e Robustez de Algoritmos para Recomendação de Serviços Web Semânticos em Face de Ataques de Injeção de Perfis;Recommendation systems based on collaborative filtering are open in nature, which makes them vulnerable to profile injection attacks that seek to insert biased evaluations into the system's database, allowing attackers to manipulate their recommendations. This article evaluates the stability and robustness of collaborative filtering algorithms for recommending Semantic Web Services when subjected to random and segment profile injection attacks. Four algorithms were evaluated: (1) IMEAN, which makes predictions using the average of the ratings received by the target item, (2) UMEAN, which makes predictions using the average of ratings made by the target user (3) an algorithm based on the method of k nearest neighbors (k-nn) and (4) another algorithm based on the k-means clustering method. The experiments carried out showed that the UMEAN algorithm is not affected by attacks and that IMEAN is the most vulnerable of all. Although not affected by the attacks, UMEAN has no practical application due to the low accuracy of its predictions. Among the algorithms with intermediate tolerance to attacks, but with good predictive performance, k-nn was more robust and stable than k-means.;;pt_BR;Declined;0;2013;2013-04-01 16:17:30
38447;Fabiano Azevedo   Dorça;Universidade Federal de Uberlândia;Um Modelo Baseado em Regras de Produção e Probabilidades para Geração Automática de Conteúdo Personalizado Através da Recomendação Estocástica de Objetos de Aprendizagem no Processo de Ensino em Sistemas Adaptativos e Inteligentes para Educação;A large number of studies attest that learning is facilitated if pedagogical strategies are in accordance with the student's learning styles, and state that using instructional material and activities that meet these characteristics makes the learning process more effective and the student's performance more effective. is considerably improved. Therefore, the automatic personalization of the teaching process based on learning styles is a fundamental aspect in adaptive and intelligent systems for education, and this is currently an area under intense investigation. In this context, this work presents a model based on production rules and probabilities for the automatic generation of personalized content through the stochastic recommendation of learning objects in the teaching process in these systems. Experiments carried out with the proposed model showed promising results. The tests carried out presented the recommendation, ordering and highlighting of OAs effectively, taking into account the students' learning styles.;;pt_BR;Declined;0;2013;2013-04-04 19:21:17
39548;Claudio Cesar   de Sá;Universidade do Estado de Santa Catarina - UDESCDepartamento de Ciência da Computação - DCC Rua Paulo Malschitzki, s/numero - Campus Universitário Prof. Avelino Marcante Bairro Zona Industrial Norte Joinville-SC - Brasil;Programação por Restrições no Problema  Mirrored Traveling Tournament Problem;This article presents the solution to the problem of how to plan the rounds of a round-robin championship, also known as \textit{Mirrored Traveling Tournament Problem}, with the objective function of minimizing the distance covered by the teams. The attractive thing is that this problem belongs to the NP class, presenting a combinatorial explosion even for small instances. Additionally,   a   mathematical modeling is presented in a first-order logic style. This modeling allows the code to be transcribed into a Constraint Programming language, known as \eclipse . Finally, several search strategies in this implementation were explored, having as criteria the choice of variables and the choice of their values ​​in the domains, during the process of expanding and propagating branches in the search tree.;;pt_BR;Declined;0;2013;2013-05-01 18:31:33
39633;Rafael Stubs   Parpinelli;UDESC;Computational Ecosystem for Optimization: Review and Perspectives for Future Research;The search for plausible biologically inspired ideas, models and computational paradigms always drew the interest of computer scientists, particularly those from the Natural Computing area. It is worth mentioning that most bio-inspired algorithms only focuses on and took inspiration from specific aspects of the natural phenomena. However, in nature, biological systems are interlinked to each other, e.g. biological ecosystems. The ecosystem as a whole can be composed by species that respond to environmental and ecological stimuli. Thus, this work reviews the theoretical foundations and applications of a computational ecosystem for optimization, named ECO. Also, as some concepts and processes inherent to biological ecosystems have already been used to develop computational systems for optimization, some related works are described. Finally, several future research directions are pointed.;;en_US;Declined;0;2013;2013-05-03 15:07:38
40946;Lauro Cássio   Martins de Paula;Instituto de Informática - Universidade Federal de Goiás;Comparação de Desempenho Computacional entre Métodos Iterativos para Solução de Sistemas Lineares;This work presents a comparison of computational performance between some iterative methods used to solve linear systems. The objective is to show that the use of parallel processing provided by a graphics processing unit (GPU) can be more viable, as it enables the rapid solution of systems of linear equations so that increasingly complex problems can be solved in a short space of time. time. To validate the work, a GPU was used, using the CUDA architecture (Compute Unified Device Architecture), and the computational performance of the iterative methods of Jacobi, Gauss-Seidel, BiCGStab and BiCGStab(2) parallelized in the solution was compared of linear systems of varying sizes. It was possible to observe a significant acceleration in tests with the parallelized method, which increases considerably as the systems grow. The results showed that the application of parallel processing in a robust and efficient method, such as BiCGStab(2), is often essential, so that simulations can be carried out with quality and in a non-prohibitive time.;;pt_BR;Declined;0;2013;2013-07-03 17:37:27
41361;Eugênio Martinho   Pires;;EXTREME PROGRAMMING (XP): UM LEVANTAMENTO DO CENÁRIO DE USO DE UMA METODOLOGIA ÁGIL NO DESENVOLVIMENTO DE SOFTWARE;Agile software development methods are increasingly being used in software projects, providing better quality software. This article aims to study the agile Extreme Programming methodology in its general concept and analyze the importance and benefits that this methodology can provide in software development. An online survey was carried out with professionals who work with software projects to collect information about the adoption of this methodology. At the end of the article, based on the results and analysis obtained from the research, some observations are made about Extreme Programming and its practices, as well as suggestions that can serve as a warning for software project managers.;;pt_BR;Declined;0;2013;2013-07-25 12:02:34
41499;Carlos Cesar Silos   Gomes;Universidade Estadual do Ceará;GENERALIZAÇÃO DO CÓDIGO BINÁRIO PARA UM SISTEMA GERAL DE CÓDIGOS;This work presents an algebraic description of the binary code system from the point of view of the decimal number system which can now be described through an n-position code system. The consequence of this new understanding primarily implies the greater language capacity offered, the understanding of the existence of other higher position codes, including a code equivalent to the decimal system, the consequences of this equivalence and the versatility of using logical diagramming. The principles used in Boolean algebra are present but are not formally presented, leaving only deductions to understand the general system of codes. From the binary code, the other positions are deduced, opening a particular understanding of the set as being made up of different bases (J) and powers (i) and the relationships between them.;;pt_BR;Declined;0;2013;2013-07-31 11:41:27
41678;Nícolas Bouvié   da Silva;Universidade de Passo Fundo;Using CUDA and genetic algorithm to solve the lapidary cutting problem;This paper proposes a quicker and more efficient solution than a preexistingalgorithm to solve the lapidary problem. The objective of this problem isfind the greatest scale that a gemstone model could fit inside a rough gemstone. Aimingthis better performance, this research was focused on Nvidia CUDA to solve thealgorithm as fast as possible in parallell.;;en_US;Declined;0;2013;2013-08-06 10:55:19
41718;Fabiane   Barreto Vavassori Benitti;Univali;Avaliações de Usabilidade no Brasil: um mapeamento sistemático;This paper examines the Brazilian research on techniques for usability evaluation with regard to the scope of use and innovations. Through a systematic mapping this study identified 116 studies that reported empirical evidence on the consolidated technical innovations and evaluations in different environments. Results indicate that the empirical technique is the most used and the web environment was chosen by 60% of the studies. This study noted that assessments of an educational product are the most applied ones (33 studies). There is a consistent increase of innovative studies in recent years. In addition to mapping research in the area, this study also contributes to point out areas for further research.;;pt_BR;Declined;0;2013;2013-08-06 20:46:03
41726;Solange Favero   de Lima Medeiros;UTFPR;Teste de Ambientes Virtuais de Aprendizagem para o Ensino de Redes de Computadores com foco em Deficientes Auditivos;The present study highlights an analysis and testing of some virtual learning environments for teaching existing computer networks, learning characteristics of deaf culture and also the needs of hearing impaired people in relation to learning mediated by technological artifacts, in order to analyze how the available tools contribute with learning for the hearing impaired. Subsequently, these tools were applied to three hearing impaired people, to verify the relevance of these tools for people with hearing impairments.;;pt_BR;Declined;0;2013;2013-08-07 0:10:18
42073;Aurelienne Aparecida Souza   Jorge;CEMADEN - Centro Nacional de Monitoramento e Alertas de Desastres Naturais;Classificação de Strahler para hidrografias brasileiras relacionadas a desastres naturais: abordagem diretamente baseada em operações via bancos de dados geográficos;Among the most frequent natural disasters in the country are floods and flash floods. The classification of watercourses in the river basin's drainage system lists a resource called Hydrological Intelligence, which is essential for monitoring natural disasters. Based exclusively on files and free software, a set of procedures for Strahler classification of a hydrography is presented, with results presented for river basins with significant history and risk to natural disasters, referring to the Itajaí, Paraíba do Sul and Doce Rivers. Approaches to obtain effective results are discussed, using interface resources between programming languages ​​(such as Python) and Geographic Database Management Systems (such as PsotgreSQL with the PostGIS spatial extension) - in this case, the psycopg2 library -, and also efficient, with the use of specific indexes in database tables. The results are presented on a robust platform aimed at natural disaster monitoring operations.;;pt_BR;Declined;0;2013;2013-08-26 9:59:56
42212;Giampaolo Luiz   Libralon;Instituto Federal de São Paulo (IFSP) - campus São Carlos;Análise do Motor Gráfico CryENGINE 3 Free SDK;This article will talk about the CryEngine 3 graphics engine, and show its prominence in the electronic games industry. An analysis of the main features in its free version will also be presented, highlighting their positive and negative aspects. All the resources studied were put into practice, which resulted in the development of a demonstration scenario using such resources.;;pt_BR;Declined;0;2013;2013-08-31 13:13:12
42420;Luiz Carlos Pessoa   Albini;Universidade Federal do Paraná;Disseminação de chaves assimétricas baseada em votação para redes tolerantes a atrasos e desconexões;One of the biggest challenges of DTNs (Delay and Disruption Tolerant Networks) is security. They inherit all the security problems of Ad-Hoc networks, but the security mechanisms are not adaptable to the new context. One of the tasks that is not adaptable is the correct and efficient dissemination of public encryption keys. Furthermore, none of the DTN-specific solutions are secure against a public key forgery attack. This paper presents a mechanism for the correct and efficient dissemination of public keys resistant to key forgery attacks, based on a voting scheme. As a result, it presents an improvement of up to 1400% in the number of true keys stored by nodes, when compared to previous mechanisms.;;pt_BR;Declined;0;2013;2013-09-06 14:55:38
42535;Rodrigo Duarte   Seabra;Universidade Federal de Itajubá;Abordagens Contemporâneas sob a Ótica do Ensino de Informática e Sociedade;This work presents a proposal for a contemporary approach to teaching the subject of Computing and Society, present in the curricular guidelines of most Computing and related courses. The object of study refers to the course offered to students at the Federal University of Itajubá in 2013. The article presents a summary of the main topics discussed in classes, as well as the results obtained based on experimental research carried out with students, being the most notable summarized: 96% of students reported that the subject contributed to the acquisition of knowledge relevant to their future professional practice. The topics of Information Technology in Education, Regulation of the IT Profession, Green Computing, Ubiquitous Computing and Evolution of Cybercrime were the topics of greatest concern. emphasis on the social aspects involved in the use of information technology.;;pt_BR;Declined;0;2013;2013-09-10 14:09:25
42605;Pedro Manuel   Fernandes;Universidade Atlântica - Portugal;Desenvolvimento de um Framework Real Time Web para HTML5;There is currently a need to create faster protocols and development paradigms that allow cutting the latency times of current network protocols. This article proposes a real-time web framework for HTML5. The essential objective of the set of real time web technologies is to create a web that is transparent to the user without the need to constantly update its content. These technologies offer an alternative to traditional data presentation proposals, significantly improving the performance of web systems, as well as reducing costs related to their maintenance. This work addresses techniques and technologies such as the Publish/Subscribe paradigm and technologies such as Comet or WebSockets. To validate the proposed framework, a proof of concept, unit tests and performance tests were developed to demonstrate the functionality of the technology. The results indicate that the proposed framework can be a way forward for web programmers.;;pt_BR;Declined;0;2013;2013-09-13 13:44:14
42692;João Ladislau   Lopes;;SisA3: Uma Abordagem para Cálculo do Volume de Produtos Agrícolas em Armazéns;This work aims to contribute to the automation of the audit process, proposing an approach for calculating the volume of agricultural products in warehouses, called SisA3. The volume is obtained from data provided by digitizing equipment, which generates a data matrix based on relief points, generally non-uniform, defined by the stored product. To evaluate SisA3's functionalities, two case studies are presented, highlighting the prototypes developed and the results obtained with their implementation and parallelization.;;pt_BR;Declined;0;2013;2013-09-17 22:37:00
42831;Pedro M.   Fernandes;Universidade Atlântica;Desenvolvimento de um Framework Real Time Web para HTML5;There is currently a need to create faster protocols and development paradigms that allow cutting the latency times of current network protocols. This article proposes a real-time web framework for HTML5. The essential objective of the set of real time web technologies is to create a web that is transparent to the user without the need to constantly update its content. These technologies offer an alternative to traditional data presentation proposals, significantly improving the performance of web systems, as well as reducing costs related to their maintenance. This work addresses techniques and technologies such as the Publish/Subscribe paradigm and technologies such as Comet or WebSockets. To validate the proposed framework, a proof of concept, unit tests and performance tests were developed to demonstrate the functionality of the technology. The results indicate that the proposed framework can be a way forward for web programmers.;;pt_BR;Declined;0;2013;2013-09-25 21:38:07
43146;Lauro   Martins;Instituto de Informática - Universidade Federal de Goiás;CUDA vs. OpenCL: Uma Comparação Teórica e Tecnológica;This work presents a comparison between two parallel architectures: Compute Unified Device Architecture (CUDA) and Open Computing Language (OpenCL). Some works in the literature presented a comparison of computational performance between the two architectures. However, there is still no recent and complete article that clearly highlights which architecture can be considered the most efficient. The objective of this work is to carry out a comparison only at the level of hardware, software, technological trends and ease of use, highlighting which one can present the best cost-benefit in general. To this end, the main works that have already made use of at least one of the architectures are described. It was observed that, as it is a heterogeneous system, the choice of OpenCL may seem more obvious. However, it was possible to conclude that CUDA, although it can only be used on NVIDIA graphics cards, has been a reference and more used lately.;;pt_BR;Declined;0;2013;2013-10-17 3:14:19
43210;Carlos Roberto   Beleti Junior;Universidade Estadual de Maringá;Metodologia de paralelização da Aplicação geoComp na Plataforma R;The R platform is a programming environment that enables the creation of applications for different areas. In geostatistics, an important application called geoCompo was developed to support the bivariate model for compositional data structures and was implemented on the R platform. This application requires considerable processing time, as it is executed sequentially. To reduce execution time, this work presents a parallelization methodology for geoComp using the R platform. Experiments have shown that the methodology provides an efficiency that reaches 70 to 125 percent in the case study carried out.;;pt_BR;Declined;0;2013;2013-10-22 11:12:15
43420;Daniela Maria   Uez;Universidade Federal de Santa Catarina;Prometheus AEOlus: um método para modelagem e geração de código em sistemas multiagentes;This article presents the Prometheus AEOlus method, a method for developing agent-oriented software that allows integrated modeling of the agent, the environment and the organization. The proposed method was developed based on the Prometheus method, in which work products were included that allow the detailed specification of the organization and the environment. Guidelines were also defined for code generation based on the work products developed. The abstractions for modeling the environment and organization were defined based on the JaCaMo framework. This method is advantageous because it allows integrated modeling of the three dimensions, meaning that specific concepts are used for each one, which reduces the conceptual difference between the modeling and the generated code.;;pt_BR;Declined;0;2013;2013-11-04 12:43:27
43819;Lauro   Martins;Instituto de Informática - Universidade Federal de Goiás;Implementação Paralela do Método BiCGStab(2) em GPU usando CUDA e Matlab para Solução de Sistemas Lineares;This paper presents a parallel implementation of the Hybrid Stabilized Bi-Conjugate Gradient iterative method (BiCGStab(2)) in Graphics Processing Unit (GPU) for solving large and sparse linear systems. This implementation makes use of CUDA-Matlab integration, in which method operations are executed on the cores of a GPU through standard Matlab functions. The objective is to show that the exploitation of parallelism using this new technology can provide significant computational performance. To validate the work, the proposed implementation was compared with a sequential and a parallelized implementation of BiCGStab(2) in the C and CUDA-C languages, respectively. The results showed that the proposed implementation is more efficient and can be essential for simulations to be carried out with quality and in a timely manner. The gains in computational efficiency were, respectively, 76x and 6x in relation to the implementation in C and CUDA-C.;;pt_BR;Declined;0;2013;2013-11-23 4:47:20
44041;Lucas Ferreira   Moura;Instituto Federal do Triângulo Mineiro - Campus Ituiutaba;Aplicações Robóticas Baseadas em Interface Gestual usando o Kinect;This article presents scientific research for the development of a natural interface for controlling robotic structures. The purpose of this interface is to be used as a tool for social inclusion of people with special needs. For development, we used: (a) a body movement sensor (b) a robotic structure in the shape of a mechanical arm and (c) software for communication between the movement sensor and the mechanical arm. Experiments were carried out to verify whether this interface is effective, and to identify possible flaws and make improvements. The results of this experiment demonstrated that this interface works satisfactorily.;;pt_BR;Declined;0;2013;2013-12-05 10:18:39
44051;Jean Carlos   Arouche Freire;Universidade Federal do Pará;Random  Forest e KNN na Classificação dos Ciclos Hidrológicos do Reservatório da Usina Hidrelétrica de Tucuruí;This work presents the results of a comparison and evaluation study in the classification of hydrological cycles in the period 2009 to 2012 that can infer the change in the physical-chemical parameters of water and metals in the reservoir of the Tucuruí Hydroelectric Plant (UHE) using intelligence techniques. computational. Initially, an exploratory study was carried out to decide on the use of the variables Temperature, pH, DO, Conductivity, Fe, Ca, Mg, K, Na, NH4, NO3, PO4, totalPO4, STS, Turbidity, Secchi disk and Chlorophyll-a on 423 samples of water quality analysis provided by Eletrobras-Eletronorte, in which the Randon Forest (RF) technique had a lower error rate compared to K-Nearest Neighbors (KNN) in the predictions used in the study.;;pt_BR;Declined;0;2013;2013-12-06 18:27:26
44214;Eleandro   Maschio;Universidade Tecnológica Federal do Paraná, Câmpus GuarapuavaUniversidade Federal do Paraná;Múltiplas Representações Externas no Suporte à Aquisição de Conhecimento em Programação de Computadores;This article focuses on describing how high-level knowledge about aspects of human experience can be modeled, represented, and then interpreted in order to support teaching and learning interactions. It specifically focuses on the problem of providing an epistemology for the description of knowledge about statements and knowledge stages of learners in Computer Programming, treating it through (1) a method based on genetic graphs to manage complexity in the authoring of utterances and (2) a general process for the dynamic modeling of learners' knowledge through the overlap of previously described domain capabilities. Both are supported by tools implemented and integrated into the MÚLTIPLA environment.;;pt_BR;Declined;0;2013;2013-12-15 23:50:49
44792;Valéria Farinazzo   Martins;Faculdade de Computação e InformáticaUniversidade Presbiteriana Mackenzie;Revisão Sistemática sobre Avaliação de Usabilidade de Aplicações de Realidade Aumentada no Brasil;This work describes the state of the art of usability evaluation of Augmented Reality applications in the last five years in Brazil. It also presents some statistics relating to the articles studied and uses the most relevant works found in the literature for a discussion and organization of the main usability criteria addressed and used in Augmented Reality.;;pt_BR;Declined;0;2014;2014-01-25 0:23:21
45211;Aparecido   Vilela Junior;Centro Universitário CESUMAR;A Lagrangian-Based Heuristic for a Lot-Sizing Problem in an Automated Foundry;This work consists of a case study in a large automated foundry, which has three moulding lines and two sets of furnaces. The moulding lines produce different types of items, which must be made of different alloys produced by the furnaces. In each period, the production programming in this foundry has two important levels of decision making which are linked: 1) which alloys should be produced in the furnaces in each period and 2) the quantity of each item to be produced in each moulding line. In \cite {ARA-ARE} a mixed integer programming optimization model is proposed in which the lot-sizing of the items and the capacity programming of the furnaces are considered. In this work we developed a lagrangian heuristic to solve the problem. The computational results are presented comparing the Lagrangian Heuristic, the Rolling Horizon Basis Method developed by \cite {ARA-ARE}, the Practical Solution and the solution of a Mixed Integer Package.;;en_US;Declined;0;2014;2014-02-22 9:04:40
45238;Nickerson Fonseca   Ferreira;Universidade de Coimbra;Um sistema de Data Warehouse com atualizações em tempo real;In this article we define a new Data Warehouse architecture that is capable of performing constant integrations of recent data without compromising query performance. This concept is known as Real-Time Data Warehouse (RTDW). For this RTDW we defined a dynamic and a static Data Warehouse component, where they represent the most recently integrated data and the rest of the historical data, respectively. Various ways of joining data from these two components were also defined, as well as these methods were evaluated to conclude which of these would be the most efficient. This architecture was evaluated through a real-time benchmark that considers both queries and updates online and simultaneously.;;pt_BR;Declined;0;2014;2014-02-24 19:34:28
45413;Cristiano Martins   Monteiro;Centro Universitário de Belo Horizonte - UniBH;Gerador de Códigos a partir do Modelo Entidade Relacionamento;Automatic source code generation is a practice adopted in software development to speed up, facilitate and standardize project implementation. By using a tool to automate coding, you avoid wasting time performing routine activities, enabling greater dedication to planning business rules and reducing project costs. The main objective of this work is to present the development of a system called Code Generator for Entity Relationships (GCER), which allows the user to register, import or export the ER model of a project and automatically generate its source code and scripts. database based on a design pattern, a programming language and a selected DBMS. GCER was developed in Java language (applying the JSF and jQuery frameworks) using the Oracle 11g database, and following the DAO and MVC standards. The project was successful in achieving its objectives, also ensuring better integration of artifacts and a lower risk of errors in the implemented operations. Such results highlight the feasibility of using tools for automatic code generation in the software development process.;;pt_BR;Declined;0;2014;2014-03-05 3:35:50
45476;Ronnie E. S.   Santos;Centro de Informática (Cin)Universidade Federal de Pernambuco;Sistemas de Recomendação: uma experiência no contexto uma rede social colaborativa de apoio à saúde;Summary. With the dizzying increase in the volume of information available on the web, finding relevant information in this environment has become a major challenge, met in part by recommendation systems (SR), which aim to facilitate or automate the tedious task of selecting content in the midst of a large amount of information. One of the main environments where SR has been used is social networks, mainly for recommending people. In this context, the present work aims to describe the experience of developing a user recommendation system for the GenNet social network (a collaborative health support network), which sought to facilitate the process of establishing new connections in the network and thus increase the collaboration between its users.;;pt_BR;Declined;0;2014;2014-03-07 21:45:19
45517;Maylon Felix de   Brito;;Transferência de Conhecimento em Projetos de Desenvolvimento de Software no Contexto de Contratação;Knowledge has been considered the main asset of innovative organizations. However, few studies have been conducted regarding the transfer of knowledge in the development of systems in a contracting environment (outsourcing), mainly in relation to the key concepts that interfere in this process. The objective of this work was to identify and organize into key concepts the elements that influence the transfer of knowledge in software development processes in the context of hiring. A systematic literature review was carried out, applying the Quasi-Gold search strategy. The elements of influence on knowledge transfer and their derivation into key concepts were identified, in: the nature of knowledge the relationship between client and supplier the human aspects the applicable models and frameworks and support tools. It is concluded that there is a low volume of work on the topic and that transferring knowledge is not something deterministic, as it is associated with personal beliefs and values, varying from person to person, and in their capabilities and skills.;;pt_BR;Declined;0;2014;2014-03-10 9:52:22
45566;Daniel Henrique Breda   Binoti;Universidade Federal de Viçosa;Sistema computacional para seleção de dados para modelagem do crescimento e produção florestal;The objective of this study was to initiate, develop, implement and validate a project to build a computerized system, to assist forest managers, academics and extensionists in selecting ideal plots for the construction of growth and production models. Select was developed using the Java programming language and is distributed free of charge on the NeuroForest Project homepage: http://neuroforest.ucoz.com. The IDE (Integrated Development Environment) Netbeans 7.1 and JDK 7.3 (Java Development Kit) were used as the development environment. System tests were carried out in a Windows environment. The system uses the Michael Thomas Flanagan's Java Scientific Library to obtain the parameters. The mathematical model for plot selection minimizes the sum of squares of total residuals (SQRT) by randomly searching for plots, as well as using the genetic algorithm meta-heuristic. The project initiated appears to be efficient for the use and ideal selection of plots for the construction of forestry growth and production models.;;pt_BR;Declined;0;2014;2014-03-11 15:46:58
45577;Maçaneiro   Maçaneiro;UNIVALI/UNIDAVI;UM MECANISMO AGREGADOR DE ATRIBUTOS MEDIADO PELO CLIENTE ALINHADO AO PROGRAMA DE EGOV.BR;The use of multiple identity providers (IdPs) in IdM systems can bring advantages to users, mainly for the privacy of their data. This article describes an attribute aggregation mechanism capable of collecting and uniting user attributes made available across multiple IdPs, so that they can be presented to providers that require attributes that are not in a single IdP. The proposed mechanism is innovative in adopting a client-mediated approach, which makes use of an application running in the user's environment and which follows the recommendations of the e-PING architecture of the Gov.br Program. The results obtained with the implementation and use of the proposed mechanism demonstrate that it brings more flexibility to a federated system and guarantees user privacy without compromising the interoperability of the system and the E.Gov application.;;pt_BR;Declined;0;2014;2014-03-11 21:36:17
45758;Carlos Henrique Gomes   Ferreira;Instituto de Ciências Matemáticas e de Computação - Universidade de São Paulo;Servidor Web x Servidor Web Distribuído, uma análise de desempenho e escalabilidade;Scalability on web servers is an issue that becomes a problem not only in computing but also in the business world when it involves non-fault tolerant processes. This article presents a comparison on Web servers presenting an alternative solution, which is load balancing on a set of servers in order to show its superiority.;;pt_BR;Declined;0;2014;2014-03-19 8:47:16
45810;Alison Zille   Lopes;Departamento de Engenharia, UFLA;PREDICTING RECTAL TEMPERATURE OF BROILER CHICKENS WITH ARTIFICIAL NEURAL NETWORK;Poultry production, facing modernization and increasing competitiveness, shows itself to be enterprising in the adoption of new technologies which enable increased productivity. Knowing that poultry productivity and rectal temperature (Tr) are affected by environmental conditions, this research was done with the objective of developing and evaluating artificial neural networks (ANNs) for the prediction of Tr in function of thermal conditions (air temperature, Tair relative humidity, RH and air velocity, V). The architecture chosen for this purpose was a single hidden layer Multilayer Perceptron (MLP), which was developed and trained under Scilab 4.1.1 aimed with ANN toolbox 0.4.2. The total data available, 139 data points obtained from literature, was divided into two sets, training (94) and validation (45). The selected MLP presented excellent results, providing estimates with an average error of 0.78% for the training set and 1.02% for the validation set. Thus, artificial neural networks constitute an appropriate and promising methodology to solve problems related to poultry production.;;en_US;Declined;0;2014;2014-03-21 0:54:13
45840;Alison Zille   Lopes;Departamento de Engenharia/UFLA;DESIGN OF A LOW COST NEURON CONTROLLER FOR CLIMATIZED BROILER HOUSES;The objective of the present research was to develop an environmental controller to be applied in climatized poultry houses based on a multilayer perceptron (MLP) artificial neural network and peripheral interface controllers (PICs). The MLP, responsible for the prediction of the rectal temperature (Tr) as a function of the thermal conditions (air temperature, Tair relative humidity, RH and air velocity, V), was used in the decision making, where the ventilation and cooling systems activation depend on the estimated Tr value. The hardware, divided in control and sensor modules, was developed to operate with four control stages (three of ventilation and one of evaporative cooling) and up to three acquisition points of Tair and RH. The neuron controller developed was evaluated under laboratory conditions. The PICs made possible the construction of a low cost robust system. The neuron controller, capable of translating thermal environment variables into comfort conditions, presented suitable behavior in the search for adequate thermal conditions for poultry production.;;en_US;Declined;0;2014;2014-03-22 19:08:14
45870;Carlos Roberto   Beleti Junior;Universidade Estadual de Maringá;Metodologia de paralelização da Aplicação geoComp na Plataforma R;The R platform is a programming environment that enables the creation of applications for different areas. In geostatistics, an important application called geoCompo was developed to support the bivariate model for compositional data structures and was implemented on the R platform. This application requires considerable processing time, as it is executed sequentially. To reduce execution time, this work presents a parallelization methodology for geoComp using the R platform. Experiments have shown that the methodology provides an efficiency that reaches 70 to 125 percent in the case study carried out.;;pt_BR;Declined;0;2014;2014-03-24 14:32:23
46338;Rodrigo Duarte   Seabra;Universidade Federal de Itajubá;Processamento Digital de Imagens na Visualização de Dados em uma Ferramenta de Cartografia Linguística;Computer Graphics and Digital Image Processing Algorithms have been increasingly explored in the most varied areas of human knowledge, such as applications in Medicine, Engineering, Games, among others. Considering the evolution of currently available computational technologies in terms of computational processing power, these algorithms, for the most part, aim to amplify the user's interaction experience, privilege aspects of information visualization and, in some cases, increase the feeling of presence. However, the techniques designed often involve real-time calculations and realistic renderings that require the development of high-performance algorithms. This work presents aspects of the implementation of algorithms developed to support data visualization in a tool for generating and visualizing linguistic maps, especially with regard to the calculation of filling and detection of intersections of areas in isogloss maps and the generation of gradients of tones to represent the productivity of the occurrences of lexical variants in these letters. Tests carried out to generate the gradients showed that the use of a parallel implementation achieved significant results in the algorithm's performance.;;pt_BR;Declined;0;2014;2014-04-08 18:34:31
46723;Yuri   Vasconcelos;Universidade Santa Cecília;A importância da tecnologia móvel na competitividade das empresas;It can be argued that software drives innovation and behavior, nowhere is this more apparent than in the innovative market for mobile applications that run on portable computing devices like smartphones and tablets. The growth of mobile technologies allows users to explore the internet using its resources to obtain information, communicate, shop, entertain themselves, among others. Mobile apps turn portable devices into e-book readers, portable navigation systems, flashlights, editors, digital wallets and more. It is necessary to emphasize that technology is essential for companies and of extreme competitive importance. The resources and benefits generated by new technologies are highly necessary for the survival of any company, and can increase its competitive potential with the ease of access to resources and applications, increasing its productivity, visibility and profitability.;;pt_BR;Declined;0;2014;2014-04-30 12:16:19
47631;ALAMIR COSTA   LOURO;UFES;O Futuro da Governança de TI: vale a pena pesquisar uma disciplina que não possui definição de seus limites e de sua essência?;The article aims to reflect on existential issues of Information Technology Governance (GTI) and its academic research. Far from being an epistemological treatise, the article broadens the vision of the discipline, shaping its near future and its importance for delivering value to stakeholders. Its methodology is theoretical and carried out through reflection on: recent academic production and the author's experience as a professional linked to GTI practices. As a result of this reflective process, arguments were obtained to appreciate the relevance of GTI, despite the perception it suffers: lack of identity , interface discipline and prescriptive frameworks without appropriate academic rigor.;;pt_BR;Declined;0;2014;2014-06-05 6:21:54
48086;Mariana Godoy   Vazquez;Centro Estadual de Educação Tecnológica Paula Souza  (CEETEPS);Uma aplicação metodológica para a caracterização de tráfego e avaliação de desempenho da rede wireless de uma Instituição de Ensino Superior;The present work presents a case study of the application of a data collection and analysis methodology for the development of a simulation model, focusing on performance analysis via Queuing Theory, presented in [14]. The objective of this research is to show the application of the methodology in another HEI (Higher Education Institution) - as suggested in Vazquez [14], with not so different topological aspects, but with very different infrastructure and link capabilities. The HEI in the study also has very congested links, especially those dedicated to the wireless network, resulting in lost requests and, consequently, low quality of service. This application showed that, in terms of analytical queuing models, the M/M/1/k model proved to be much more appropriate than the G/G/1, although the service distribution is not exponential, meaning that the capacity of the queue (buffer size) is an important indicator for model construction. The analyzed network has a very small buffer and approximately 60% of requests use the TCP protocol.;;pt_BR;Declined;0;2014;2014-06-24 14:05:20
48113;Carlos Henrique Villa   Pinto;Universidade Federal de São Carlos (UFSCar);Deconvolução Cega Aplicada à Correção de Artefatos de Movimento em Imagens de Vídeo de Microscopia Intravital para Detecção Automática de Leucócitos;Intravital microscopy (IM) is a powerful tool used in the biomedical field for the in vivo observation and imaging of biological systems, having important application in the study of leukocyte-endothelium interactions that occur in the microcirculation of various animal tissues under normal and pathological conditions. As the control of image acquisition conditions in in vivo analysis is quite limited, one of the main obstacles of MI is the presence of blur and motion artifacts in the acquired video frame sequences, arising as a result of breathing and heartbeats. inevitable consequences of the animal. This significantly compromises the detection and tracking of leukocytes throughout the frames, both in visual and automatic analyses. Thus, this work carried out the study and application of blind deconvolution techniques to correct motion artifacts in MI videos. Tests were carried out using two automatic leukocyte detection techniques (pattern matching and local phase symmetry), evaluating the effectiveness of detection in images of good visual quality, images degraded by motion and images restored with two blind deconvolution techniques (deconvblind algorithm and method by Shan et al.). From a precision versus recall analysis, it was concluded that the method by Shan et al. has the greatest potential for leukocyte restoration and that blind deconvolution is useful as a way of pre-processing MI videos.;;pt_BR;Declined;0;2014;2014-06-25 12:44:29
48316;Neireli Rubert   Biavati;Faculdade Educacional de Dois Vizinhos;Proposta de Sistema de Gerenciamento de Marketing Seletivo;This article presents the proposal for developing applications (both mobile and web) that enable the receipt of advertisements and promotions for different types of goods and services, allowing the user to choose to receive only what they deem to be interesting. The development of the proposed project involves the development of a WebService that manages advertisements, in addition to the development of three client applications, one of which is for the registration and management of advertisements by companies, and the other two for viewing and selection by part of end consumers.;;pt_BR;Declined;0;2014;2014-07-01 21:42:57
48422;Gisiéli   Severnini de Oliveira;UNISEP - União de Ensino do Sudoeste do Paraná;Automação do Processo de Regagem de Jardins de Inverno Utilizando Arduino;Plants need frequent care, however, people don't always have the time to care for them. How can technology help in this situation? One of the available technologies that allows solving this problem is the Arduino platform. Arduino was created in 2005 for educational purposes and is based on free software and hardware. This work presents the basic concepts of this platform and also some of the components that can be used, together with it, to carry out a project that will allow communication, real-world data abstraction and automation of the winter garden irrigation process. The choice of theme and technology occurs due to the constant demand for time to grow plants, the interest in encouraging the preservation of the environment and the numerous advantages of Arduino in relation to other technologies on the market, which allow this interaction between objects and people. . As future results, it is expected to automate the irrigation process of a winter garden, facilitating the cultivation of plants and making this process less dependent on frequent care.;;pt_BR;Declined;0;2014;2014-07-06 17:31:27
48578;Bruno Pasquini Baptista   Affonso;Universidade Estadual de Ponta Grossa (UEPG);IMPORTÂNCIA DAS APLICAÇÕES DOS MODELOS DE SIMULAÇÃO PARA SISTEMAS AGRONÔMICOS;The objective of this article is to demonstrate the importance of Simulators in agricultural applications, their benefits in production, warn about the dangers of using pesticides and show how vast the field of Simulation Models is. Showing the design patterns and the differences between the simulators available on the market, this article may be interesting for all those who want to find out a little more about Simulators and their scope.;;pt_BR;Declined;0;2014;2014-07-10 18:38:20
48648;Jéssica   Perin;União de Ensino do Sudoeste do Paraná;Autismo e Tecnologia Projeto e Desenvolvimento de Comunicação Alternativa para Autistas com Dificuldades na Fala;In this work, some concepts relating to autism will be presented, what are the characteristics of people who have this type of disorder, what are their main difficulties in interacting with people and society as a whole. It will be addressed with a special focus, the obstacles faced when communicating with other people, expressing your desires and feelings through words. Analyzing this context, a success case will be presented where a girl with autism begins to use technology without much purpose, and as the days go by, her parents are able to see that through this tool she is able to express her feelings, explains what the world is like in society. vision of an autistic person, a spectacular case of overcoming that serves as inspiration to carry out countless works for people with this type of problem. At the end of the work, a technological solution will be proposed with the aim of helping people with autism to improve their social development and allow communication in an alternative way for those who have this difficulty.;;pt_BR;Declined;0;2014;2014-07-12 21:07:56
48763;Marcos Édison   Griebeler;União de Ensino do Sudoeste do Paraná - UNISEP;Proposta para avaliação da Influência do iBeacon como Ferramenta de Marketing no Retail Brasileiro;With advances in technology, companies are adopting ways to update themselves and improve their relationships with their customers. As the majority of these customers have a mobile device as a means of communication, be it a smartphone or a tablet, with various functionalities, some components are being designed so that retailers can interact directly with them. iBeacon is known for its low-cost transmitters that can notify nearby smartphone devices, which was created to make retailers' lives easier and add technology and interactivity to their businesses. It must be taken into account that this technology is not only being applied in businesses, but is already part of countless places we visit on a daily basis. Therefore, this article will demonstrate the characteristics and tools to implement iBeacon equipment and how it is implemented, in addition to verifying the feasibility of installing communication devices to assist the marketing of Brazilian businesses.;;pt_BR;Declined;0;2014;2014-07-15 22:30:57
49041;Luiz   Velho;IMPA - Instituto de Matematica Pura e Aplicada;Developing Mobile Multimedia Apps, Botanic: A Case Study;This paper describes the development of Jobim Botanic, an App for those who wish to explore Rio de Janeiro’s Botanical Garden, developed by the VIS- GRAF Laboratory in collaboration with the Instituto Antonio Carlos Jobim. It pre- sents the complete process of creating this App, going through all the stages of its lifecycle, from initial concept to final deployment and usage. ;;en_US;Declined;0;2014;2014-07-21 23:18:00
49106;Antônio Carlos   Rocha Costa;PPGCOMP-C3/FURG e PPGC-PGIE/UFRGS;Approaching the Legal Aspects of Agent Societies;This paper focuses, in a prospective way, on the “legal aspects” of agent societies. It argues that their treatment should be carried on separated from the treatment of the other types of normative aspects of such societies, given the increasing possibility of “legal couplings” between agent societies and the human societies in which they may be embedded. The notions of “legal environments” and “legal contexts” are introduced as a means for the structuring of the “internal legal systems” of agent societies, which the paper claims to be essential for the proper treatment of those legal aspects. As one possible modeling and implementation concept, the notion of “legal artifact” is introduced, allowing for an “artifact-based modeling” of legal environments and legal contexts. A brief example illustrates the approach. The Appendix brings a formalization of the notion of “legal system” that oriented the development of the work.;;en_US;Declined;0;2014;2014-07-24 2:33:59
49135;Daniela Maria   Uez;Universidade Federal de Santa Catarina;Prometheus AEOlus: método para modelagem e geração de código em sistemas multiagentes;This article presents the Prometheus AEOlus method, a method for developing agent-oriented software that allows integrated modeling of the agent, the environment and the organization. The proposed method was developed based on the Prometheus method, in which work products were included that allow the detailed specification of the organization and the environment. Guidelines for code generation based on the work products developed were also defined. The abstractions for modeling the environment and organization were defined based on the JaCaMo framework. This method is advantageous because it allows integrated modeling of the three dimensions, with specific concepts being used for each, which reduces the conceptual difference between the modeling and the generated code.;;pt_BR;Declined;0;2014;2014-07-25 18:21:43
49412;Joyce Aline Pereira   de Oliveira;Universidade Federal de Pernambuco;Fatores que Influenciam a Estruturação de um Escritório de Processos em uma Organização Pública;Process Offices (BPMO) have been structured in public organizations with the purpose of formalizing BPM actions and increasing the effectiveness of service delivery to citizens. Peculiarities inherent to this context, such as little flexibility to change and rigidity of the organizational structure, make it difficult for BPMO to consolidate in this sector. This article discusses the factors that positively and negatively influence the structuring of this unit. Among the factors identified are resistance to change, leadership and organizational culture, among others.;;pt_BR;Declined;0;2014;2014-08-05 8:39:47
49684;Eanes Torres   Pereira;Universidade Federal de Campina Grande;Local Binary Patterns Applied to Breast Cancer Classification in Mammographies;Among all cancer types, breast cancer is the one with the second highest incidence rate for women. Mammography is the most used method for breast cancer detection, as it reveals abnormalities such as masses, calcifications, asymmetries and architectural distortions. In this paper, we propose a classification method for breast cancer that has been tested for six different cancer types: CALC, CIRC, SPIC, MISC, ARCH, ASYM. The proposed approach is composed of a SVM classifier trained with LBP features. The MIAS image database was used in the experiments and ROC curves were generated. To the best of our knowledge, our approach is the first to handle those six different cancer types using the same technique. One important result of the proposed approach is that it was tested over six different breast cancer types proving to be generic enough to obtain high classification results in all cases.;;en_US;Declined;0;2014;2014-08-19 15:02:53
49702;Bruno   Crestani Calegaro;Instituto Federal de Santa Catarina;Quantum Monad using Java Closures;Quantum computing is a emergent technology capable to outperform classical computing for certain classes of computational problems but lacks programming languages for describing quantum computation on a high-level abstraction. Researchers in computer science have the challenge to develop new semantic models for programming languages to support the creation, analysis, modeling and simulation of high level quantum algorithms. We address this issue by presenting a monadic Java library, named QJava, for quantum programming based on previous works in Haskell. We exemplify our library with an implementation of the Toffoli quantum circuit.;;en_US;Declined;0;2014;2014-08-20 11:25:02
49798;Geam Carlos de Araújo   Filgueira;Instituto Federal de Educação, Ciência e Tecnologia do Rio Grande do Norte;Gerência de Variabilidades de Linha de Produto de Software Dirigida por Modelos e Aspectos;This article presents an approach for model- and aspect-driven variability management, called CrossMDA-SPL. The approach adopts the technique of model-driven engineering and aspect-oriented development with the central objective of improving the management, modularization and isolation of the variability of the Software Product Lines (LPS) architecture, during the design and implementation phases of software. domain. The approach defines models to promote a clear separation between mandatory and optional features in the LPS architecture, they are: (i) core model – which specifies the features common to all members of the LPS and (ii) variability model – which represents the variable features of the LPS. The composition between such models is carried out through the use of aspect-oriented mechanisms.;;pt_BR;Declined;0;2014;2014-08-25 14:29:09
49962;Andrea Cristina Oliveira   Alves;Fundação Educacional de Oliveira;DESENVOLVIMENTO DE UM MODELO DE PROCESSO PARA IMPLEMENTAÇÃO DE UM ESCRITÓRIO DE GERENCIAMENTO DE PROJETOS NA EMPRESA GERÊNCIANET;This article addresses the development of a process model for implementing a project management office (PMO) in a software development company. With the great growth of information technology companies and the use of project management, the need to implement a PMO in these companies has become vital. The biggest difficulty for organizations is planning the initial definitions of the PMO, that is, creating and implementing project management methodologies for creating a project office. The objective of this article is to demonstrate a process model for implementing a project office based on PMBOK in search of best practices and metrics used in project management. A descriptive research was carried out, in which the data obtained for its preparation were collected through structured questionnaires, which covered the entire structure and way of functioning regarding the projects carried out in the company Gerêncianet. With the research it was possible to verify several flaws in project management and it became clear that the implementation of a PMO in the company would bring great benefits and opportunities for it.;;pt_BR;Declined;0;2014;2014-09-01 15:43:25
50164;Johann Gomes   Barros Lima;Universidade Federal Rural de Pernambuco;Text-Based Data Mining using Classification Algorithms for a Social Impact Software;Social inequality occurs when a group limit, re-proach, discriminate and / or affect the status of another group,class or social circle, decreasing their access to their fundamentalfreedoms, depriving them of their rights assured as humans.Software, acting as a “game-changer” in our society, have greatpotential to produce a positive social impact and can evenreduce inequality through social justice, considering its ubiquityin the modern world. This work, aims to bring relevant socialchange to communities through technology. The implementedsoftware enables victims of discrimination, to write complaintsthrough an application that makes this process easier and faster,using an algorithm to categorize the type of discrimination itrepresents, automatically, by text mining (Text-based Mining).Additionally, a study comparing the performance, observed indifferent Classification Algorithms for the proposed problem ofautomatic categorization of complaints, is conducted. This studyis done using our mass of data, created to train the algorithm,with the objective of predict types of complaints;;pt_BR;Declined;0;2014;2014-09-10 13:03:48
50181;Leandro Marques   Queiros;Programa de Pós-graduação em Informática Aplicada (PPGIA), Universidade Federal Rural de Pernambuco (UFRPE);Inserção de Tarefas Dirigidas à Inovação em Atividades de Desenvolvimento de Software: Um Relato de Experiência;This article presents an experience report on the insertion of tasks aimed at innovation in the context of software development activities. Such tasks are supported by tools provided by the Design Thinking and Business Model Generation approaches. The results presented in this work were achieved from a software project that aimed to build an application, with innovative characteristics, to allow better interaction between members of a university community.;;pt_BR;Declined;0;2014;2014-10-10 8:54:36
50268;Marcos Fialho   Carvalho;PPGI-UFRJ - Programa de Pós-Graduação em Informática - Universidade Federal do Rio de JaneiroNCE-UFRJ - Instituto Tecnológico Tércio Pacitti de Aplicações e Pesquisas Computacionais;Uso de giroscópio para auxiliar pessoas com deficiências múltiplas no uso do Dosvox;This article describes a solution that allows visually impaired people, who are also unable to use their hands, to have access to the Dosvox system, a system that enables interaction between visually impaired people and the computer. Dosvox is one of the most used Assistive Technologies in Brazil by visually impaired people. In this solution, Dosvox, whose operation is originally performed solely via the keyboard, can now be operated via a gyroscope, attached to the user's head, whose movement is translated into a series of keystrokes, chosen to provide full menu operation. of Dosvox, which correspond to a high percentage of interaction with this system. The solution identified several problems to be solved and which were addressed through algorithms and techniques presented in the article.;;pt_BR;Declined;0;2014;2014-09-15 13:17:44
50549;Helton Hideraldo   Bíscaro;USP University of São Paulo;Compressive Representation of Three-dimensional Models;Due to recent developments in data acquisition mechanisms , called 3d scanners , mesh compression has become an important tool for manipulating geometric data in several areas. In this context, a recentapproach to the theory of signs called Compressive Sensing states that a signal can be recovered from far fewer samples than that provided by the classical theory . In this paper , we investigate the applicability of this new theory in order to obtain a compressive representation of geometric meshes . We developed an experiment which combines sampling , compression and reconstruction of various mesh sizes. Besides figuring compression rates, we also measured the relative error between the original mesh and recovered and we analyze the performance of two variations of the technique through its average processing time. The results indicate that the technique is feasible as well , not just in terms of compression, but also paves the way for the creation of compressive acquisition protocols of geometric information , ie compress while that acquired information.;;en_US;Declined;0;2014;2014-09-29 12:09:04
50878;Ronneesley Moura   Teles;Instituto Federal Goiano Câmpus Ceres;Distribuição de Recursos em Áreas Geográficas com Algoritmo Genético;The geographic distribution of resources is a strategic task for organizations that try to predict future resource requests. This problem can be found in many for-profit and non-profit organizations. From distributing taxis in a city to distributing an army in a war scenario. This work presents a genetic algorithm for resource distribution that at its maximum viable capacity can be used in areas of up to 10,000 km2 subdivided into 1 km2 with an execution time of approximately 4 hours. This allows the program to run during the evening hours while the organization is not in operation.;;pt_BR;Declined;0;2014;2014-10-13 20:50:36
51198;Thiago Assis   de Oliveira Rodrigues;PUCMINAS;Predição de Função de Proteínas Através da Extração de Características Físico-Químicas;With the conclusion of the Genome project, the number of new proteins discovered has grown, but due to the high cost and slow process of discovering the function of proteins, only a small portion of them have their function known. This work presents a methodology for predicting protein function through the extraction of characteristics from their structures, present in the Sting_DB database, the use of the Discrete Cosine Transform, the coding of the primary structure, class balancing and the use of Vector Machines. Support. The average values ​​obtained for precision, sensitivity, accuracy and specificity were 80%, 71%, 74% and 77%, respectively. The results were compared with other works in the literature, and showed a 10% increase in the accuracy rate.;;pt_BR;Declined;0;2014;2014-10-26 18:18:01
51414;Themis Patricia Diaz   Morales;Universidad de las Ciencias Informáticas;Mercado de datos Civil-Administrativo del Sistema de Información Estadística Judicial para los Tribunales Populares.;This research arises from the need to manage the information of the Statistics Department of the Supreme People's Court, in the Civil-Administrative area, where data related to divorce and alimony processes, family matters, civil matters, civil sentences are collected. , administrative sentences and appeals. For this reason, in this research, the Civil-Administrative Data Market was developed, where the information is centralized, standardized and easily accessible for consultation. For its development it was necessary to substantiate the methodology and tools to be used. The analysis, design and implementation of the storage, integration and visualization subsystems was carried out, as well as application testing. Finally, the Statistics Department was provided with a data market that stores information from the Civil-Administrative area, which allows historical statistical analysis of the main indicators of this area, facilitating decision-making for the directors of the Supreme People's Court.;;es_ES;Declined;0;2014;2014-11-06 12:40:49
51433;Lucas Pupulin   Nanni;Universidade Estadual de Maringá;Avaliação de Desempenho e Consumo Energético para Configurações de Wavefront Pools de uma GPU AMD;The use of heterogeneous CPU-GPU systems to meet the growing demand for applications with large data parallelism results in the need to study and evaluate such architectures to continuously improve them. In this work, simulations were carried out to execute a benchmark suite on an AMD ATI Radeon HD 7970 GPU, in order to evaluate the impact on performance and energy consumption when changing the number of Wavefront Pools present in each compute unit of the GPU, which is 4 by default. The most significant result shows a speed increase of around 5.7% for the configuration with two Wavefront Pools together with an increase in energy consumption of around 5.1%. However, the other configurations evaluated also represent options for different types of needs, depending on the category of computational demand.;;pt_BR;Declined;0;2014;2014-11-07 15:06:28
51482;Fabíola   Kaczam;Universidade Tecnológica Federal do Paraná;Desafios e Perspectivas da Computação em Nuvem;The decision to invest or hire Information Technology (IT) involves several dilemmas and among them is the companies' investment capacity. Cloud Computing appears as a new possibility for reducing the volumes of these investments, enabling greater flexibility in the demand for services, with very attractive costs. This is a new model in which software is sold as services and accessible anywhere, as long as there is an Internet connection available. Cloud Computing services provide: Service on Demand, Access through different platforms, balancing of Physical Resources, Rapid Elasticity and Measured Service. The Cloud is also characterized according to implementation models: Private, Public, Community and Hybrid. As it is a relatively recent technology, it faces some challenges, such as: Service Availability, Data Centralization, Security, Scalability, Interoperability and Reliability. However, it is clear that Cloud Solutions, in order to keep up with technological advances, are becoming increasingly in demand. The objective of this study is to define Cloud Computing, highlighting its characteristics, challenges and perspectives.;;pt_BR;Declined;0;2014;2014-11-11 14:19:15
51727;Maribel Silva   Muñoz;Universidade das Ciências Informáticas;Modelo de Avaliação da Segurança de Controle de Acesso dos Sistemas Informação para a  Gestão das Organizações.;Access control allows you to restrict and audit user access to organizations' Management Information Systems (MIS) through the integrated design of Identification and Authentication, Authorization and Audit processes. Organization managers need to evaluate this mechanism so that they can make decisions about the information stored. Assessing the access control security of organizations' GIS presents some problems that limit the effectiveness and potential for success when adopting one model or another. independently, or even integrate some evaluation models that exist today. Not having a management structure based on a common approach to best practices and service management in organizational environments negatively affects the way in which managers in organizations where these GIS are implemented should understand and define risks, causes irregularities when defining target areas and areas process in which they must affect security. In this work, we propose a model that integrates indicators and criteria to effectively evaluate the Identification and Authentication, Authorization and Audit processes of organizations' GIS. The model contributes to the integration and synthesis of controls for evaluation, allows continuous improvement, generalization and descriptive measurement of the process. We present a guide to the application and a System for Access Control Assessment (SIECA) based on an assessment algorithm.;;pt_PT;Declined;0;2014;2014-11-18 22:27:32
51984;Eliane Jacqueline de Souza   Guilhen;Mestranda em Administração pelo programa de Mestrado Profissional pela Universidade Estadual do Oeste do Paraná.;ANÁLISE DE AQUISIÇÃO DE SOFTWARE EM UMA PEQUENA EMPRESA;The present work aimed to report the reasons that motivated a manager to check a new software as well as the manager's experience when selecting software acquisition, from a small company located in Cascavel-Pr.During the intervention process carried out, it was noted that the company found it difficult to list what was intended with the replacement of the software, so that this exchange was as assertive as possible, thus aligning expectations with the tools available on the market. The work was divided into three stages: survey of needs, evaluation of alternatives and recommendation of the solution. Thus, the intervention carried out was to provide assistance in this regard and monitoring at all stages. As an instrument to report this intervention, the technical report was used. At the end of all stages it was noted that there is no single software on the market that meets the necessary controls for sale in a bidding process, in addition to the financial unfeasibility of financial viability.;;pt_BR;Declined;0;2014;2014-11-29 6:46:47
52203;Guilherme Defreitas   Juraszek;Universidade do Estado de Santa Catarina;Reconhecimento de Produtos por Imagem Utilizando Palavras Visuais e Redes Neurais Convolucionais;This work consists of recognizing product images, based on three methods: visual words using artificial descriptors Bag of Visual Words (BOVW), convolutional neural networks (CNN) and natural descriptors (obtained through a neural network previously trained in a different basis). In the BOVW technique, the SIFT and SURF descriptors are compared, extracted densely and using MSER, grouped with KMeans and Unsupervised Optimal Path Forest (OPF-U) and classified with Support Vector Machines (SVM) and Optimal Path Forest Supervised (OPF-S). The accuracies obtained in the Caltech 101 database and in a product database with 12 thousand images in 36 categories are evaluated. The CNN as a natural descriptor, together with the SVM classifier, presented the best accuracy with 0.856 in the Caltech101 database and 0.906 in the created database (scale from 0 to 1). The CNN modeled without prior training obtained an accuracy of 0.540 in the Caltech101 database and 0.710 in the created database. Both CNNs tested, with and without prior training, achieved greater accuracy than the BOVW technique.;;pt_BR;Declined;0;2014;2014-12-08 10:19:04
52281;Matheus   Mirapalheta Longaray;Universidade Federal do Rio Grande;An investigation over security issues behind cloud computing;Cloud computing has been a revolutionary moment in the history of technology. The development of the cloud service model delivers business-supporting technology more efficiently than ever before due new resource provisioning techniques and technology advances. It has simultaneously transformed business and government. The change from server to service-based thinking is transforming the way IT departments concern about design, business-level security policies, and applications. However, these advances have created new security challenges. The purpose of this paper is to carry out a survey on cloud data security.;;en_US;Declined;0;2014;2014-12-10 4:00:30
52882;Sylvio Villas Boas   Neto;INPE - Instituto Nacional de Pesquisa Espaciais;Exibição gráfica da alocação de tarefas aos nós computacionais do supercomputador CRAY XE6;The use of supercomputers allowed the Meteorology area to be leveraged, allowing the execution of atmospheric numerical models to generate weather forecasts. Monitoring these supercomputers, and the processes submitted to them, is a fundamental task to guarantee the execution of these applications. INPE/CPTEC currently uses the Cray XE6 supercomputer to execute its Atmospheric Numerical Models. CRAY provides the xnodestat command, which, executed via the command line, informs the state of the computing nodes and the processes running in textual form. Interactive use, with results visualized in textual form, is not suitable in dynamic Information Technology (IT) environments. This work aims to develop a graphical interface for displaying the state of processing nodes in (almost) real time, based on textual information from the xtnodestat command. This tool is implemented at INPE/CPTEC, being extremely useful in monitoring CRAY XE6 and in decision making. In the future, we intend to develop a graphical tool that presents the history of the supercomputer's status in a linear way, allowing the visualization of the best execution periods of an application, among other information.;;pt_BR;Declined;0;2015;2015-01-14 14:48:37
53117;Gustavo Taiji   Naozuka;Universidade Estadual de Londrina;Gerador de Malhas Bidimensionais em Coordenadas Generalizadas Implementado em Python;The use of differential equations as an analysis and description tool in studies of physical phenomena is intensely used. Through mathematical models, it is possible to transform a problem from the physical domain to the computational domain. In this context, the present work presents a two-dimensional mesh generator in generalized coordinates for the domain, which uses the Parameterized Linear Spline method and the numerical resolution of partial differential equations. The generator is automated and capable of handling complex domains and, therefore, more realistic. The code was implemented in Python, applying the numpy and matplotlib libraries for matrix manipulations and graphical plots. Python was used due to the fact that it provided a portable program for a large number of operating systems, coded under a free platform, general purpose and developed collaboratively.;;pt_BR;Declined;0;2015;2015-01-28 9:25:29
53191;Fábio Bulegon   Zappas;Centro Universitário La Salle;Aplicativo Android como alternativa de acesso ao ambiente virtual Moodle e a consequência no tráfego de internet;Summary: The advancement of mobile computing is expanding the way in which people use the internet. With this transformation, it becomes necessary to evaluate new teaching tools using mobile devices. Based on this scenario, this work proposes to evaluate alternatives regarding the use of the Moodle virtual learning environment in Android operating systems, helping users with the use of the environment. Furthermore, carry out a theoretical-practical study involving the planning and development of an application that meets the main interaction needs with Moodle. Through quantitative and qualitative evaluations, it was found that the application developed in native code requires less internet traffic, in addition to providing the user with greater ease and efficiency in interacting with the virtual environment.;;pt_BR;Declined;0;2015;2015-01-30 11:00:14
53322;Igor Augusto de Carvalho   Alves;Universidade do Estado do Rio Grande do Norte;ESPECIFICAÇÃO FORMAL DE ESCALONADOR RECONFIGURÁVEL PARA SISTEMAS DE TEMPO REAL;The quest to meet the timing and parallelism requirements of new applications has made scaling a very complex task, especially when it comes to real-time systems and MPSoC. Most solutions scale through operating systems. However, one way to improve performance is to migrate scheduling to a reconfigurable hardware component, aligning performance and flexibility, as they are capable of implementing different scheduling policies. Hardware solutions, however, use simulation and emulation techniques for quantitative analysis that may not be sufficient to detect failures. This work uses formal methods to specify a hardware scheduler for real-time systems capable of using different scheduling policies. The qualitative approach used allowed formal reasoning about the project, modeling its structure and behavior to ensure the validation of essential requirements, in addition to enabling the reuse of validated components.;;pt_BR;Declined;0;2015;2015-02-06 15:50:30
53334;Daniel   Formolo;Universidade do Vale do Rio dos Sinos - UNISINOS;Um Modelo para Otimização de Tráfego de Pacotes em Redes de Provedores de Internet;This work proposes a CDN (Content Delivery Network) architecture model focused on optimizing redundant packet traffic in internet provider networks, complementing existing solutions, with a low cost of updating the already installed infrastructure. This work analyzes how a CDN data management model can improve the use of data traffic in internet provider backbones. The results of this study show that the proposed architecture is particularly interesting in regions where the market is mature and there are several internet providers operating. In these markets, a reduction in investment costs and an increase in the quality of services provided are projected.;;pt_BR;Declined;0;2015;2015-02-07 0:28:32
53844;Ana Paula   Correia Silva;Universidade Estadual de Mato Grosso do Sul;OpenCV e Redes Neurais: Captura e Reconhecimento de Caracteres;For many years, researchers in the exact field have been developing mathematical concepts and algorithms to solve various problems. Among them is the computer vision model, which aims, through image processing and object recognition, to make a computer see like a human being. The objective of this work is to contribute to this area with a system capable of recognizing alphabetic characters and providing a response to "learning", becoming yet another tool that opens up broad possibilities in the field of computer vision together with the use of artificial neural networks. To achieve this, an extensive study was necessary in related areas and throughout the OpenCV library, which is currently the largest and most used repository of functions that help the development of numerous related projects in the area.;;pt_BR;Declined;0;2015;2015-02-27 18:38:23
53911;Giovana Angélica   Ros Miola;Faculdade de Tecnologia de Presidente Prudente;Uso de alvos baseados em correlação estrutural para reconstrução de fachadas de edificações derivadas do sistema laser terrestre;Currently, there is an intense evolution of technological resources, whether for hardware or software, which means constant changes are necessary, an example of which is terrestrial laser scanner equipment. The same, allows the capture of three-dimensional data, on the physical surface with an overabundance of information, quickly, safely, accurately and is currently used in urban areas, where there is a great complexity of information regarding the details of a building and its representation and storage in computational means becomes difficult, therefore, the objective of this work was to use targets, in this case straight lines, based on structural correlation, arising from the intersection of adjacent planes of point clouds, derived from the terrestrial laser system for reconstruction of building facades. To this end, laser data, the C++ programming language and the PCL library intended for manipulating point clouds were used to develop the research. In the end, it was found that the result was satisfactory, demonstrating the registration of point clouds. points and three-dimensional representation.;;pt_BR;Declined;0;2015;2015-03-02 15:35:52
54283;Chaiene M. da Silva   Minella;UNIVALI - Universidade do Vale do Itajaí;Sistema Especialista para Diagnóstico de Processos em Organizações Intensivas em Software;This work presents the development of an expert system to support the automated diagnosis of an organization's software development life cycle. The methodology involved the participation of experts in the area of ​​process improvement and software-intensive organizations, in which the development went through the phases of literature review, decision tree modeling, construction of the expert system and evaluation of it. The main objective of automated diagnosis is to evaluate the current situation of the organization's processes, identifying weak and strong points that will serve as a basis for process improvement initiatives. The evaluation of the results obtained with the application of the expert system was carried out from the point of view of 7 experts and 6 organizations and is also presented.;;pt_BR;Declined;0;2015;2015-03-17 16:07:37
54312;César Eduardo   Guarienti;UFMT;ELEVAÇÃO DO NÍVEL DE SEGURANÇA EM SERVIDORES WEB  UTILIZANDO NGINX;This article demonstrates a reverse proxy solution that was successfully implemented at the Computing Institute (IC) of the Federal University of Mato Grosso (UFMT), Cuiabá campus. To provide services to a larger number of people, several web servers are made available on the Internet. With the reduced number of public IP addresses available, it is important that these resources are made available in an organized way that allows centralized control. Through unique management, it is even possible to increase the level of security. This study demonstrates that it is possible to create an additional layer of security between client and server.;;pt_BR;Declined;0;2015;2015-03-18 10:54:04
54375;Juan Carlos Alvarado   Alcocer;Instituto de Engenharias e Desenvolvimento Sustentável - IEDSMestrado em Biodiversidade e Tecnologias Sustentáveis - MASTSUniversidade da Integração Internacional da Lusofonia Afro - Brasileira (UNILAB);Desenvolvendo um Software Para Realizar a Análise entre a Correlação da Energia Requerida pela Companhia Energética do Ceará e a Precipitação Pluvial.;The main objective of this work is to show the correlation between rainfall indices and the Energy Required in the State of Ceará using the period from 1975 to 2005 in order to evaluate the inclusion of these indices as explanatory variables in the load forecasting models used by Companhia Energética. of Ceará (COELCE), thus reducing the risk of errors and improving the definition of energy purchase amounts to serve consumers. This will result in lower tariffs.;;pt_BR;Declined;0;2015;2015-03-22 14:26:26
54483;Alex   Costa;Universidade Regional Integrada do Alto Uruguai e das Missões - URI;Extensão do middleware QMachine para flexibilizar a utilização de computação voluntária via browser;This work extends the QMachine volunteer computing middleware, allowing developers and volunteer users to manipulate it. The choice was made through a comparative study between eight web middlewares, where their characteristics were surveyed and compared using six decision criteria. Practical usage tests were also carried out, demonstrating the validation of the software requirements raised and managed through the SCRUM methodology.;;pt_BR;Declined;0;2015;2015-03-25 23:28:23
54551;Junior Silva   Souza;Universidade Federal de Mato Grosso do Sul;Identificação de Viabilidade de Leveduras Com Corante Vital Utilizando Histogramas de Palavras Visuais em Imagens Coloridas;This article presents a proposal to automate the viability classification of yeasts of the species Saccharomyces cerevisae, responsible for the commercial production of ethanol, using as an attribute the color absorbed by the vital dye methylene blue. The methodology is widely used in plants in Brazil and consists of counting the colorless cells that are considered viable, separating them from those colored blue, considered non-viable. The number of viable cells per liter affects industrial yield. As this counting is tiring and results in errors, we present as an alternative the computer vision technique defined as the Bag-of-Word algorithm (histogram of visual words), as well as some extensions that add color information and that can be added to the algorithm. , this is because Bag-of-Word is used for grayscale images. The attributes extracted from this algorithm with its extensions were used for testing and training classifiers extracted from supervised learning algorithms. Among the classification algorithms we use we can highlight J48, SMO, Naives Bayes and IBk which are implemented in the WEKA environment. The results were analyzed using ANOVA, which presented a p-value < 2e-16, indicating a statistical difference between the techniques analyzed. The Opponent Color technique showed better results, representing a potential for application in real plant conditions.;;pt_BR;Declined;0;2015;2015-03-29 11:02:57
55223;Danilo Heitor   Melo;Universidade Federal da Bahia;Decifrando o processo de georreferenciamento no ArcGIS;The insertion of geographic data into a Geographic Information System requires it to have spatial reference. If not, you need to carry out the georeferencing process. Currently, this task has become routine in GIS, being performed quickly and easily. However, this is a fundamental task and when not carried out correctly, it compromises the result of the work, especially cartographic quality. The objective of this work is to present the georeferencing process of a Digital Topographic Map, from its insertion in the software to the final product, the Georeferenced Digital Topographic Map. For this purpose, a map prepared by IBGE was used. For the development of georeferencing, the Topographic Map of Boquira was selected, using the ArcGIS software, version 10.2 and the work demonstrated step by step how to carry out this processing.;;pt_BR;Declined;0;2015;2015-04-30 14:53:56
55842;Nathalia Moraes   Nascimento;Pontifícia Universidade Católica do Rio de Janeiro (PUC-Rio]);Internet das Coisas para Conservação de Frutas: O Caso da Banana;Imagine a device capable of measuring in advance the real shelf life of a fruit according to local storage conditions? Or to indicate the possible percentage of load loss when transporting fruit? Based on this information, the entire process of supplying fruit to the market could be meticulously monitored, from the boxes used for transportation and distribution of post-harvest fruit, to those for displaying fruit in markets and fairs. Consumers could also monitor them indoors. A series of questions related to fruit storage time could be answered: (i) Is it better to store fruit in the refrigerator? (ii) Should I leave it in a closed container? (iii) If I wash it before storing it, will it spoil faster? (iv) Does light interfere with fruit ripening? We understand that the actual shelf life of a food varies according to the environment in which it is immersed. And, by having this information, the huge post-harvest fruit waste can be significantly reduced. The purpose of this work, therefore, is to present the device called "Quantified Fruit". This device allows you to monitor and make inferences about where a fruit is stored, making the information available on the Internet. To this end, environmental data is monitored, such as temperature, humidity, light and some gases that interfere with the fruit's ripening process. Different fruit stocks collect and share this data, so that a rot pattern is established, allowing the device to quantify the expiration date of the fruit given certain environmental conditions.;;pt_BR;Declined;0;2015;2015-05-22 14:52:51
56127;Rafael   Glauber;Universidade Estadual de Feira de Santana;Mineração de Textos em Help Desk: um estudo de caso;Support service data for customers of software development companies are recorded in Help Desk systems. Textual records recorded in this type of system can constitute a source of information for the organization. This work proposes Data Mining in a real Help Desk database, seeking to identify patterns in the stored data. The results obtained with the material used demonstrate that this type of research can constitute a technological basis for solutions to support the customer service management process.;;pt_BR;Declined;0;2015;2015-05-30 22:24:10
56185;Victor Manaia Gonçalves   Chaves;Universidade Estadual do Ceará, UECE, Mestrado Profissional em Computação Aplicada, MPCOMP;Descoberta de Conhecimento em Dados Textuais Utilizando Gerencimento Ágil de Projetos;This work presents AKDT, a framework for knowledge discovery in texts, composed of process models for agile project management and knowledge discovery, supported by a computational architecture and a set of artifacts to record decisions throughout the project execution. The main contribution lies in combining agile management aspects with knowledge discovery activities in a modular way, enabling monitoring and control in a simple way. From this perspective, a proof of concept is also presented that evaluated the proposal, the results of which indicate that the use of the model is viable and productive;;pt_BR;Declined;0;2015;2015-06-01 19:41:13
56599;Douglas   Rosemann;Univali;Sistema Tutor Inteligente Bayesiano para um Ambiente Virtual de Aprendizagem de Código Aberto - Uma experiência no Ensino de Estrutura de Dados;Virtual Learning Environments (VLE) are developed to support the teaching-learning process. The student interacts with the environment, and it guides students in conducting their studies, through the interaction of the teacher as a tutor or through intelligent tools. VLE Moodle stands out for being open source and adaptable, which allows exploring the application of an Intelligent Tutor System (ITS) with the insertion of an Artificial Intelligence (AI) technique called Bayesian Networks (RB), thus enabling personalized instruction. By implementing blocks in VLE Moodle, it was possible to develop a structure for content personalization. Furthermore, it allowed the application of other evaluation criteria in addition to content tests, which made it possible to measure a student's level of learning. At the end, a teacher also contributed with his analysis regarding the assessment format applied.;;pt_BR;Declined;0;2015;2015-06-21 19:36:40
56717;Caio Lélis   Couto;Faculdade Independente do Nordeste;UTILIZAÇÃO DA REALIDADE VIRTUAL E AUMENTADA NA REABILITAÇÃO COGNITIVA;This article is a bibliographical review of studies on the possibility of Cognitive Rehabilitation using Virtual Reality, an advanced interface that allows real-time interaction between users in three-dimensional computer environments, and Augmented Reality, a real-time overlay of the physical world with objects generated by a computer. The objective of this article is to identify the points that show how the use of this technique can help alleviate cognitive problems based on comparative analyzes between studies on the topic. Cognitive degeneration is a problem that can affect several areas, including: difficulty concentrating, memory loss, difficulty with judgment and reasoning, among others. Using the concept of existing treatments, research carried out by third parties disseminates the use of Virtual Reality and Augmented Reality in the cognitive rehabilitation of patients.;;pt_BR;Declined;0;2015;2015-06-26 20:35:14
56879;Thábata   Amaral;Universidade Federal de Mato Grosso do Sul;Elaboração De Uma Base De Conhecimento Como Instrumento De Auxílio Na Classificação Dos Gastos.;Knowledge bases are fundamental instruments for organizations that aim for stability, effectiveness and precision in their activities. They enable quick retrieval of knowledge, in addition to minimizing the occurrence of errors that are portrayed in it. Expense is a generic concept that encompasses the others and it is often embarrassing, even for an expert, to determine the type of expense incurred. In this sense, it is desirable that an aid instrument be present to guide the specialist during decision making. The present work proposes the conception of a knowledge base that allows the reception of various characteristics (attributes) relating to expenses, thus simplifying their differentiation between investment, cost, expense, loss and waste. To validate the knowledge base, the idea of ​​an information system known as Case-Based Reasoning was used, which allows retrieving, from a case described by the user, the case most similar to the one defined. This idea was applied in a case study delimited by a hypothetical situation whose aim was to identify the type of expense. The result obtained with the application of the case study was satisfactory and consistent with reality, thus validating the premise of the knowledge base.;;pt_BR;Declined;0;2015;2015-07-03 12:03:02
57075;Jeferson Costa da   Silva;UNIVERSIDADE FEDERAL DE RORAIMA;Sistema de Classificação Neuro-Fuzzy de Dados Escolares com Validação ROC;This research describes the concepts for implementing a neuro-fuzzy school performance classifier. Classifying school performance information is considered a linear task as it involves values ​​(Attributes), such as: grade, percentage of attendance (punctuality) and number of student failures in a subject. The objective is to implement a neuro-fuzzy classification system to qualify students' performance in fuzzy concepts (Fuzzy Classes) such as: terrible, bad, regular, good and excellent. Based on numerical information contained in the StudentsDataset with the attribute values, a classifier based on the ANFIS neuro-fuzzy learning and classification model is developed. Complementations in scripts of the statistical programming language R. In addition to implementing the neuro-fuzzy model for training and testing the neural network, scripts are developed, with the ROC methodology (ROC Curves), to validate the model, using the ROCR package of the language R, presented at the end of the research.;;pt_BR;Declined;0;2015;2015-07-14 15:07:28
57152;Hudson Santos   Lapa;Universidade Tecnológica Federal do Paraná;ALGORITMO PARA PROCESSAMENTO DE DADOS EM TEMPO REAL;This article was developed from the scientific initiation project “Monitoring the ionosphere in almost real time from GNSS NTRIP networks”, which aims to correct and update the GI application algorithm, convert the application from a Windows environment to Linux and for C and C++ languages, as well as adaptations so that the application remains in continuous operation mode, 24 hours a day, executing GNSS data processing in real time. The problem with modeling the ionosphere is developing or improving methods capable of providing GNSS users with reliable ionospheric corrections, in real time and using simple data transmission structures. The GI application can estimate the ionospheric delay and its confidence level, considering the peculiarities of the equatorial region, in order to compensate for the systematic effect of the ionosphere on the GNSS observable and provide integrity information, using the ionospheric grid concept and can also generate real-time or post-processed TEC maps. Keywords: GNSS NTRIP Real Time GI Application.;;pt_BR;Declined;0;2015;2015-07-17 14:00:25
57190;Lanylldo Araujo   Santos;Licenciado em Informática - UFMAMestre em Engenharia da Computação e Sistemas - UFMA;Um Modelo de Arquitetura para Gerenciar a Criação de Recursos Educacionais Abertos em Núcleos de EaD;This article presents the partial results of a research that aims to propose an Educational Design tool to be used in Distance Education Centers, as a computational resource to assist from the stage of creating a teaching material, through its packaging as an object of learning (OA) using a metadata standard, until its distribution in an educational resources repository. To design the Software, standards for creating OA existing in the literature were taken into consideration, as well as a survey of information carried out with a multidisciplinary team that creates OA at a University in Brazil.;;pt_BR;Declined;0;2015;2015-07-19 21:34:56
57278;jose vigno   Moura Sousa;Universidade Estadual do Piauí;FA-OLSR: Fuzzy Ant Colony Optimization aplicado ao protocolo OLSR;Wireless Mesh Networks (WMN) are multi-hop networks composed of fixed and mobile nodes, communicating wirelessly with a focus on supporting Quality of Service (QoS) for applications. In many cases, these fixed nodes are not battery powered. Therefore, routing protocols must deal with reliability and performance improvements, rather than mobility or energy savings. Additionally, the multi-hop wireless nature of a WMN demands a different routing approach from conventional wireless networks. The strategy proposed in this work consists of optimizing the operations of the Optimized Link State Routing (OLSR) routing protocol. OLSR is a proactive protocol designed for mobile ad hoc networks. The route quality value is estimated using the Expected Transmission Count and Route Delay values. An Ant Colony Optimization (ACO) algorithm is used to automatically adjust the fuzzy system's rule base, with the aim of improving the throughput and information transmission time in the WMN. Tests were carried out on the ns-2 simulator using a realistic scenario to validate the approach.;;pt_BR;Declined;0;2015;2015-07-23 15:25:50
57349;Anderson Afonso   Nunes;Universidade Tecnológica Federal do Paraná;Restrições no Espaço de Busca na Geração de Estruturas de Coalizão Utilizando Grafos;Generation of coalition structures involves partitioning the set of agents into disjoint coalitions in order to maximize social welfare. What makes this problem so challenging is the number of possible coalitions is exponential. There are two main ways to solve this problem. The first way, basically enumerates all possible solutions and the second, uses restrictions to limit the feasible coalitions. New approaches use graphs, where the edges represent a vital synergy link, such as communication. A coalition is feasible only if the members meet a certain criterion, such as: connected induced subgraph (SIC) or a clique. We verify the limits of using graphs as restrictions on the formation of coalitions and, in particular, the impact of using clique as a criterion for the formation of coalitions. We analyze the impact of different definitions of feasible coalition. For Kn-1,1 star graphs, mathematical calculations were used that provide the numbers of connected induced subgraphs and cliques based on the number of vertices in the graph. We observe that a coalition being a connected subgraph does not present a significant reduction. But considering that a feasible coalition must be a clique, the reduction seems attractive for use by algorithms for generating coalition structures.;;pt_BR;Declined;0;2015;2015-07-27 21:11:31
57503;Khalid   Belhajjame;Université de Paris - Dauphine;piSODM: Building SOC Applications in the Presence of Non-Functional Requirements;Specifying non-functional requirements (NFRs) is a complex task, being usually dealt with on the later phases of the software process.The late inclusion of NFRs in the development may compromise the quality of the deployed application.This paper presents piSODM, a method and associated tools that(i) allows the early specification of NFRs in a principled way: users are abstracted away from low level details(ii) embraces the MDA philosophy, generating models (code) whenever possible.Our solution has been used in the context of an industrial and real case study.;;en_US;Declined;0;2015;2015-08-03 13:01:28
57629;Anne Rose Alves Federici   Marinho;Universidade Federal do Rio de Janeiro;Sobre o uso e a importância de algoritmos certificadores;Certifying algorithms are algorithms that return not only the solution to the problem they are intended to solve, but also a simple and efficiently verifiable certificate that such a solution is correct. In this article, we argue in favor of the use of certifying algorithms for the computational solution of problems in general, to the detriment of classical, non-certifying algorithms. The central point is that the former are protected against possible --- and, certainly, common --- errors introduced inadvertently by the programmer, while the latter, in these cases, would present unpredictable responses, probably incorrect and with undesirable effects. After a brief coverage of the theory of certification algorithms, we proceed to the analysis of three very illustrative examples, highlighting the necessary care regarding the completeness of the verification.;;pt_BR;Declined;0;2015;2015-08-05 14:40:23
57696;André Luiz   Souza;UFTM - Universidade Federal do Triângulo Mineiro;Software Web para simulação do modelo dinâmico inercial rígido em sistemas hidráulicos;This project aims to develop a software system that allows the simulation of hydraulic networks, evaluating the behavior of water in supply systems based on the Rigid Dynamic Inertial Model (MDIR). The steps and processes applied in the development of the MDIR (Rigid Dynamic Inertial Model) software are presented. The use of software engineering techniques in conjunction with internet development and programming technologies has made possible an environment for creating distribution networks and analyzing water behavior in both permanent and non-permanent regimes. The mathematical model used in the development of this project considers the effect of inertia in simulations, unlike Epanet which is the most widespread software system in the area. The use of free access and use libraries available on the internet, such as Jointjs and Google Chart Tools, helped to implement user-friendly and feature-rich interfaces. The final product resulting from this work is available on the internet at http://mdir.sqlweb.com.br for access and use by anyone interested in the topic.;;pt_BR;Declined;0;2015;2015-08-07 14:45:08
57776;Andre Alessandro   Stein;Univali - Universidade do Vale do ItajaíIFC - Instituto Federal Catarinense;Filtro de Difusão Anisotrópica em FPGA;Filtering digital images aims to smooth and remove noise and help highlight the edges of these images. The Anisotropic Diffusion Filter is a filtering technique recognized by the scientific community and offers satisfactory quality at an average computational cost, compared to other pre-processing filters. This article presents an implementation of the Anisotropic Diffusion Filter in the form of the data path of a special purpose processor synthesized in a programmable logic device. The implementation carried out is compared with the execution of the algorithm written in a high-level language on a general purpose embedded processor, both synthesized in a programmable logic device. The results obtained demonstrate that the proposed solution performs around 4566 times better than the software implementation. These results demonstrate the feasibility of accelerating the execution of this algorithm through a dedicated hardware implementation.;;pt_BR;Declined;0;2015;2015-08-12 11:25:44
57990;Ion Ferreira   Patruni;Universidade do Estado de Santa Catarina;Detecção de Pessoas e Carros com Classificadores SVM Baseados em Fluxo Óptico e HOG;This article presents a method for intrusion detection to support Closed Circuit Television (CCTV) operators. In this method, features extracted from a dense Optical Flow (FO) vector field are used to train a linear Support Vector Machine (SVM) as the first stage of cascaded classifiers. Image regions selected by this classifier potentially as people according to Optical Flow behavior, are redirected to the second stage based on Histograms of Oriented Gradients (HOG). The proposed system is designed to be used primarily with surveillance videos. Therefore, movement is important information captured by FO. To evaluate this method, a new metric was proposed to measure the intrusion event that simulates an alarm sent to a CCTV operator. This metric is based on the criterion of persistence of detections and proved to be effective in generating alerts. The cascaded use of the two classifiers FO and HOG presents a better performance than that obtained by the HOG classifier alone.;;pt_BR;Declined;0;2015;2015-08-22 18:25:43
58065;Bruno Pereira   Palma;Universidade Federal do Rio de Janeiro;PRM: Uma Análise Estatística dos Melhores Métodos;In recent years, many studies have emerged studying robot route planning in static or dynamic environments. Probabilistic roadmaps are one of the most used approaches in route planning with static environments. One of its main advantages is that after building and investigating the map, any pair of nodes (departure and arrival) provided already have a calculated solution, if this solution is possible. In recent years this technique has been studied by different researchers and this has generated a large number of variants, each with its own merit. It is difficult to compare different techniques because they are tested in different types of scenarios, using different software, implemented by different people and on different machines. The objective of this work is to study these different approaches and suggest improvements to the robot locomotion algorithm in complex spaces. In this study, the random methods, cell method, obstacle-based method and the use of components were analyzed in more depth.;;pt_BR;Declined;0;2015;2015-08-28 18:09:55
58124;Eryca Tatyane   Martinho de Amorim;Universidade do Estado do Rio Grande do Norte  e Universidade Federal Rural do Semi-Árido;OTIMIZAÇÃO POR COLÔNIA DE FORMIGAS APLICADA AO SEQUENCIAMENTO DE TAREFAS NO RAMO DE PETRÓLEO;This work proposes to show the applicability of scheduling tasks for launching oil pipelines using the ant colony metaheuristic to solve the flow shop problem. This problem is classified in the literature as NP-hard and consists of determining the task sequencing of a project, aiming to minimize the makespan in the project, the total process time, as well as managing the available resources in an optimized way, all of this considering the precedence restrictions between tasks, thus providing a sequence of services to be executed. To this end, four parameters were developed to compare the efficiency of the application, being two schedules, executed by Microsoft Excel, called sequential and parallel, the optimization by the ant colony implemented in Java and the optimal values ​​found by CPLEX via MATLAB. Regarding the results obtained by CPLEX and optimization by the ant colony, we have a GAP of up to 3% in the value found for the makespan, with the optimization by the ant colony being resolved in less computational time.;;pt_BR;Declined;0;2015;2015-08-29 18:08:35
58167;Karla Raphaela   Cardoso;Universidade Federal Rural do Semi-Árido - UFERSA;Um estudo sobre a definição de estratégias para o jogo de BlackJack usando técnicas de aprendizagem de máquina e sistemas fuzzy;BlackJack is a card game played by one or more players and a croupier (table owner), whose objective is to obtain more points than the table, but without exceeding 21 points. Even if nothing influences the outcome of the cards, there are techniques that help predict the decision to be made according to the player's hand in the round. Such BlackJack strategies used today come from the 1960s, when mathematicians using probability applied their knowledge in hundreds of BlackJack games and developed their strategies. However, these strategies are quite complex, which makes it difficult for the player to memorize each action to be taken according to the configuration of the cards. In this context, this work focuses on discovering a way to minimize the casino's advantage and turn the odds in the player's favor using gaming strategies. Therefore, large sets of data containing information relevant to thousands of BlackJack games were produced and analyzed, aiming to extract relevant rules that favor the player in relation to the casino. The present work uses artificial intelligence algorithms, specific for classification and association together with fuzzy logic, specifically Apriori, FuzzyDT, Fuzzy FCA, C4.5, PART and Ripper in order to extract relevant rules from BlackJack. The generated rule sets were used in a range of match settings and the results produced were compared and evaluated.;;pt_BR;Declined;0;2015;2015-08-31 11:13:33
58272;Melquizedequi   Cabral dos Santos;Instituto Federal Sertão Pernambucano (IF SERTÃO-PE);O Impacto do Scrum e XP na Satisfação dos Stakeholders: Um Estudo Sistemático;Context: Studies show the growth in the adoption of agile methodologies, however, there is still a lack of evidence on how the use of such approaches influences software development. One area that still presents research gaps is related to stakeholder satisfaction in the software project. Objective: This study aims to identify, from a secondary study, the impact of the Scrum and XP approaches on stakeholder satisfaction in software projects. Method: To achieve the objectives, a systematic literature review was carried out following the guide proposed by Kitchenham. Results: The research resulted in the identification and modeling of the impacts of methodologies on stakeholder satisfaction. Conclusions: it can be seen that there is a low number of studies that address the issue of the impact of agile methods Scrum, XP on stakeholder satisfaction. It can be concluded that there is a need for more research in this area using the various existing empirical methods.;;pt_BR;Declined;0;2015;2015-09-02 13:26:36
58287;Raquel Romes   Linhares;Universidade Federal de Uberlândia;A plataforma JAVA como facilitadora no ensino de Estatística;Statistical research is carried out, in general, based on the formulation of hypotheses. Verification of these hypotheses can be done through the planning of experiments. From these observations emerge, which in turn are analyzed. These steps, from planning to analysis, are covered by an area of ​​Statistics called Experiment Planning and Analysis. Here we present a graphical and intuitive interface for teaching statistical content related to Experiment Planning and Analysis. We use the JAVA platform as a facilitator so that mathematical operations that are purely and simply repetitive are the responsibility of the software, allowing the student to focus on interpreting the data.;;pt_BR;Declined;0;2015;2015-09-02 20:56:26
59303;ABDELLATIF   HAIR;Sultan Moulay Slimane University;Viewpoint oriented development: Towards a comprehensive approach to multi-targets code;In order to generate multi-targets code in viewpoint-oriented development, several approaches are developed, but they are either not comprehensive, or not well defined. In this paper we present a comprehensive and well-defined view implementation pattern by using the extension mechanisms for UML, that is, stereotypes, constraints, and tagged values. The paper also proposed profile for the viewpoint-oriented development. ;;en_US;Declined;0;2015;2015-10-13 8:02:26
59588;MARLON De Oliveira   VAZ;IFPR / UTFPR;Detecção de Tubos em Imagens Radiográficas Digitais;This article presents a methodology for tube detection in double wall double view (PDVD) radiographic images of oil pipes. The main objective of the proposal is to reduce the search region by delimiting the tube area for the automatic extraction of the weld bead, thus helping the subsequent detection of defects in welded joints. The tube detection process presented is fully automatic and based on image processing techniques such as brightness and contrast adjustments, thresholding and analysis of the regions identified for tube segmentation. The process was applied to 167 images from three different radiographic systems, obtaining a result of 90.4% accuracy in detecting the tube. A comparison was made with another approach for tube detection in PDVD type radiographic images and the proposed methodology showed an improvement in relation to previous work. It is concluded, therefore, that the proposed method can be used as a step that precedes the automatic detection of the weld bead.;;pt_BR;Declined;0;2015;2015-10-26 15:20:53
59767;Almir Olivette   Artero;Faculdade de Ciências e Tecnologia/Universidade Estadual Paulista;Estudo Comparativo do desempenho de diferentes Operadores Genéticos na Resolução do  Problema do Caixeiro Viajante;This work presents a comparative study of the performance of different combinations of genetic operators commonly used to solve the Traveling Salesman Problem. The evaluation was carried out with several instances of the symmetric version of the problem. Nine genetic operators were selected, three for selection, three for crossover and three for mutation. The tests were carried out with and without the use of elitism for all possible combinations. The results obtained showed that the Tournament selection operator was superior in relation to the other operators. The CX operator, in turn, presented the best performance among the crossover operators and the Inversion outperformed the other mutation operators. Additional experiments were also carried out for different elitism and population values. The best results from these additional tests were obtained with populations of 300 and 500 chromosomes and a 1% elitism rate. It was also found that the increase in randomly generated chromosomes in the population does not lead to superior solutions.;;pt_BR;Declined;0;2015;2015-11-03 15:23:16
59966;Hugo Wendell   Maia;Universidade Federal Rural do Semi Árido;Proposta de Classificador de Lesões de Pele Utilizando Características de Forma, Cor e Textura;Skin cancer is the most common of all cancers. Melanoma is a type of malignant skin cancer, responsible for many deaths around the world. Early diagnosis of this type of cancer increases the patient's chances of cure. One of the ways to make this diagnosis is through dermoscopy, which consists of recognizing structures present in the skin, not visible to the naked eye. With the help of a dermascope, equipment that magnifies the image, the doctor recognizes these structures and diagnoses the lesion. However, despite analyzing the image in an expanded way, several factors negatively influence the diagnosis. Thus, aiming to assist the use of dermoscopy by health professionals, the present work proposes the development of a methodology that uses a combination of shape, color and texture characteristics. In addition to the combination, a comparison is also made with related works, verifying the efficiency of this work.;;pt_BR;Declined;0;2015;2015-11-10 19:41:44
59975;Alex Lima   Silva;Universidade Federal Rural do Semi-árido;Proposta de um método híbrido para reconhecimento de faces;Automatic facial recognition technology has provided great advances in the interaction between man and machine. One of the main challenges for researchers in this area is to develop and improve methods that are capable of making inferences about new patterns, not restricted to just memorizing facial characteristics. Knowledge about the state of the art makes it possible to develop more efficient methods for recognizing these patterns. This work presents a bibliographical review of facial recognition methods restricted to images of faces in two dimensions and shows, through a comparative analysis, advantages and disadvantages of these methods in different test environments, aiming to provide support to researchers in the area.;;pt_BR;Declined;0;2015;2015-11-11 15:06:41
60080;Marcio Fernandes   Cruz;Universidade Paulista;UMA APLICAÇÃO PARA INTERPRETAR SINAIS DO ALFABETO DIGITAL DE LIBRAS;This work presents a study of image processing concepts and techniques that aim to recognize patterns. Using Computer Vision techniques, the challenge is to create an artificial device that performs the function of human vision in the problem of recognizing signs of a digital Libras alphabet. In this question, the problem is defined, which is specifically recognizing gestures from a digital alphabet of this sign language. At the end, the study is discussed and a proposal for future work is suggested, which, in this case, we give as an example the recognition of the Libras language itself and not just its digital alphabet.;;pt_BR;Declined;0;2015;2015-11-17 13:28:18
60217;Marcio Fernandes   Cruz;Universidade Paulista;UMA APLICAÇÃO PARA INTERPRETAR SINAIS DO ALFABETO DIGITAL DE LIBRAS;This work presents a study of image processing concepts and techniques that aim to recognize patterns. Using Computer Vision techniques, the challenge is to create an artificial device that performs the function of human vision in the problem of recognizing signs of a digital Libras alphabet. In this question, the problem is defined, which is specifically recognizing gestures from a digital alphabet of this sign language. At the end, the study is discussed and a proposal for future work is suggested, which, in this case, we give as an example the recognition of the Libras language itself and not just its digital alphabet.;;pt_BR;Declined;0;2015;2015-11-21 16:34:48
60238;Lázaro Nogueira   Pena Neto;Universidade Federal do Triângulo Mineiro;Análise experimental do funcionamento de um cluster via computação distribuída;This article explains how a standard Bewoulf computing cluster works. The principle of physical construction of the cluster and its logical organization of systems are developed. The cluster is tested by a quantitative algorithm to calculate specific quantities so that operations can be distributed among its nodes. With this study, procedures are systematized that can be applied in future work involving high performance and use of computers, difficulties are reported and the planning and construction of this shared model are outlined.;;pt_BR;Declined;0;2015;2015-11-23 11:34:24
60617;Gabriel   Bronzatti Moro;;Uma Proposta de Arquitetura para um Editor Gráfico de Apoio à metodologia Prometheus AEOlus;Agent Oriented Software Engineering (AOSE) is an area that helps in modeling complex systems, facilitating the development of Multi-Agent Systems (SMA). There are several AOSE methodologies, among them the Prometheus AEOlus approach, defined by Uez (2014). The lack of technological support for this approach is the main motivation for this work. Therefore, the main objective is to carry out a feasibility study, which will allow the creation of a knowledge base for the development of a tool to support the Prometheus AEOlus methodology. The main result acquired in this work was the architecture of the tool, defined based on a systematic mapping of the literature. This mapping made it possible to identify different CASE (Computer Aided Software Engineering) tools and the technologies associated with their respective developments. As future work, we intend to instantiate the generated architecture, through the implementation of the tool.;;pt_BR;Declined;0;2015;2015-12-03 21:41:06
60628;Iuri Andrade   Carvalho;Faculdade Governador Ozanam Coelho - FAGOC;JNORMA: Desenvolvimento de Aplicativo Desktop para Simulação de Máquina NORMA;Among the characteristics of universal machines, some of the most notable are exactly those that prevent their physical implementation. For example, the universal machine called NORMA has an infinite number of registers to be used in calculations and in the execution of its programs. However, the NORMA machine would be physically limited due to the impossibility of creating infinite registers. This situation brings the need to use devices to study these machines. The most common devices are applications that simulate their operation, allowing scholars and researchers in the field of computer theory to simulate their operation, exploring all of their resources and having the minimum of limitations. This article describes the proposal for a simulator for the NORMA universal machine, given the need for this, as there is no other in operation today. This article also describes the chosen form of development, and to conclude, provides an example of using the simulator to demonstrate its operation.;;pt_BR;Declined;0;2015;2015-12-04 10:33:30
60709;Marcos Tadeu   Silva;Universidade de São Paulo (USP);Análise de desempenho de estruturas métricas no contexto de Recuperação de Imagens Baseada em Conteúdo (CBIR);Indexing structures are an important component of Database Management Systems (DBMS), essential for speeding up queries. Content-Based Image Retrieval (CBIR) is an area of ​​research whose purpose is to correctly respond to a query according to the similarity between elements. Metric structures have been used to make queries more efficient in the context of CBIR, but few studies have evaluated the performance of such structures. The objective of this work is to compare the performance between metric structures appropriate to this type of query and an unmodified DBMS with data from a CBIR system. The results show the importance of using these appropriate metric structures in similarity queries, given the better performance obtained with such structures in most tests compared to a DBMS.;;pt_BR;Declined;0;2015;2015-12-07 22:59:46
61030;Sr Carlos Alberto   Franco Maron;Pontifícia Universidade Católica do Rio Grande do Sul - PUCRS;Avaliando Micro-Benchmarks e Aplicações de Alto Desempenho em Nuvens OpenStack e OpenNebula;Infrastructure as a Service (IaaS) cloud environments provide on-demand resources for running applications. These virtual resources, such as processing, network memory and storage, are managed by several tools. However, only a few works have investigated the performance of IaaS clouds deployed in a private environment. This assessment has been restricted to the virtualization layer, disregarding the impact of management tools. Therefore, this article aims to evaluate and compare the impact of management tools on performance, seeking to identify whether there are influences or differences between OpenStack and OpenNebula, considering the same scenario and applications. We use micro-benchmarks, with isolated workloads, and parallel benchmarks, with scientific applications. The results obtained show that the OpenNebula tool was 11.07% better using micro-benchmarks and 8.41% considering parallelized scientific application benchmarks.;;pt_BR;Declined;0;2015;2015-12-18 23:46:18
61150;Fabíola   Kaczam;Universidade Tecnológica Federal do Paraná;Integração de Aplicações para Gestão de Nuvens Computacionais;The decision to invest or hire Information Technology (IT) involves several dilemmas and among them is the companies' investment capacity. Cloud Computing appears as a new possibility for reducing the volumes of these investments, enabling greater flexibility in the demand for services, with very attractive costs. This is a new model in which software is sold as services and accessible anywhere, as long as there is an Internet connection available. Cloud Computing services provide: Service on Demand, Access through different Platforms, Balancing of Physical Resources, Rapid Elasticity and Measured Service. Due to increasing technological advancement, Cloud Solutions are becoming increasingly in demand. Currently companies and academic laboratories have a large number of devices with spare storage space, processing, memory and underutilized network resources. This great potential can be managed and leveraged like a cloud. Given this scenario, this project aims to demonstrate the possibility of deploying, configuring and integrating applications for managing a Cloud.;;pt_BR;Declined;0;2015;2015-12-24 8:59:06
61408;Guilherme de Araújo   Silva;Universidade Federal de Goiás (Regional Jataí);Padrão de Ambientes Virtuais de Aprendizagem para o público idoso;The difficulty in using Virtual Learning Environments (VLEs) by the elderly population constitutes an instrument of disincentive to learning via Distance Education (EaD), thus hindering the dissemination of knowledge for these people. This article proposes a solution to this conflict, where the level of complexity in using these tools is high for beginners. Based on the elderly population, these environments have many obstacles to overcome for their successful use. The methodology used includes the analysis of accessibility recommendations aimed at elderly users and essential and unnecessary resources for the Moodle VLE to become more accessible. The article concludes that it is necessary to harmonize the content of these analyzes and proposes a way to use a step-by-step manual for the user's first access, so that elderly people can become better and faster familiar with AVA's.;;pt_BR;Declined;0;2016;2016-01-06 21:29:48
61510;Lilian   Noronha Nassif;;A context-aware taxonomy of deduplication metrics for backup strategies;The increasing data evolution brings complex challenges to data storage and compression. Deduplication technologies are widely used in enterprise environments as a solution to save disk space. Nevertheless, unlike traditional backups where the data type is disconsidered, deduplication is sensitive to this characteristic. Deduplication is more effective if backup strategies are associated to the input data type. This paper empirically compares a traditional backup environment before and after deduplication technology implementation. It also analyzes time and space improvements and defines a context-aware taxonomy highlighting problems and benefits of a mixed environment.;;en_US;Declined;0;2016;2016-01-10 10:41:13
61801;Éderson   Recalcatti;Universidade do Vale do Itajaí;Segurança em Sistemas Embarcados:  um Estudo sobre Ataques de Canal Lateral;The dissemination of embedded computer systems in society and the use of these devices to store sensitive personal information, such as cryptographic keys, passwords and other private data, requires solutions that protect users from unauthorized access. However, new attack modalities that seek to extract such information or violate other security properties of these devices have been developed. One of them is known as a side channel attack and exploits characteristics linked to the system implementation to extract confidential information. This article is part of this context and discusses issues relating to security in embedded computing systems, with an emphasis on side channel attacks.;;pt_BR;Declined;0;2016;2016-01-22 17:50:24
61851;Elton Bezerra   Torres;Instituto Federal de Educação, Ciência e Tecnologia de Pernambuco;Uma Metodologia para Comparação de Desempenho entre Protocolos de Roteamento em Redes Mesh;Wireless mesh networks are characterized by reduced cost, ease of installation and also by providing fault tolerance. These factors make them suitable for providing wireless coverage to large areas. The main responsible for these characteristics are the routing protocols. This article aims to propose a methodology to compare the performance of two routing protocols for mesh networks, under voice, streaming and data traffic. The protocols compared as a case study were OLSR (Optimized Link StateRouting) and AODV (Ad-hoc On-demand Distance Vector), in the UFRPE campus environment, through simulations carried out in the Network Simulator. The choice of these protocols is due to the fact that both have the best support in simulation tools and stability in firmware used in real implementations of mesh networks. The objective of this comparison is to verify which protocol has better performance in the evaluated scenario, through metrics such as: delay, jitter, blocking probability and throughput.;;pt_BR;Declined;0;2016;2016-01-26 14:07:49
61858;Diogo Fernando   Trevisan;Universidade Estadual de Mato Grosso do Sul;Development of A Simple Java Game Framework For 2D Games;In this paper we show the details of the Development of A Simple Java Game Framework For 2D Games. This is a simple framework to create 2D platform, action, shooter or RPG games. This framework comes with an game engine and visual tools to create animations and maps. It was created thinking on computer science students, as a tool to begin game development. We show the details of the engine including the map, background, animation and sprites editor. We also show the implementation of a sample game using our engine.;;en_US;Declined;0;2016;2016-01-26 19:22:19
61880;Kivson Marcell Nogueira   de Andrade;Universidade Federal de Mato Grosso;Armazenamento e Manipulação de Dados Geoespaciais em Dispositivos Móveis;The technological advancement of mobile devices has promoted the growth of applications that work with geospatial data, displaying data of interest to the user based on their geographic position. In general, this data is requested through mobile internet connections, so the processing of geospatial queries takes place on a remote computer. This form of query has the disadvantages of consuming a greater amount of the user's data plan, in addition to dependence on the connection. In this work, an alternative was proposed to maintain this data and execute queries on the mobile device itself, eliminating the disadvantages of traditional queries. A comparison was made between possible alternatives in order to verify the viability of the new approach as an offline alternative for users to use geospatial operations. To this end, an application was implemented for the Android platform that uses geospatial functionalities. Tests were carried out evaluating consultation alternatives, both online and offline. The results showed that the new approach, performing geospatial queries on the mobile device itself, is viable and brings advantages to the user.;;pt_BR;Declined;0;2016;2016-01-27 17:46:36
61911;Rodrigo Monteiro   Lima;Universidade Federal Rural do Semi-Árido;DOCTRAINING: Um Ambiente 3D Multiplataforma com Jogo Sério  para o Treinamento de Estudantes de Medicina em Casos Clínicos;This article describes a multiplatform auxiliary environment in the teaching and learning process for medical students and teachers. The environment has a serious game available on various computing devices to simulate clinical cases, in order to test students' knowledge. Diagnoses are simulated through a 3D environment, mobile application using a voice synthesizer and immersion through virtual reality glasses. The environment has gamification characteristics as a motivational mechanism for use for users. Within the 3D environment, medical topics are offered by NPCs (Non Playable Characters), with the aim of offering auxiliary knowledge that facilitates the identification of diseases in patients or medical topics in general. Teachers can check their students' scores and take additional measures in the classroom to resolve doubts. The system has a multi-agent system and machine learning to classify diseases offered by virtual patients.;;pt_BR;Declined;0;2016;2016-01-28 18:10:04
61951;Tiago Carmo   Nogueira;Instituto Federal de Mato Grosso;Avaliação dos Atributos Emocionais da Experiência de Usuários Cegos no Design Web Responsivo e não Responsivo;Accessing information on the Web is still a challenge for the community of people with some type of visual impairment. Research reports that the application of accessibility guidelines alone is insufficient, thus requiring a more careful investigation into the user experience in these applications. Therefore, this article aims to identify the emotional impact on the experience of blind users between responsive and non-responsive design. Therefore, six websites were selected, in three categories, with six tasks on each website. After each interaction, emotional impact questionnaires were administered to measure the emotions felt by users. The results demonstrated that non-responsive design had a positive emotional impact compared to responsive design. It is concluded that it is possible to measure the experience of blind users on accessible websites, thus enabling greater levels of accessibility.;;pt_BR;Declined;0;2016;2016-01-30 22:12:19
62028;Gabriel   Araújo;Departamento de Computação, Universidade Federal de Sergipe;Towards the standardization of the development process for Automatic Speech Recognition systems;Automatic Speech Recognition (ASR) currently represents one of the main characters in the Human-Computer Interaction (HCI) scenario, not only for be- ing a great ergonomic interface but also for its recent advances. Commercial products and services with built-in speech interfaces has become popular over the last years. From Web applications to wearable devices, such interfaces has been built for several different platforms, domains and users. Building a speech recognition system, how- ever, is not a trivial task. Although ASR disciplines are very well documented, they co-occur in an unrelated manner, which hinders the full understanding of the logi- cal and sequential development aspects. The lack of a standard development process with the common building blocks constrains the rapid prototyping of a ASR system and hampers novice researchers’ work. In this paper we propose a complete process meta-model for ASR systems development that fully complies with the SPEM Specifi- cation. The work contributes to both Artificial Intelligence and Software Engineering disciplines. In one hand, (i) we provide a scientific reference guide for Knowledge- based systems development well grounded on software engineering practices and, on the other hand, (ii) we foster the investigation of innovative software engineering prac- tices to better comply Knowledge-based systems specific requirements. The process meta-model has been used to the development of two distinct ASR complex systems: (i) a context-sensitive ASR system to provide navigation of mobile robots and (ii) a semantic-driven ASR home automation system. Results show process flexibility in taking care of different application specificities, providing, at the same time, desired standardization. In addition, common ASR metrics such as WER and WIL, have shown improved results which reaffirms that the process is well suited to ASR system development. ;;en_US;Declined;0;2016;2016-02-03 17:27:06
62053;Isadora Giacomini de   Moraes;Faculdade de Tecnologia de Mococa (FATEC);Desenvolvimento de Jogos Digitais: Explorando a Técnica de Inteligência Artificial Navigation System por meio da Unity3D;A game, in addition to engaging and retaining the attention of its users, must also be able to provide situations in which they are encouraged to seek strategies to win, situations that simulate behaviors similar to those in the real world. In view of this, what will enable developers to produce more realistic games and provide non-controllable characters with the intelligence necessary to present challenges to players is Artificial Intelligence. Therefore, this tutorial aims to develop the prototype of a game in order to explore the A.I. technique. Navigation System through the Unity3D engine.;;pt_BR;Declined;0;2016;2016-02-04 18:19:43
62524;Claudio Cesar   de Sá;Universidade do Estado de Santa Catarina - UDESCDepartamento de Ciência da Computação - DCC Rua Paulo Malschitzki, s/numero - Campus Universitário Prof. Avelino Marcante Bairro Zona Industrial Norte Joinville-SC - Brasil;Uma Biblioteca de Grafos para a Linguagem MiniZinc;\begin{abstract} This article presents a library of graph functions and predicates for the MiniZinc language. This language is intended for building computational models in the areas of combinatorial or discrete optimization, constraint programming and operational research. These areas address combinatorial problems which belong to the NP class of problems. Many of the NPs problems are modeled with complex structures, such as graphs. In this context, there is a motivation to build a graph library, as this is a fundamental computational structure intended for computational applications in general. The use of this library is illustrated with two classic problems from the graph area: checking whether a graph is complete and obtaining the set of cliques$-k$. Finally, the clicks$-k$ problem is modified to the maximum click problem, where some experiments are carried out. \end{abstract};;pt_BR;Declined;0;2016;2016-02-25 18:36:30
62551;Kleber Kroll   de Azevedo Silva;Universidade do Estado do Rio Grande do Norte-UERN;Gestão em transporte marítimo: otimização de alocação de contêineres vazios utilizando GRASP Reativo com aprendizado por reforço;The repositioning of empty containers between ports presents a high cost for shippers and occurs when the quantities of exported and imported cargo are different in a given maritime trade area, causing an excess of empty containers in some ports and a shortage in others. To meet customer demand, companies can develop actions that cause losses, such as, for example, transferring their customers to other companies when there is no empty container available or renting empty containers, if available, at the port of demand. The present study proposes an algorithmic solution to minimize the costs involved in this activity, using an approximate method (metaheuristic), specifically the Greedy Randomized Adaptive Search Procedure-GRASP Reactive algorithm, combining the Reinforcement Learning technique with the Q- algorithm. Learning. This algorithm is capable of learning directly from previous experiences, which minimizes the number of a posteriori calculations, thus optimizing computational processing. A series of instances found in the literature were used when carrying out the tests. These pointed to advances (better solutions) in relation to the results obtained by other studies that also dealt with the problem of repositioning empty containers, implemented with the traditional GRASP algorithm.;;pt_BR;Declined;0;2016;2016-02-26 17:26:03
62555;Kleber Kroll   de Azevedo Silva;Universidade do Estado do Rio Grande do Norte-UERN;Gestão em transporte marítimo: otimização de alocação de contêineres vazios utilizando GRASP Reativo com aprendizado por reforço;The repositioning of empty containers between ports presents a high cost for shippers and occurs when the quantities of exported and imported cargo are different in a given maritime trade area, causing an excess of empty containers in some ports and a shortage in others. To meet customer demand, companies can develop actions that cause losses, such as, for example, transferring their customers to other companies when there is no empty container available or renting empty containers, if available, at the port of demand. The present study proposes an algorithmic solution to minimize the costs involved in this activity, using an approximate method (metaheuristic), specifically the Greedy Randomized Adaptive Search Procedure-GRASP Reactive algorithm, combining the Reinforcement Learning technique with the Q- algorithm. Learning. This algorithm is capable of learning directly from previous experiences, which minimizes the number of a posteriori calculations, thus optimizing computational processing. A series of instances found in the literature were used when carrying out the tests. These pointed to advances (better solutions) in relation to the results obtained by other studies that also dealt with the problem of repositioning empty containers, implemented with the traditional GRASP algorithm.;;pt_BR;Declined;0;2016;2016-02-26 18:57:46
62700;alex sandro   christofari;instituto de educação ciência e tecnologia farroupilha campus são borja;SISTEMAS DE INFORMAÇÃO: A ARTE DA MANIPULAÇÃO DE DADOS;Summary. This article aims to introduce the basic concepts regarding information systems, their types, their importance and applications in the social and technological axis, with an institutional character and with the aim of presenting information necessary for understanding what information systems are and their importance for both the present and the future of our society.;;pt_BR;Declined;0;2016;2016-03-02 17:45:52
62814;Sandro Teixeira   Pinto;Universidade Tecnologica Federal do Paraná - UTFPR;Análise da Arquitetura RouteFlow no Tempo de Convergência do protocolo OSPF;The convergence time of a network is the total time taken by the routing protocol to update router routes. In the case of OSPF, it is possible to reduce this time through adjustments to the values ​​of the configuration parameters specified in the RFC2328 standard. This work presents an analysis of the effects of the Hello-Interval and Dead-Interval parameters on the convergence time in a RouteFlow architecture. A practical analysis is carried out using the standard RouteFlow virtualized network infrastructure and another using an Abilene backbone to identify which values ​​presented the best results. After analysis, it was revealed that the convergence time can be improved by adjusting the OSPF, Hello-Interval and Dead-Interval configuration parameters to values ​​of 1 and 4 seconds respectively, however it was identified that the size of the scenario has influences the configured values.;;pt_BR;Declined;0;2016;2016-03-07 8:05:01
62818;Paulo Damasceno   Barreto;IPT - Instituto de pesquisas tecnológicas do estado de São Paulo;Estudo comparativo entre treinamento supervisionado e não supervisionado em agrupamento de dados nos IDSs baseados em anomalias;Intrusion detection systems – SDI (Intrusion Detection System – IDS) based on anomaly are presented as an alternative to IDSs based on misuse (signature). Anomaly-based IDS obtain better detection rates for new attacks, but with higher false positive rates and require training that determines the limits of the clusters and directly influences the detection rate and false positives. This work presents a comparative study between supervised and unsupervised training in IDSs based on anomalies with data clustering and presents results on which technique offers the best clustering limit and its influence on intrusion and false positive detection rates.;;pt_BR;Declined;0;2016;2016-03-07 9:58:20
63515;Ivar   Vargas Belizario;UNIVERSIDADE DE SÃO PAULO / INSTITUTO DE CIÊNCIAS MATEMÁTICAS E DE COMPUTAÇÃO;Avaliação de medidas de similaridade no agrupamento em grafos para segmentação de imagens;This work presents an approach for image segmentation using graph clustering algorithms, suitable for segmenting images of natural scenes. The work presents the evaluation of 7 similarity measures and, quantitatively, demonstrates which of these measures and which grouping algorithms are most suitable for the image segmentation process. The evaluation is carried out by comparing the segmentation produced by the method with manual segmentations. The experiments demonstrated that two algorithms stand out in the process (FG and LP), while 6 of the 7 similarity measures can, in fact, be used for segmentation.;;pt_BR;Declined;0;2016;2016-03-29 1:23:35
63694;Elizangela Nunes Neves   Cerqueira;UEMA;ESTUDO DE FILTRAGEM ADAPTATIVA NO ESTADO DO MARANHÃO;This article aims to review the scientific production on adaptive filtering in the State of Maranhão. To this end, research was carried out on the theory of adaptive filters and subsequently a brief review was carried out on this topic, emphasizing its structure, functioning and main applications. Afterwards, the adaptive algorithm most used in adaptive filtering applications is explained, the Least Mean Square algorithm, known as LMS, and finally the adaptive algorithms RNL (Non-Linear Recursive Algorithm), SA (Sigmoidal Algorithm) are highlighted. and WEM (Weighted Even Moment), algorithms developed by researchers in the State of Maranhão.;;pt_BR;Declined;0;2016;2016-04-02 20:15:23
63884;Gilseone Rosa de   Moraes;Centro Universitário Franciscano;Protótipo de aplicação para Avaliação Postural utilizando o Microsoft Kinect;Postural assessment is of great importance so that postural anomalies are identified. From there, it is possible to develop corrective treatments that can be applied to the patient. Currently, postural assessment is carried out manually, with the main problem being the time required to carry out the complete process, in addition to being subject to errors, as it requires the evaluator's perception to point out the problems detected. In this sense, the present work proposes the development of a system that makes it possible to carry out postural assessment of patients in an automated and quick way, using Microsoft Kinect to capture images and identify reference points.;;pt_BR;Declined;0;2016;2016-04-09 20:41:16
63928;Ives Fernando   Martins Santos de Moura;Departamento de EstatísticaUniversidade Federal da Paraíba;Avaliação para Trajetórias de Incisões Cirúrgicas com SVM;Virtual Reality surgical procedure simulators have become increasingly popular. An important component of this type of software for the medical field is the ability to simulate incisions. In the computational context, incisions involve three basic steps: definition of geometry and topology, collision and deformation detection. Furthermore, in simulators aimed at training students, the ability to evaluate user performance is essential. In this work, two experiments are carried out, one with randomly generated data and the other with data generated from user interaction with an application via mouse, to evaluate the quality of the cut with regard to its trajectory. Both experiments were performed using the Support Vector Machine (SVM) method. Satisfactory results were obtained with SVM and five kernels, with success rates exceeding 70%. The main conclusion, then, is that SVM is a method capable of evaluating problems related to the incision trajectory. The contributions of the work include the analysis of the incision components, the survey of evaluation methods applicable to this problem and the use of SVM in the two experiments conducted, which showed the applicability of this method in this context.;;pt_BR;Declined;0;2016;2016-04-11 18:50:20
64090;Fabrício Tonetto   Londero;;Estudo sobre Segurança de Banco de Dados na Nuvem;With the growth in the use of Cloud environments, there is a need for greater attention and studies on Information Security. Care regarding information protection does not only cover the computational area, as it is also necessary to think about infrastructure and how to avoid social engineering, identifying weak links, since each company has its own peculiarities. This work presents the results of a bibliographic study on the topic and, finally, exposes the most relevant results found in books and articles used in the research. Furthermore, it aims to present some of the challenges that this area of ​​study faces, in order to help companies and Information Technology professionals in making decisions on the subject.;;pt_BR;Declined;0;2016;2016-04-16 17:33:25
64257;Marcos Antonio   Alves;Programa de Pós-Graduação em Engenharia Elétrica - Universidade Federal de Minas Gerais - Av. Antônio Carlos 6627, 31270-901, Belo Horizonte, MG, Brasil;Satisfação de Usuários de Smartphones: Um Estudo Comparativo entre os Sistemas Operacionais Android, iOS e Windows Phone;This work aims to measure subjective user satisfaction regarding the usability of smartphone interfaces. The operating systems studied were Android, iOS and Windows Phone. The research covered university students in the areas of Computing, Engineering and Administration. Data collection was carried out using an online questionnaire, adapted from QUIS, Questionnaire For User Interaction Satisfaction. This quiz uses a 1 to 9 point scale for each question in different sections. Respondents expressed their satisfaction by assigning a score on this scale. The following sections were analyzed: Screen, Terminology, Learning and System Resources. The results revealed that iOS had the highest satisfaction rate among the items evaluated. However, the study points out usability problems that need to be improved, since the highest average score achieved was 7.67 out of 9.0. A more in-depth evaluation was carried out using accumulated frequency distribution for both systems. In this way, it was possible to count and list which aspects relating to the systems indicated greater dissatisfaction among users. Unhelpful or non-specific error messages were highlighted as the main reason for dissatisfaction. However, other problems were also detected and allow research to continue in this area.;;pt_BR;Declined;0;2016;2016-04-23 13:04:11
64347;Tales Luiz   Bortolin;Centro Universitário Franciscano - UNIFRA;Desenvolvimento de um Web Service para Gerenciamento de Frotas de Taxis;This article presents the development of a Web Service that provides developers with a service to manage the location of taxi fleets through call control in commercial or service environments with validation in an Android application.;;pt_BR;Declined;0;2016;2016-04-27 0:50:44
65003;Henrique Carlos   Fonte Boa Carvalho;Universidade Federal dos Vales do Jequitinhonha e Mucuri;Técnicas de Reconhecimento de Padrões para identificação de ataque de DNS;Most devices that are connected to the Internet use DNS (Domain Name System) services for domain name resolution. Based on the statement that most networks do not restrict the traffic of packets destined for DNS services, attack techniques can be applied, meaning that a simple apparently normal name resolution request can lead to an attack causing various inconveniences to the victims. Spoofing attacks consist of deceiving the user's device, causing the computer to identify the malicious user's device, in a reliable way. As it is a highly dangerous type of attack, due to the lack of research and efficient techniques for its identification, we seek to find viable solutions for detecting this type of attack. This work aimed to apply Pattern Recognition techniques through the application of Feature Selection and Feature Classification techniques to detect DNS Spoofing in local computer networks. Results were obtained with an average accuracy of 98.33%± 0.64% in detecting the network failure class, that is, when they were under DNS Spoofing attack.;;pt_BR;Declined;0;2016;2016-05-25 10:55:31
65019;Carlos Alberto   Franco Maron;Pontifícia Universidade Católica do Rio Grande do Sul;Avaliando OpenStack e OpenNebula em Estações de Trabalho com Microbenchmarks e Aplicações Científicas;IaaS (Infrastructure as a Service) cloud environments provide on-demand computing resources for running applications. These resources are memory, network, processing unit and storage. The problem is that work that evaluates the performance of IaaS clouds is limited to the virtualization layer and disregards the analysis of the impact of management tools. In contrast, this article aims to investigate their impact, seeking to identify whether there are influences or differences between OpenStack and OpenNebula. Intensive workloads (microbenchmarks that exhaustively use a specific resource) and scientific applications (benchmarks that exploit parallelism of shared and distributed memory architectures) were used for this purpose. Statistically, the results obtained show that OpenNebula was 11.07% better using microbenchmarks and 8.41% considering only applications.;;pt_BR;Declined;0;2016;2016-05-26 17:37:58
66218;João Paulo   Aramuni;Universidade FUMEC;ANÁLISE DA ADOÇÃO DO LEAN MANUFACTURING NA GESTÃO DE PROJETOS DE TECNOLOGIA DA INFORMAÇÃO: Estudo de Caso em uma Multinacional desse Segmento;This article, part of a master's thesis, presents a study on agile project management through Toyota's Lean Manufacturing model. Conservative resistance to the use of traditional management models creates a psychological barrier that prevents the proliferation of the agile philosophy and cultural change within the organization. In recent years, agile models have gained ground and found a natural habitat for growth in the IT market. In particular, the agile management methodology of Lean Manufacturing stands out, which for over fifteen years has been transforming the way companies work around the world, making them more competitive, flexible and structured.;;pt_BR;Declined;0;2016;2016-07-15 15:35:25
66386;Antonio Carlos Mateus   Silva;Universidade de São Paulo;Estudo comparativo entre SGBDs Relacionais e SGBDs Orientados a Grafos para aplicação em sistemas de recuperação com base em conteúdo;Although the relational model is still the most used in current databases, NoSQL alternatives have been used. Among these alternatives are graph-oriented databases. Some studies have compared the performance of the two paradigms, but in general they do not direct the comparison to specific and complex contexts. This work aims to compare MySQL (relational DBMS) and Neo4j (graph-oriented DBMS) within the context of content-based image retrieval. To obtain the results, the construction (and population) time of the database and search for a given image was measured, varying the number of images stored, descriptors applied and images returned in a search. It was found (in both paradigms) that the database construction time increases as the number of images or descriptor extractors increases, and the search time remains constant with the variation of any of the factors. Although schema definition is not required in Neo4j, MySQL has proven to be faster than its competitor in both tasks.;;pt_BR;Declined;0;2016;2016-07-23 15:18:58
67000;Elzenir Araujo   Montes;Universidade Estadual do Maranhão;Aplicação de  um Método Computacional para o Diagnóstico de Câncer de Próstata Usando Reconhecimento de Padrões Proteômico;The present work presents a method based on the recognition of proteomic patterns for the early diagnosis of prostate cancer, in order to improve the quality of life of patients and reduce the number of deaths caused by this disease, using computational techniques, applied on a database SELDI-TOF data obtained by mass spectrometry. The method is based on classifying the individual according to the stage of infectability as a carrier or not of this pathology. For this purpose, the Independent Component Analysis (ICA) technique is used to extract the characteristics of the proteomic signals. Subsequently, the Maximum Relevance and Minimum Redundancy algorithm is applied to reduce the computational cost, and finally the Support Vector Machine to perform the final classification. The best result of the method was obtained with a vector of 27 features, achieving accuracy, specificity and sensitivity, respectively, of 89.21%, 83.68% and $95.08%.;;pt_BR;Declined;0;2016;2016-08-15 11:04:13
68095;Samuel Portela   Carvalho;Universidade de São Paulo;Uma contribuição ao auxílio do diagnóstico do autismo a partir do processamento de imagens para extração de medidas antropométricas;Autism Spectrum Disorder (ASD) is a syndrome characterized by difficulty in social interaction and qualitative deviations in communication and the use of imagination. Although the diagnosis of this syndrome basically consists of clinical assessments, there is evidence that children with ASD also present different facial anthropometric measurements than children without the syndrome. In this case, computational tools can be used as assistants in this task. The present work aims to define and validate techniques for processing facial images and measuring anthropometric distances in order to assist in the diagnosis of ASD. The defined techniques culminated in the construction of a computational tool capable of analyzing patient images and calculating facial anthropometric measurements. The tool was validated with an image bank of individuals with and without the syndrome, and similarities and differences were found between the anthropometric measurements extracted by the tool and measurements cited in previous studies. The tool proved capable of processing frontal images of patients and extracting their components and anthropometric measurements accurately, using image processing techniques adapted for these purposes, and can effectively contribute to aiding the diagnosis of ASD.;;pt_BR;Declined;0;2016;2016-09-20 0:31:11
68134;Tiago Machado   Wanzeler;Universidade Federal do Pará - UFPA;Desenvolvimento de um sistema de automação residencial de baixo custo aliado ao conceito de Internet das Coisas (IoT);This article presents the development of a low-cost home automation system controlled through a mobile device using the Arduino electronics prototyping platform. This control and automation system through a set of tools and devices has the following functionalities: automating the entire lighting system of a residence, which ranges from simply turning on or off a lamp remotely to dimming the lights in certain environments, monitoring temperature and implementation of an alarm system, aimed at residential security. This project takes into account the cost-benefit binomial, as there is great added value in the benefits offered to the user, such as: practicality, dynamism and safety in carrying out tasks with low investment cost, the latter being the main stimulus for improvements in home automation through this open-source electronic prototyping platform based on flexibility, with easy-to-use hardware and software that is growing every day in the world, which is the Arduino platform. Combined with the development of this system, the article addresses the concept of Internet of Things (IoT) with the use of sensors and actuators responsible for communicating and activating microcontrolled devices.;;pt_BR;Declined;0;2016;2016-09-21 16:38:10
68248;Georgea   Danielewicz;;Uma Visão Geral sobre o Problema da Predição de Laços Sociais;Social networks are a way of describing social interactions in a group or community. They can be modeled using graphs, in which a vertex corresponds to a person, and an edge represents some form of association between two people [5]. Social networks are highly dynamic objects, they grow and change rapidly over time due to the addition and deletion of vertices and edges. Understanding the mechanisms by which these social structures evolve is a fundamental issue, not yet well understood, and which constitutes the motivation for this work. More specifically, the research is dedicated to the problem of predicting social ties: given a snapshot of a social network at time t 0, we seek to accurately predict the edges that will be added to the network at a given time t in the future, such that t > t 0 [8]. The solutions studied are divided into two main groups: supervised loop prediction and unsupervised loop prediction. Supervised loop prediction involves machine learning techniques such as feature extraction and classification algorithms [14]. Unsupervised prediction seeks to calculate metrics based on the topological characteristics of the graph[5].;;pt_BR;Declined;0;2016;2016-09-26 18:04:30
68677;Marcio   Poffo;Universidade do Vale do Itajaí;Gamification: agente motivador na aprendizagem de Engenharia de Software;Studies show that using gamification, the use of game elements in serious environments, can increase motivation to carry out activities. The use of gamification in learning environments has been the focus of many scientific articles to demonstrate its efficiency in relation to the motivation generated. In addition to extrinsic motivation, gamification also allows the generation of intrinsic motivation. In this sense, using gamification in education can contribute to increasing students' motivation in the learning process, since traditional academic activities are usually considered monotonous. The objective of this work is to analyze the relationship between motivation and the effect it has on learning through the adoption of an educational environment using gamification. The study was conducted in the form of an experiment, involving three Software Engineering classes. This article presents the planning, operation and results of the evaluation carried out in the experiment.;;pt_BR;Declined;0;2016;2016-10-06 23:48:49
68945;Rogério Luis   Rizzi;Universidade Estadual do Oeste do Paraná - UNIOESTE;Autômatos Celulares e Sistema Multiagente à Simulação de Hipotéticas Doenças;This work presents a study on epidemiological computational models, focusing on Susceptible-Infected-Removed, SIR, and different solution strategies for computational simulation of the spread of hypothetical communicable diseases. It is shown that models based on cellular automata type \textit{Lattice Gas Cellular Automata}, LGCA, have solutions similar to those obtained by multi-agent systems, unlike diffusive cellular automata. The results obtained from the literature, as well as those resulting from this work, indicate that such methodologies have the potential to simulate the dynamics of ecological, biological and physical phenomena that can thus be modeled. They indicate, however, that results more consistent with real data depend on the development and parameterization of models that add essential characteristics to the phenomenon, such as the interaction between individuals and the environment, and the heterogeneity of the relational system of contacts.;;pt_BR;Declined;0;2016;2016-10-21 2:02:50
69036;Diogo Fernando   Trevisan;Universidade Estadual de Mato Grosso do Sul - UEMS;Implementação de um Sistema de Partículas Utilizando WebGL;This work shows how the implementation of a particle system was carried out using WebGL. WebGL has proven to be an interesting technology as it allows displaying quality 3D graphics within a web browser. At the end, results and examples of simulations that can be carried out using the implemented system are shown.;;pt_BR;Declined;0;2016;2016-10-26 11:44:36
69059;Alex Júnior   Fabonatto;;SOFTWARE LIVRE NA EDUCAÇÃO: EXPERIÊNCIAS COM O LINUX EDUCACIONAL 5.0;Today, IT's main objective is to assist, that is, to improve processes and existing projects, regardless of the field. One of these branches is education, it has been seeking the additional benefits that technology provides, mainly improving the student teaching process, and incorporating tools into education, which students are constantly using. The study evaluates the use of the Linux Educational 5.0 platform, highlighting the tools it makes available or facilitates access to its user, and the way in which the technology will interact with the participating people (teachers and students). The objective of providing tools and resources present in Educational Linux, which gives the class a new way for the teacher to pass on knowledge and the student to acquire this knowledge, and with the class more attractive to the student and proposing the teacher to include new means of learning to your class methodology. The project methodology is qualitative research, which encourages people to reason and give their opinion freely on the subject and which involves a case study of an element, in which the element was defined as Educational Linux 5.0, which has a group of people who carry out the project and a sample of these people from whom the result is sought. The application of the project was structured around understanding the physical structure of the laboratory, initial collection of knowledge data regarding the platform, implementation of Linux Educational 5.0, carrying out activities with educational games, online information tools and office tools, and concluding with an interview to collect the final information, that is, the results.;;pt_BR;Declined;0;2016;2016-10-26 19:46:14
69542;Guilherme Duarte   Mattos;;Análise de erros de anotação de genes exclusivos;Identifying which genes are exclusive to an organism is a fundamental activity in comparative genomics, which can help in the identification of pathogenic characteristics or even in the development of mechanisms to combat diseases. However, due to the existence of different strategies for the identification and functional annotation of genes, this activity presents some challenges. This article presents an approach for identifying annotation errors in unique genes, detailing the tools that have been developed for this. The tools are generic in nature and can be used by researchers and professionals in the field, as well as enabling greater reliability in a phylogenetic analysis aimed at identifying exclusive genes and their origins. Additionally, a case study with genes from Xanthomonas bacteria species is presented.;;pt_BR;Declined;0;2016;2016-11-22 11:51:27
69669;Graziele da Silva   Martins;Fundação Educacional de Fernandópolis - FEFFaculdades Integradas de Fernandópolis - FIFE;Estudo Comparativo entre o Banco de dados Relacional com o Modelo Orientado a Documentos utilizando o   MongoDB;With the increasing computerization of functions in the market, there is a greater need to store and control the flow of information. There are several database models that manage this information, which can be classified as relational or non-relational (NoSQL). This article aims to compare some structures between the relational and non-relational model, more specifically the document-oriented model, using the PostgreSQL DBMSs and MongoDB to carry out this study, as well as showing that it is possible to migrate data from a database relational model for a NoSQL and through comparisons point out the main characteristics and differences between these two models. Since its emergence, for a long time the relational model was the most used for commercial applications, but with the constant growth in the flow of information, some problems such as scalability and high availability arose, leading to the emergence of the NoSQL model to solve such problems. The most common models of NoSQL databases are defined as: key-value, graphs, columns and documents. MongoDB is one of the most used document-oriented databases today, therefore it was used to carry out the comparisons made in this article. Analyzing the database models, it can be concluded that each of them has its advantages.;;pt_BR;Declined;0;2016;2016-11-29 2:17:44
69781;Wheeler Guilherme   Ismarsi;Fundação educacional de fernandopolis;Aplicando Big Data para Transformação de Dados;Big Data are large databases, which require an innovative way of processing information for better perception and decision making. Competition between company brands is increasingly fierce, requiring them to make quick decisions to create a competitive advantage. The objective of this article is to use Big Data with a large volume of data on a social network to analyze which cities have recognized the work of an automotive inspection company in the city of Fernandópolis, State of São Paulo, which has been investing in advertising using the internet through a Fanpage. With the data extracted from this network's database, analyzes were carried out with the aim of reaching a large audience, who are not aware of this company's services. With this, it is possible to show that you can extract business decision-making information such as investment in advertising from the data that was extracted. The Tableau tool was used to visualize the data that was extracted in the form of graphs.;;pt_BR;Declined;0;2016;2016-12-01 1:44:37
69786;Graziele da Silva   Martins;Fundação Educacional de Fernandópolis - FEFFaculdades Integradas de Fernandópolis - FIFE;Estudo Comparativo entre o Banco de dados Relacional com o Modelo Orientado a Documentos utilizando o MongoDB;With the increasing computerization of functions in the market, there is a greater need to store and control the flow of information. There are several database models that manage this information, which can be classified as relational or non-relational (NoSQL). This article aims to compare some structures between the relational and non-relational model, more specifically the document-oriented model, using the PostgreSQL DBMSs and MongoDB to carry out this study, as well as showing that it is possible to migrate data from a database relational model for a NoSQL and through comparisons point out the main characteristics and differences between these two models. Since its emergence, for a long time the relational model was the most used for commercial applications, but with the constant growth in the flow of information, some problems such as scalability and high availability arose, leading to the emergence of the NoSQL model to solve such problems. The most common models of NoSQL databases are defined as: key-value, graphs, columns and documents. MongoDB is one of the most used document-oriented databases today, therefore it was used to carry out the comparisons made in this article. Analyzing the database models, it can be concluded that each of them has its advantages.;;pt_BR;Declined;0;2016;2016-12-01 2:38:20
69854;Bruna Souza   Nobre;Fundação Educacional de Fernandópolis;Transmissão de Dados por PLC: Uma Tecnologia que está sendo Implantada no Brasil.;: The article shows the development of Power Line Communication (PLC) technology, in Brazil this technology is still recent, but in other countries such as the USA, Japan and Europe it already works and correctly meets the needs of users, the PLC transforms the electrical grid buildings and homes in a true network, to enable data to be transferred via the electrical network signal through the location's own power outlet, PLC technology does not limit the signal level, depending only on the local electrical network, in addition to compared results between Wi-Fi technology.;;pt_BR;Declined;0;2016;2016-12-04 23:13:56
69876;Laís Carla   Bordon;Fundação Educacional de Fernandópolis;A Importância do Cadastro Multifinalitário Urbano;This article's main objective was to study the role of geotechnologies as a means of assisting municipalities in carrying out the Urban Multifinancial Registry, which is fundamental in planning, management and urban requalification. The importance of territorial information comes to meet the need for accurate information for urban planning and development.;;pt_BR;Declined;0;2016;2016-12-06 11:44:43
69893;Daisyeli Aparecida   Codinhoto;Fundação Educacional de Fernandópolis;O Uso da Inteligência Artificial por meio do algoritmo EdgeRank no Feed de Notícias das Redes Sociais;This study provides a brief approach to Artificial Intelligence (AI), which is applied or used to understand and constitute intelligent entities and also simulate human life. It emerged after the Second World War, with a wide variety of subfields, from general use areas such as an English instructor, to specific tasks such as chess games and social networking. AI systematizes and automates intellectual tasks, it is potentially relevant for any sphere of human intellectual activity. The main focus of the project is to base research on AI and computational algorithms used in a social network's news feed. An algorithm is an ordered, defined and finite sequence of actions that aim to solve a given computational problem. In the social network analyzed for the present study, the most efficient algorithm is EdgeRank, which defines which posts appear or not in the user's news feed, taking into account affinity, relevance and time.;;pt_BR;Declined;0;2016;2016-12-06 20:00:15
69915;Vitor Hugo   Bichof;Fundação Educacional de Fernandópolis;Aplicação de Pentest utilizando SQL Injection em ambiente Web;This article aims to demonstrate pentest procedures and methods using a methodology, which presents the steps for executing the pentest process in a web application. In addition to demonstrating the proof of concept by exploiting one of the vulnerabilities found, proving the existence of the security flaw and correcting it in order to avoid malicious attackers in the future and demonstrating the importance of information security.;;pt_BR;Declined;0;2016;2016-12-07 23:57:37
69949;Elias Augusto   Fank;Universidade Federal da Fronteira Sul;INSIDe: Ferramenta para Reconhecimento de Imagens para Auxiliar Deficientes Visuais Durante Navegação em Ambientes Internos;Visually impaired people face numerous obstacles in their process of inclusion in society. Computer vision can be used to provide a higher quality of life for people with visual impairments, contributing to the accessibility of frequented places. This work presents a tool that uses computer vision and image recognition to help visually impaired people navigate indoor environments using previously collected metadata. The tool, called {\it INSIDe} ({\it Indoor Navigation for viSually ImpaireD}), works through a cell phone application that, when requested, captures a photo that is then sent to the server that returns, by in turn, the information corresponding to the image reproduced in sound form. This information contains a message about whether or not the object present in the image is recognized. Some experiments were conducted and they suggest that the {\it INSIDe} tool is viable.;;pt_BR;Declined;0;2016;2016-12-10 8:38:40
70212;Igor Luiz   Vila;Fundação Educacional de Fernandopolis;Uma Abordagem sobre as Ferramentas e Tecnologias Utilizadas no Desenvolvimento de Aplicações Móveis Híbridas;The number of operating systems for mobile devices has been showing moderate growth. There are several options on the market, which makes it a difficult task for the developer to place their applications on all operating systems, as each one has its own development tool. With the emergence of hybrid applications, it was possible for developers to use web development technologies and tools such as HTML5, Java Script and CSS (Cascade Style Sheet) so that applications can be executed as web pages on any mobile device, regardless of its operating system. This article aims to describe the technologies used to develop a hybrid application, and through a case study, demonstrate the application running on two different operating systems.;;pt_BR;Declined;0;2016;2016-12-19 20:18:22
70762;Sanderson   Scheuer;;Processo para Manutenção Contínua de Software Aderente ao Modelo MPS para Serviços;Maintenance is a critical area within the software life cycle. The need to keep products always updated according to the market makes organizations look for solutions to satisfy them efficiently. However, the evolution of the software product may require emergency solutions to change it, whether to correct critical defects or to meet specific demands. In this context, this work presents a continuous software maintenance process drawn from the concept of service offered by software-intensive organizations. This process is divided into four types of services: incident handling and maintenance, detailing the maintenance request, developing the maintenance request and releasing the maintenance service. In addition to presenting the process, an evaluation was demonstrated in three software-intensive organizations, in the dimensions of adequacy and motivation. The result of this evaluation revealed that the process tends to adapt to and motivate organizations that perform this type of service.;;pt_BR;Declined;0;2017;2017-01-20 14:26:04
70779;Matheus Silva   Ferreira;Universidade Federal de Lavras;Diário de Classe: uma ferramenta de apoio aos professores;It was found that, in municipal schools in Lavras/MG, the recording of essential information for the school environment is carried out in a handwritten document called a class diary. This is a tedious and error-prone process due to the large amount of information. Although there are some technological solutions concerned with improving this process, it was noticed that they do not apply well to the context in question. These solutions are aimed at the Web platform while the studied context has mobile technology infrastructure. This work proposes the development of the ``Class Diary'' application. It consists of an application for mobile devices capable of assisting teachers in completing and maintaining handwritten diaries. To this end, the ``Class Diary'' standardizes and automates the flow of information from a conventional diary, improving the teacher's class management process, as well as offering quick and accurate access to information.;;pt_BR;Declined;0;2017;2017-01-21 19:46:57
70996;Ariel Gustavo   Zuquello;Universidade Estadual de Maringá;Validação Experimental de Métricas de Complexidade para Product-Line Architectures: uma Replicação Interna;Software Product Line (LPS) can be defined as a set of techniques and methods with the aim of facilitating and improving the development process of similar software products. One of the most important artifacts of an LPS is its architecture, known as Product-Line Architecture (PLA). However, one of the biggest difficulties encountered in this area of ​​research is the evaluation of a PLA. To this end, several techniques can be used, such as trade-off analyzes based on metrics. Therefore, this article aims to present the internal replication of a controlled experiment conducted to validate complexity metrics for PLAs. PLA analysis, supported by metrics, can be used as an important indicator of the quality of an LPS and return on investment (ROI). With this replication, we compared and analyzed the results obtained from the original experiment in relation to the replication results, which corroborate the results of the original experiment, pointing to a significant correlation between the proposed metrics and the complexity of a PLA based on the participants' judgment.;;pt_BR;Declined;0;2017;2017-02-01 23:47:51
71110;Cristiane Neri   Nobre;PUC Minas;Design and evaluation of mobile game for older people: an empirical study;Digital games can provide leisure for older people. However, to achieve these benefits, game designers must consider age restrictions so that older users can play comfortably. a digitalmobile game focused on older people. The results indicate that this target audience attaches importance to images, colors, sounds and soundtracks. Furthermore, we concluded that a game designed for older people should also have simple rewards, reinforcement messages and language adapted to the target audience, considering their preferences and low experience using technology.;;en_US;Declined;0;2017;2017-02-08 14:22:04
71316;Denis Andrei   de Araujo;Universidade do Vale do Rio dos Sinos;UbiTourism: An Ontology Net for Ubiquitous Tourism;Electronic Tourist Guides can generate valuable results to the tourist with the use of location and also the context and user profile information. The support of semantic resources in the development of these tourism systems can enhance the meaning of a touristic offer, to facilitate an automatic association of a tourist profile and some context, among other possibilities. Therefore, several recent works in this area apply knowledge representation resources. The Ubitour research project uses semantic resources to improve the results in the personalization of tourist recommendation. This paper describes the improvements in an ontology developed in the Ubitour Research Project. The main scientific contribution of this work is the proposal and evaluation of an ontology net to the tourism area which allies traditional electronic tourist guide’s information with ubiquitous computing elements, such as context and profile user. The results obtained indicate advances in concepts coverage and growth flexibility.;;en_US;Declined;0;2017;2017-02-18 14:12:49
71402;Rodrigo Bastos   Vasconcelos;Universidade Estadual do Ceará;Problema do Carteiro Chinês não dirigido para otimizar oproblema de coleta de lixo na cidade de Fortaleza;The problem of determining, in an undirected graph, the minimum cost circuit passing through all the edges of this graph, is known as the Chinese Undirected Postman Problem (PCCND). This problem is contained in the class of NP-complete problems, therefore, there is no deterministic polynomial algorithm that finds the exact solution for any instance of the problem. The problem addressed consists of determining a shortest path that starts at some vertex of the graph, passes through all its edges at least once and returns to the initial vertex. This work formalizes a way to calculate the optimal route of the Chinese postman. At the end of the study, the developed algorithm is applied to a real example of the garbage collection problem in the city of Fortaleza.;;pt_BR;Declined;0;2017;2017-02-22 21:48:28
71479;Thiago   Bispo;Universidade Federal de Sergipe;Ferramenta web para geração multi-parametrizada de corpora linguísticos na Nuvem;Mechanisms for collecting and automatically processing texts in natural language are essential for NLP systems. Unfortunately, tools for this purpose are not abundant, especially if we consider the Portuguese language as a target. In this article, we present the design, development and evaluation of a new tool for this purpose, uCrawnler, which facilitates the collection of such texts from the Web or Twitter. uCrawnler allows multiple parameterization in order to enable the automatic generation of corpora suited to the needs of the expert user. We evaluated uCrawnler both in relation to the quality of the corpora generated for creating language models and their usability. We also compared uCrawnler with another similar tool, BootCat. The results showed that, in addition to the configuration and data search process being more efficient through uCrawnler, the generated corpora achieved good Perplexity values.;;pt_BR;Declined;0;2017;2017-02-26 23:06:37
71678;Bruno Santana da   Silva;UFRN;Relação entre Chamados e Modiﬁcações no Código-Fonte de um Sistema de Acompanhamento de Obras;Some systems undergo a long period of maintenance during their useful life. Cycles often occur in which users report errors and the development team modifies the system to correct them. After some time modifying the system, it is difficult to identify the source of new errors: Did the errors arise during development or during system maintenance? What modification to the system could have caused a particular error in the future? Is it necessary to continue taking care of testing activities during system maintenance? Questions like these already find some answers in academia, but professionals do not always understand how they can affect their work in the industry. This article presents a case study on the relationships between calls and modifications to the source code over 3 years of a construction control system for an energy company. Understanding these relationships highlighted opportunities for improvements in the process of developing and maintaining the analyzed system and other similar systems.;;pt_BR;Declined;0;2017;2017-03-05 22:44:59
71687;Reinaldo Gomes   Baldoino filho;UnB;Modelo Para Gerenciamento das Comunicac¸ ˜oes em Projetos de TIC Integrando os Frameworks ITIL, COBIT, PMBOK e ISO 31000;It is known that Project Management is an important tool in companies that want to achieve their objectives. There are numerous tools that help with Project Management and also help with risk mitigation in projects. The main objective of this article is to demonstrate a model that includes some of the main \textit{frameworks} that can assist in project execution and help mitigate the risks of uncertainty in ICT projects, based on project communication, for this using the ITIL and COBIT frameworks and the ISO 31000 standard.;;pt_BR;Declined;0;2017;2017-03-06 10:27:06
72127;Paulo Roberto Martins de   Andrade;University of Regina;Representing Non-Relational Databases with Darwinian Networks;The Darwinian networks (DNs) are first introduced by Dr Butz to simplify and clarify how to work with Bayesian networks (BNs). DNs can unify modeling and reasoning tasks into a single platform using the graphical manipulation of the probability tables that takes on a biological feel. From this view of the DNs, we propose a graphical library to represent and depict non-relational databases using DNs. Because of the growing of this kind of databases, we need even more tools to help in the management work, and the DNs can help with these tasks.;;en_US;Declined;0;2017;2017-03-25 22:16:36
72197;Emmanuel Sávio Silva   Freire;Instituto Federal do Ceará;Extensão do Metamodelo do Diagrama de Casos de Uso para a Modelagem de Requisitos em Projetos de Sistemas Multiagente Normativos;Through requirements modeling it is possible to understand users' needs and map them to the system that will be developed. In this sense, the UnifiedModeling Language (UML) has the use case diagram to support this phase. However, for modeling multi-agent systems, Guedes (2012) proposed some changes to enable the modeling of typical entities found in these systems without considering the rules that regulate the behavior of these entities. This article aims to present an extension of Guedes' (2012) metamodel to enable the modeling of actors and use cases together with the norms present in normative multi-agent systems. Additionally, a modeling example is used to illustrate the new version.;;pt_BR;Declined;0;2017;2017-03-29 13:06:00
72523;Emmanuel Neri   Souza;Institutos Lactec;Um comparativo quantitativo de código fonte de arquiteturas de micro serviços em relação a arquiteturas monolíticas;From 2012 onwards, new practices of subdividing large software structures into small structures, later called microservices architecture, began to emerge, which present software concepts that are flexible to change, scaling and with integrations between systems as their essence. . However, in most current systems, the concept of monolith software is adhered to, in which every solution is found in a single software structure, which causes less flexibility in the system architecture. From this, the article applies the concepts of software decomposition proposed by the microservices architecture, through which the divergent structural characteristics are demonstrated, such as the size of the source code, where the source code can reach quantities of lines of code and cyclomatic complexity greater than double.;;pt_BR;Declined;0;2017;2017-04-10 22:48:43
72524;Cristiano Torres do   Amaral;Fundação Universidade Federal de Rondônia (UNIR);Sistema de Irrigação de Baixo Custo de Uso na Agricultura Familiar na Amazônia;This article presents the development of an automated irrigation system control prototype that was applied to family farming in Rondônia. This project was carried out in the cultivation of vegetables and other crops developed by the Association of Parents and Friends of the Exceptional (APAE) in the city of Alta Floresta d’Oeste. The low-cost prototype monitors soil moisture and optimizes the irrigation process, maintaining conditions for plant development, in addition to making rational use of the water used. The device developed was optimized for the reality of the Amazon and had a relevant social contribution. To execute the project, graduates of the bachelor's degree course in electrical engineering at the Fundação Universidade Federal de Rondônia (UNIR), in a voluntary and supportive manner, presented the project as a work to complete the activities of the discipline of microprocessed systems, guided by the Energy Research Group Sustainable Renewable (GPRES). At the end of the activities, the system was donated to a philanthropic entity.;;pt_BR;Declined;0;2017;2017-04-10 23:21:11
72568;Bruno Guazzelli   Batista;Universidade Federal de Itajubá;Análise Comparativa entre Ferramentas de Otimização de Tráfego WAN em um Ambiente Real de Manufatura;Applications that travel through a wide area network (WAN - Wide Area Network), which can connect offices and data centers across the planet, suffer from performance caused by problems such as latency, jitter and packet loss. WAN optimization aims to minimize or eliminate the impact caused by WAN limitations in order to improve system and application performance. Therefore, this work aims to analyze the acquisition of a WAN optimization solution taking into account technical and business aspects, as well as comparing two solutions, which were tested in a production environment of a multinational manufacturing company. It was found through experiments that the acquisition of a WAN acceleration solution is fundamental to providing the business with the performance necessary for its operation and obtaining a short and long-term return on investment.;;pt_BR;Declined;0;2017;2017-04-12 19:17:14
73605;Nilson dos   Santos;UNOPAR;O DESENVOLVIMENTO WEB NAS ORGANIZAÇÕES PÚBLICAS – AVANÇOS E DESAFIOS;The article aims to highlight the advances and challenges faced by public organizations regarding the development of WEB applications. Among the advances are: integration with society, creation of ePING and eMAG, public software website and government school open to society. The Challenges are: transforming the IT area into a board, reaching the organization as a whole, changing the IT culture within the organization and standardizing development.;;pt_BR;Declined;0;2017;2017-05-22 9:56:07
73765;Silvio R. R.   Sanches;Universidade Tecnológica Federal do Paraná;Impacto da Taxa de Atualização em Realidade Aumentada para Dispositivos Móveis;Augmented Reality applications based on fiducial markers enable real-time interaction of users with virtual elements. Since these applications are computationally expensive, they must be carefully designed so that they can run on mobile devices. Application developers for this type of platform must be concerned about meeting minimum limits for certain requirements such as frame update rate. The objective of this work is to demonstrate that there is a correlation between the update rate and the ease of use of the system, in addition to identifying the minimum limits for this requirement. The results showed that, in addition to there being a correlation between these factors, the minimum limits found vary depending on the type of interaction.;;pt_BR;Declined;0;2017;2017-06-02 0:01:31
73940;Hugo   Saba;Universidade do Estado da Bahia;PERCEPT: Um Framework para o Desenvolvimento de Aplicações de Computação Perceptiva;Natural interfaces are increasingly popular modes of human-computer interaction, as they allow people to interact with devices in an intuitive way, meeting users' growing needs. Perceptual technologies such as Kinect and Intel RealSense 3D meet these needs, providing more immersive and human interfaces. The objective of this work was to develop and validate the Percept framework, which provides a generic layer for perceptual computing applications. To analyze the coding effectiveness and reuse of the framework, applications were developed for both devices (Kinect and Intel RealSense 3D).;;pt_BR;Declined;0;2017;2017-06-04 13:12:06
74073;Flávia Gonçalves   Fernandes;Universidade Federal de Goiás - UFG;Jogo de quebra-cabeça para crianças com deficiência física nos membros superiores utilizando o dispositivo vestível Myo;The characteristics of immersion, involvement and motivation have made serious games an important tool used in the medical field. However, there are people who, due to some physical disability, cannot or do not feel motivated to play. From this perspective, this work presents a strategy to support human-computer interaction for children with upper limb disabilities through a wearable device, with the aim of improving access to digital games for this target audience. To develop this work, the Myo wearable device was used to control a puzzle game as a means of providing interaction between the individual and the game. In this context, the game is controlled by the movements of the user's upper limb, which has the disability, through Myo. To validate the research, the game developed was made available to individuals with physical disabilities in the upper limbs, aged between eight and fifteen years, from the Association for Assistance to Disabled Children (AACD). Therefore, it was observed that the research participants were able to play using the disabled member with the support of Myo and felt more motivated to play. In the long term, it is expected to contribute to patient motivation through technological innovations.;;pt_BR;Declined;0;2017;2017-06-11 18:17:09
75223;Maíla Lima   Claro;Universidade Federal do Piauí;Métodos Computacionais para Segmentação do Disco Óptico em Imagens de Retina: Uma Revisão;The use of digital image processing (PDI) techniques is highlighted in the medical scenario for the automatic diagnosis of pathologies. In the ophthalmological area, glaucoma is the second leading cause of vision loss in the world and there is no cure. Currently, there are treatments to prevent vision loss, however the disease must be discovered in the early stages. The main objective of this article is to review the methodologies and techniques for segmenting the optic disc boundaries and excavation. These regions are used to calculate metrics for glaucoma classification and assist professionals in the field. The most recent works published in the area were classified into four groups according to the main PDI technique applied: active contour superpixel clustering and mathematical morphology. Furthermore, a survey of the main image databases and evaluation metrics used was carried out.;;pt_BR;Declined;0;2017;2017-07-25 9:55:28
75319;Diego   Couto;;Composição de Agentes EBDI: Integração WASABI-Jason;Emotions play a very important role in the decision-making process of human beings and it is natural that their use becomes a very fertile field in the area of ​​Artificial Intelligence, whether with the aim of bringing the behavior of computational agents closer to that of humans, or simply to improve the human-computer relationship. This work presents the integration of the WASABI emotion simulator with the BDI JASON agent framework, to provide emotional agents. The results obtained suggest that the performance of agents in the environment, as well as in human societies, is susceptible not only to their programmed behavior, but to their emotional personality and environmental conditions.;;pt_PT;Declined;0;2017;2017-07-29 14:58:36
75487;João Paulo   Aramuni;Universidade FUMEC;O IMPACTO DA TECNOLOGIA DA INFORMAÇÃO NO ENSINO SUPERIOR: Desafios da ubiquidade na aprendizagem estudantil;This article presents an approach to ubiquitous computing at the service of higher education from the point of view of the contribution of new digital technologies to learning. The period of technological convergence in the current information society has forced students and teachers to adapt to new methods of content exposure and knowledge transfer. The analysis of examples of human-machine interactions between the digital environment and the academic environment illustrates theoretical considerations about new ways of absorbing content and discoveries of knowledge, more precisely that of ubiquity, in the construction of new cognitive experiences for the student and in modernization of teaching by teachers.;;pt_BR;Declined;0;2017;2017-08-05 17:14:13
75590;Lucio   Padrini-Andrade;Universidade Federal de São Paulo/Escola Paulista de Medicina;Avaliação da usabilidade de um sistema de informação em saúde neonatal, através da percepção do usuário, utilizando a ferramenta System Usability Scale (SUS);The evaluation of information systems is a necessity both to improve and to justify the high investments made in IT. This study aimed to measure the degree of satisfaction of health professionals regarding the usability of a neonatal health information system, using the System Usability Scale (SUS) instrument and identify the factors that can influence the evaluation of user satisfaction regarding usability. Cross-sectional and exploratory study carried out with health professionals from the centers of the Brazilian Neonatal Research Network (RBPN). To evaluate usability, the SUS was used between February and March/2017. Descriptive and inferential statistical analysis of the collected variables was carried out, with the purpose of describing the sample, quantifying the degree of user satisfaction and identifying the variables associated with the degree of user satisfaction in relation to usability. The usability of the system was not associated with age, sex, education, profession, area of ​​activity, level of computer knowledge and time of using the system. The instrument proved to be easily applicable for evaluating healthcare user satisfaction in relation to the use of a computerized system and can be used as a quick usability assessment.;;pt_BR;Declined;0;2017;2017-08-09 20:48:38
75591;Rubens   Barbosa Filho;Universidade Estadual de Mato Grosso do Sul/Docente;A Parallel Multi-PBIL Applied to Mutimodal Problems;Multi-Population Based Incremental Learning (Multi-PBIL) is a powerful search technique that can be successfully applied to solve highly complex multimodal problems. PBIL (Population Based Incremental Learning) has received increasing attention in various fields of science due to its effectiveness, easy implementation and robustness. Although these strengths are highlighted, there are several articles that highlight certain phenomena that weaken the use of PBIL, such as the loss of diversity in populations and premature convergence. This article describes a Multi-Population Based Parallel Incremental Learning Algorithm. The system designed for testing comprises two multimodal problems with complex search spaces (Schwefel function and Rastrigin function) in a star topology (based on the master-slave model). The results obtained when applying this technique suggest that the parallelization of this model comprises a consistent approach to optimizing complex problems. The performance obtained is relatively superior to that obtained by a sequential algorithm. Based on the results obtained, it will be possible to explore practical problems in future work.;;pt_BR;Declined;0;2017;2017-08-09 21:21:05
75783;Tiago Carmo   Nogueira;Instituto Federal de Mato Grosso;Abordagens Metodológicas da Experiência dos Usuários Cegos Aplicadas nas Interações Web em Dispositivos Móveis: Uma Revisão Sistemática da Literatura;With the exponential growth in scientific interest in evaluating the blind user's experience in Web environments, work that correlates usability attributes aligned with accessibility characteristics becomes imperative. At the same time, with the advancement of technological resources and access to information through different devices, there is a gap in investigations into UX on mobile devices, specifically, the blind user experience. Therefore, this work proposes a systematic review of the literature, identifying the main methods of blind user experience applied in interactions with mobile devices. In this way, 805 scientific articles were identified through the literature, which addressed issues about usability, blind user experience and mobile devices. By extracting the results, sixteen different methods were identified as applied to the blind user's experience in interactions with mobile devices. The applicability of the methods supported by expert reviewers, observation techniques, experimental studies, validation and verification of compliance with the Web Content Accessibility Guidelines (WCAG) stands out.;;pt_BR;Declined;0;2017;2017-08-18 14:09:45
75784;Tiago do Carmo   Nogueira;Instituto Federal de Mato Grosso;Diretrizes de Acessibilidade na Web e Redes Sociais: Uma Revisão Sistemática da Literatura;Online social networks play an important role in the visual representation of relationships, impacting people's interactions. Therefore, it is essential that the social network is accessible, so that all people with some type of disability have equal access to content and interaction opportunities. However, current research focuses on just measuring its benefits during interactions, leaving aside the identification and mitigation of accessibility problems. Thus, this article identifies, through a systematic review, the correlations between the Web Content Accessibility Guidelines (WCAG) and social networks, identifying the main barriers faced by people with disabilities. The results of this review demonstrate that the barriers are related to content, loss of identity, navigability and accessibility. However, there is a lack of work that correlates with the applicability of accessibility guidelines in the construction of social networks.;;pt_BR;Declined;0;2017;2017-08-18 14:44:31
76042;Filippo C. G.   Régis;Federal Rural University of Pernambuco;Decision Make System Based on Mean-Variance Model to Support Stock Market Investment;The Markowitz’s mean-variance model allow find a portfolio’s assets in the stock market that produce a minimum variance (risk) under a target of expected return. One weakness of this model is the computation of the expected return, that is quantified by the arithmetic mean of the historical returns. To produce better estimate for the expected return of each asset, we are proposing the use of Random Walk and GARCH (Generalized Autoregressive Conditional Heteroskedasticity) models instead of the arithmetic mean. The models are also compared with an Algorithm of Random Choices, which simulates an investor who does not use any theoretical and/or statistical basis for compose a financial portfolio. We provided numerical experiments using time series with historical values of assets selected per economic segment, which constitute the indexes of the stock markets: Nasdaq, Dow Jones and BM&FBOVESPA. The numerical experiments were performed upon different levels of return and risk, classified in the efficient frontier. Then, we found investment opportunities for different investor profiles: aggressive, conservative and moderate. For markets with a developed economy, that present low volatility, the better results were obtained using the GARCH model. While in the developing economies with high volatility, the mean-variance model presents better results.;;en_US;Declined;0;2017;2017-08-30 1:22:46
76256;Camila Pereira dos Santos   Tautenhain;Universidade Federal de São Paulo;Cadeias de Suprimentos Sustentáveis: uma breve revisão de modelos e métodos de solução;Sustainability has been increasingly incorporated by industries into supply chains. In this way, planning sustainable supply chains takes into account, in addition to economic benefits, the reduction of environmental impacts and actions that benefit social aspects. As, in most cases, these criteria are conflicting, multi-objective models are the most adopted to approach the problem. Despite the efforts of some studies to propose generic multi-objective models for the problem of planning sustainable supply chains, there is still no widely accepted formulation, due to the specificities of the problems of industries and their processes. Many multi-objective methods for solving these problems are computationally expensive and, in most cases, unsuitable for  real-world case studies. Thus, in the last three years, some efficient heuristic methods have been developed to solve several of these problems. In this context, this article reviews the characteristics of the main and most recent multi-objective solution models and methods for planning these chains and points out directions for future research.;;pt_BR;Declined;0;2017;2017-09-04 16:30:13
76613;Luís Guilherme   Teixeira dos Santos;Universidade Federal do Piauí;Seeded Fuzzy C-means: um algoritmo de agrupamento semissupervisionado aplicado à segmentação de imagens médicas;The use of imaging exams is one of the least invasive ways to identify some diseases. The analysis normally begins by detecting the regions to be investigated and subsequently checking relevant information, such as size and texture. This work proposes the Seeded Fuzzy C-means algorithm, which uses little information provided by a doctor to segment such regions. In this way, the algorithm automates one of the steps, thus leading to a faster diagnosis. This algorithm was evaluated on image bases of leukemia, melanoma and glaucoma, which are diseases that have a harmful effect if not diagnosed early. The results obtained illustrate the feasibility of applying the algorithm, in order to effectively assist doctors in detecting regions, since in most tests the Kappa index achieved was “Excellent”.;;pt_BR;Declined;0;2017;2017-09-21 8:34:26
76740;JEAN MONTEIRO   LIMA;Instituto Federal de Minas Gerais - IFMG;DRPN: Software de Diagnóstico do Risco de  Poluição de Nascentes;In this work, a system was developed that facilitates the work of the environmental consultant in applying the diagnostic assessment index for spring waters, according to the literature on the Spring Water Pollution Risk Index. Following the requirements gathering, analysis and design, implementation, testing and deployment phases, and software validation, the DRPN Application – Diagnosis of the Risk of Pollution of Springs was built for use on cell phones, which proved to be an excellent tool to aid the consultant's work when used in the evaluation of springs at the Federal Institute of Minas Gerais, São João Evangelista campus.;;pt_BR;Declined;0;2017;2017-09-26 19:14:59
76896;Charles Tim Batista   Garrocho;IFSP Campus Campos do Jordão;MusicFence: Um Sistema de Reprodução Automática de Músicas em Áreas Geográficas Através de GeoFences;Listening to music has become a common activity in the daily lives of most of the population. The songs are defined in advance to play according to the user's interest. However, through the Pervasive Computing paradigm, applications are expected to run and integrate seamlessly into people's lives. Therefore, it is expected that this integration will also occur with music, being played according to the context of the area where the device is. To this end, a system capable of providing a new way of listening to music is presented, where it is defined in virtual areas that represent real geographic areas. The system is evaluated and compared with similar proposals.;;pt_BR;Declined;0;2017;2017-10-02 1:12:57
77545;Angelo Maggioni   e Silva;Instituto Federal do Acre - IFAC;Water-Clu: Uma abordagem para agrupamento de amostras de água da Região Amazônica;The analysis of rainfall rates is extremely important as they are related to agricultural development. In the agroindustry, for example, weather conditions that enable the planting of a crop are predicted using Artificial Neural Networks (ANNs) and offer an accuracy rate of 96% [3]. Predicting the cycle of a phenomenon reduces uncertainties and allows human and economic capital to be applied during the essential period. The objective of this work is to map rainfall in the North region and offer a methodology to identify the best planting period. Data collection and the proposed grouping called Water-Clu use only 10 water characteristics such as: pH, turbidity, temperature, among others. The data were collected at the Water Treatment Station (ETA) in the city of Guajará-Mirim, which captures the Madeira Mamoré River located in the North region that borders the states of Rondônia and Amazonas. After using the Water-Clu approach, it was found that water samples can be grouped into 3 classes with SSE of 50.45% and with up to 47.61% fewer attributes than other methodologies.;;pt_BR;Declined;0;2017;2017-10-23 19:51:26
77763;Michel Conrado   Meneses;Universidade Federal de Sergipe;Um Mapeamento Sistemático sobre a Utilização de Fluxo Óptico por UAVs Autônomos para a Detecção de Obstáculos;Currently, unmanned aerial vehicles (UVAs) are used in different commercial applications related to monitoring, cargo transportation and the acquisition of aerial images in general. Due to this, several researches are carried out aiming to improve the navigation capacity of these instruments. However, among the main difficulties faced during this process is the problem of detecting and avoiding obstacles, which is vital for the safety of the device. Therefore, this work carries out a systematic mapping of the main techniques based on optical flow used to solve this problem. To do this, the main databases related to the area are searched and at the end the selected articles are mapped according to the technique used, making it possible to identify the main trends in the area.;;pt_BR;Declined;0;2017;2017-10-31 0:43:42
77891;Diego Felipe   Tischer;Centro Universitário Unifacvest;DT GERENCIAMENTO E CONTROLE DE SUPRIMENTOS E IMPRESSÕES;The objective of this work was to develop a web system for managing printers at Klabin, a unit in Otacílio Costa - SC, to reduce expenses and simplify the administration of printing resources. Several organizations are looking for a solution, which has proven to be very advantageous, as it allows greater control over what is printed. Therefore, this article proposed to evaluate the use of this trend.;;pt_BR;Declined;0;2017;2017-11-07 19:34:50
77970;Daniel Armando   Brandão;Faculdades Integradas de Fernandópolis;Implementação de WebSocket como Solução para Experiência de Usabilidade em Tempo Real em Software Web para Gestão de Leitos Hospitalares.;Finding a solution that meets web software that requires real-time updates today is no longer as complex as it was a few years ago. With the specification of the API interface for using the WebSocket protocol that emerged with HTML5, it became possible to develop applications that present real-time updates to their users, allowing the development of asynchronous software that communicates with the server in an efficient manner. . The WebSocket protocol establishes an interactive connection between client and server so that both can exchange messages at any time, making applications more dynamic and interactive. This article presents the use of WebSocket as a solution for web software requiring real-time updates, explaining the need for the application's main screen to work in real time, demonstrating the application of the WebSocket API in the project through programming technologies and proving its efficiency in relation to the polling technique, previously used to update information on the screen.;;pt_BR;Declined;0;2017;2017-11-11 10:57:02
78312;Marcus Vinicius   Campos Rodrigues da Silva;Escola de Artes, Ciências e Humanidades (EACH) - Universidade de São Paulo (USP);Segmentação de sequências de imagens de Ressonância Magnética cardíaca usando a técnica Shape-Constrained Snake adaptada;The treatment and segmentation of medical images constitute an important area of ​​Computing and its main objective is to highlight and extract the main characteristics of an image, so that they can be used for analysis and information extraction. In Medicine, the use of segmentation techniques helps with diagnosis and is commonly used in several medical specialties. Segmentation techniques applied to medical images must be structured according to the characteristics of the image to be processed and the purpose of the application. Computational applications that employ three-dimensional objects usually require image sequences to be segmented in order to extract the object of interest. Although there are several studies on cardiac image segmentation aimed at extracting the left ventricle, the challenge of segmenting a sequence of images semi-automatically still persists. This work presents an adaptation of the Shape-Constrained Snake Model (SCSM) technique, promoting the propagation of information from the first segmented image in a sequence of images of the same cardiac structure. The results show an average accuracy above 80%, corroborating the potential of the proposed method.;;pt_BR;Declined;0;2017;2017-11-26 16:14:03
78331;Amarildo   de Vicente;Universidade Estadual do Oeste do Paraná;A Heuristic for Nonlinear Optimization Based on the Reproduction of Trees on Mountains;This paper presents an algorithm that employs a heuristic whose aim is the global optimization of non-linear functions. The algorithm aforementioned, which was created and developed by this author, is based on the reproductive process of a fictitious plant species that aggregates the features of several other plants. It not only simulates the transfer of pollen among these plants through the wind, but also the renovation of this species from one generation to another. Due to the environment in which such plants live, the new plants tend to converge to the lower parts of the land, which mathematically represent the minimum points of the function under study. The cited algorithm is intended to optimize non-linear, positive and unconstrained functions. However, small adjustments can be made so that it is applied in cases where the function is not positive. Further, with the usage of penalty functions, it is also possible to employ the aforementioned algorithm in problems with restrictions. This essay shows some experiments using test functions, which indicate an excellent performance of the proposed algorithm.;;en_US;Declined;0;2017;2017-11-27 15:35:38
78455;adilson lopes   khouri;Ex aluno da USP;Combining artificial intelligence, ontology, and frequency-based approaches to recommend activities in scientific workflows;The number of activities provided by scientific workflow managementsystems is large, which requires scientists to know many of them to take advantageof the reusability of these systems. To minimize this problem, the literature presentssome techniques to recommend activities during the scientific workflow construction.In this paper we specified and developed a hybrid activity recommendation systemconsidering information on frequency, input and outputs of activities and ontologicalannotations. Additionally, this paper presents a modeling of activities recommenda-tion as a classification problem, tested using 5 classifiers 5 regressors and a compos-ite approach which uses a Support Vector Machine (SVM) classifier, combining theresults of other classifiers and regressors to recommend and Rotation Forest, an en-semble of classifiers. The proposed technique was compared to related techniques andto classifiers and regressors, using 10-fold-cross-validation, achieving a Mean Recip-rocal Rank (MRR) at least 70% greater than those obtained by classical techniques.;;en_US;Declined;0;2017;2017-12-04 22:36:03
78535;Jayme   Proni;Fundação Educacional de Fernandópolis;Desempenho de Busca Orgânica em Sítios de Comércio Eletrônico – SEO;The proposed article presents the importance of applying SEO techniques to improve sales performance in online stores. After determining markets, types of customers and support tools to assist with SEO, a study was carried out based on a comparison of two websites, one already performing well in SEO and the other performing poorly. In the low-performing version, textual reproduction was redone, through the composition of keywords, generation of friendly links and always respecting Google's semantic Web and the guidelines of the World Wide Web Consortium (W3C). After the indexing time for new content, an increase in revenue of approximately forty-five percent in conversions was observed over a period of six months, this already considering the problem that the VTEX platform suffered throughout the month of October. It is concluded that respecting the grammatical rules used by the search engine results in the desired return, that is, better positioning, which causes more sales.;;pt_BR;Declined;0;2017;2017-12-06 18:44:04
78538;André Luis Sango   Peruchi;FEF - Fundação Educacional de Fernandópolis;Realidade Virtual e Aumentada Aplicadas na Área da Construção Civil, Engenharia Civil e da Arquitetura;Due to their popularization, Virtual Reality and Augmented Reality have currently been widely used in various areas such as construction and by its professionals. The use of these technologies together aims to facilitate the creation and demonstration of projects between construction professionals and their clients, enabling greater interaction between them. The development of this article was based on research into articles, videos and tools that use both technologies to demonstrate the benefits they can provide, taking into account the most used technologies on the market today. Based on research carried out, a result is presented that determines that both tools can reduce costs and also time in some cases compared to traditional forms of development and provide more convenience to the customer. It can be concluded that both Virtual Reality and Augmented Reality bring benefits in the area of ​​construction, for its professionals and also for its customers with a focus on quality.;;pt_BR;Declined;0;2017;2017-12-06 21:38:14
78539;Marcio Alessandro   Lima;FEF- FUNDAÇÃO EDUCACIONAL DE FERNADÓPOLIS;BITCOIN;The traditional economic model is the result of a combination of private initiative and governments. The interference of the State and banks in the market motivated, among other things, the creation of digital currencies, including Bitcoin. This virtual currency entered circulation in 2009, it was created by a programmer identified by the pseudonym Satoshi Nakamoto, who calls it the first open source digital currency. This article compares the use of the Bitcoin currency, the differences in relation to the traditional financial system and the changes that its use causes in the economy. The text analyzes the innovations and impact brought by Bitcoin on society in general and, in particular, on the financial sector. The methodology used to prepare this article is based on bibliographical reviews, supported by descriptive and comparative analysis based on websites, books and magazines relevant to the subject, with the aim of verifying whether decentralized virtual currencies like Bitcoin influence the conventional financial market. Bitcoin may be quite popular among computer geeks and people who have greater freedom right now, but leading economists see it as the key to creating a more stable financial system and reducing social inequality.;;pt_BR;Declined;0;2017;2017-12-06 22:54:30
78542;Marcio Alessandro Eugenio   Lima;FEF- FUNDAÇÃO EDUCACIONAL DE FERNADÓPOLIS;BITCOIN Revolução no mercado financeiro com o avanço da tecnologia;The traditional economic model is the result of a combination of private initiative and governments. The interference of the State and banks in the market motivated, among other things, the creation of digital currencies, including Bitcoin. This virtual currency entered circulation in 2009, it was created by a programmer identified by the pseudonym Satoshi Nakamoto, who calls it the first open source digital currency. This article compares the use of the Bitcoin currency, the differences in relation to the traditional financial system and the changes that its use causes in the economy. The text analyzes the innovations and impact brought by Bitcoin on society in general and, in particular, on the financial sector. The methodology used to prepare this article is based on bibliographical reviews, supported by descriptive and comparative analysis based on websites, books and magazines relevant to the subject, with the aim of verifying whether decentralized virtual currencies like Bitcoin influence the conventional financial market. Bitcoin may be quite popular among computer geeks and people who have greater freedom right now, but leading economists see it as the key to creating a more stable financial system and reducing social inequality.;;pt_BR;Declined;0;2017;2017-12-07 8:41:29
78557;Humberto Lidio   Antonelli;Universidade de São PauloInstituto de Ciências Matemáticas e de Computação;Adaptação de menus Web para dispositivos móveis com foco  na interação por pessoas idosas;The characteristic portability of the Web, leveraged by the growing use of mobile devices, especially smartphones, has motivated the development of methods for adapting the forms of presentation of content available on the Web. Furthermore, the diversification of the profile of users who make use of it is notable. of Web resources. Elderly people are examples of these users, who encounter barriers that tend to hinder or limit their access to applications and Web content in general. This work describes a Case Study that addressed the problem of adapting Web content to devices mobile devices, analyzing the interaction of elderly users with Web menus generated by the Adapte-me! tool. The results obtained indicate better performance in the interaction with the menus generated by the tool. Furthermore, all participants responded better to the adapted menus, as they were able to successfully complete all the tasks defined in the Case Study.;;pt_BR;Declined;0;2017;2017-12-07 14:14:14
78889;Alane Marie   de Lima;Universidade Federal do Paraná;Exact Algorithms for the Graph Coloring Problem;The graph coloring problem is the problem of partitioning the vertices of a graph into the smallest possible set of independent sets. The main exact algorithms for the problem are scattered in the technical literature in scientific papers. Hence, the goal of this work is to group and contextualize some of these algorithms. We discuss the solutions based on Integer Linear Programming, Branch-and-Bound and Dynamic Programming. ;;en_US;Declined;0;2017;2017-12-16 11:23:08
79335;Geovane Menezes   Ramos Neto;UFMA;Study of Local Binary Pattern Variants for the Diagnosis of Breast Cancer;Given the increase in the occurrence and mortality of breast cancer, detection and diagnosis techniques are being developed in order to suppress the damage of this disease caused by early diagnosis and improvements in treatment efficacy. Aiming to contribute to the diagnosis of the specialist, this paper presents a methodology to diagnose breast cancer using techniques of analysis of local texture patterns (LBP, LQP, CLBP and CS-LBP) along with spatial decomposition approaches to extract relevant characteristics. The best result was the CLBP technique with the Cartesian division 2x2, which obtained 89.09% Accuracy, 84.00% Sensitivity and 95.09% Specificity, showing that the use of these descriptors is valid for classification of breast cancer.;;en_US;Declined;0;2018;2018-01-03 0:32:22
79634;Samantha Adeline Córdova   da SIlva;Centro Universitário Facvest;BIBLOS: APLICATIVO MOBILE PARA INCENTIVAR ADOLESCENTES A DESENVOLVER O HÁBITO DA LEITURA DIÁRIA DA BÍBLIA;Nowadays, it is evident in teenagers and young people that it is difficult to develop the habit of reading and this is an obstacle to common activities in the religious environment such as Bible reading. In an attempt to reverse this situation, the idea was born to explore game mechanics and mobile device technology to create something that would be attractive to them. This article details the development of an application for mobile devices called Biblos, the gamified Bible, a new technology created to help people develop the habit of reading the Bible daily. Biblos, the gamified bible is an application for cell phones and tablets created to give those who wish to progress in their biblical studies the necessary motivation to develop the habit of reading the Bible daily using gamification as the main tool, and thus helps them to have a better understanding of the content of this book and spiritual growth, all in a simple and fun way.;Bible, gamification, Android, application, mobile development.;pt_BR;Declined;0;2018;2018-01-15 13:31:55
79796;Manoel Miqueias   Maia;Centro Universitário Católica de Quixadá - UNICATÓLICA;DESENVOLVIMENTO DE UM REPOSITÓRIO DE PROJETOS BASEADO NOS CONCEITOS DE DESIGN THINKING;Innovation is today a fundamental differentiator in the lives of organizations, especially for those seeking to launch new concepts, new products or solve a market problem, given that competitiveness – given the great flow and speed of information exchange – is overwhelming. Some of the innovation methodologies are oriented towards the problem to be solved, involving a creative process that requires methods and techniques to organize and evolve your ideas, in addition to facilitating their validation and implementation. This is where Design Thinking fits in, which is a solution and innovation methodology in a problem-based approach that, a priori, was used by designers and applied to deductive thinking. In itself, Design Thinking focuses on empathy, creativity and people, comprising several tools and techniques, some of which are: the persona, storyboard, insight cards, guiding criteria, stakeholder map, data collection plan. data, feasibility analysis and feedback matrix. These, in turn, are divided and applied to the phases of the methodology, namely: immersion, analysis and synthesis, ideation and prototyping. Therefore, this article aims to describe the process of developing a system that provides and simulates Design Thinking tools. And it goes further: the solution serves as a repository for projects, allowing projects of ideas to be created and made available using the tools. The system, named Design Thinking Tools – or simply DTTools – is an application for the Web platform, developed in the Java language, using JSF technology with Primefaces components, the PostgreSQL DBMS as a database, Apache Maven and Apache Tomcat , in addition to using the MVC software architecture pattern. Finally, it presents the achievement of results with the fulfillment of the research objective, such as the implementation of the tool and, in addition, its responsive behavior and potential to support data investigation to aid analysis and decision making from reports. The system allows the creation of personal user accounts and maintain innovation projects through design thinking.;Innovation tool, Problem solving methodology, Web system, Project repository;pt_BR;Declined;0;2018;2018-01-19 16:12:16
79840;Roger   Ritter;UFRGS;Minimizando o esforço de migração de cenários BDD para a plataforma Android;The development of mobile versions of corporate systems that already run on Desktop and/or Web platforms has become common. Although many functionalities remain valid in the new environment, the process of migrating both logic and tests can be quite complex. This work presents the MBehavior tool, a framework that allows the reuse of BDD scenarios that already exist on non-mobile platforms for system testing on the Android platform. MBehavior allows usage scenarios valid for different platforms to be written once and executed on Desktop, Web and Android platforms. Furthermore, platform-specific scenarios can be written alongside other scenarios to be executed only on the platform of interest, allowing the developer greater freedom in organizing and maintaining the scenarios. Experiments have shown that 83% of real application scenarios can be reused, reducing migration effort.;Android, Acceptance Testing, Behavior Driven Development,;pt_BR;Declined;0;2018;2018-01-21 11:24:35
80047;Rafael da Paixão   Cândido;Universidade Federal de Uberlândia (UFU);Refinamento de modelos de navegação de robôs autônomos através da calibração do sistema de odometria;Bio-inspired techniques have been investigated in route planning in autonomous robot navigation models. Among these techniques, cellular automata (ACs) were shown to be a decentralized and low computational cost option. From the study of navigation models based on previously published ACs, it was noticed that the use of environments formed by cells of the size of the e-puck robot results in trajectories with collisions. In this work, a method of odometry calibration was integrated to these models of navigation in order to guarantee a more accurate trajectory. Simulations showed that the adopted method was able to improve the trajectorie in the scenario evaluated. The robot not only got closer to the goal cell, but also presented a path closer to the ideal and totally free of collisions. ;;pt_BR;Declined;0;2018;2018-01-31 20:57:43
80298;Flávia Gonçalves   Fernandes;Universidade Federal de Goiás - UFG;Aplicação de Algoritmos Genéticos para Solução do Problema da Caixa Preta;In systems theory, a closed system of potentially high complexity is called a black box, the internal structure of which is unknown or not taken into account in its analysis, which is thus limited to measures of the input and output relationships. exit. Therefore, this work aims to implement a Genetic Algorithm to solve the Black Box Problem and carry out a simplified study of the effects of some of the parameters on the performance of the implemented algorithm.;Genetic Algorithms, Artificial Intelligence, Black Box Problem.;pt_BR;Declined;0;2018;2018-02-12 14:44:48
80299;Flávia Gonçalves   Fernandes;Universidade Federal de Goiás - UFG;Aplicação do Algoritmo de Dijkstra para otimização da trajetória entre diversos municípios de Minas Gerais;In the technological and globalized world we currently live in, it is always necessary to implement new solutions in order to alleviate problems and make life easier for society, such as determining shorter routes when traveling, for example. In this line of reasoning, Dijkstra's algorithm is the most famous of the algorithms for calculating the minimum cost path between vertices of a graph and, in practice, the most used. Therefore, this work aims to apply Dijkstra's algorithm with the purpose of obtaining the optimization of the trajectory between several municipalities in the Brazilian state of Minas Gerais.;Dijkstra's Algorithm, Graphs, Path optimization.;pt_BR;Declined;0;2018;2018-02-12 14:48:08
80327;Luis Eduardo   Costa Laurindo;Estácio CEUT;Location of the Basic Health Units in Teresina Using the Model p-Center;The objective of this article is to carry out a study using the locationmodel p-Centre, applying it to the location of the Basic Health Units (UBS) in theneighborhood Lourival Parente, in the city of Teresina, capital of the Brazilian state,Piauí. For the study, two scenarios were approached, and in the first one, new locationswere defined for the installation of the UBSs, considering their reallocation within theregion. In the second scenario, the UBS were located according to the existing one inthe neighborhood. To obtain the two scenarios a representation of the neighborhoodwas constructed using graph theory and then the implementation and application ofthe location model p-Centre. In the present work, the cost of displacement (distancein meters) of the farthest user to the nearest center was used as an evaluation metric.Also taken into consideration in the article is the time the algorithm takes to determinean optimum solution, combinations and iterations that it performs for the problemaddressed. It was possible to verify that the UBS located in the studied neighborhoodwas installed in an empirical way, noting that probably no optimization method wasused to locate it.;;en_US;Declined;0;2018;2018-02-14 18:28:25
80337;Marco Antonio de Castro   Barbosa;Universidade Tecnológica Federal do Paraná;A Memetic Approach for the Traveling Salesman Problem with Draft Limits;This paper presents a solution approach for the Traveling SalesmanProblem with Draft Limits (TSPDL) using a memetic algorithm metaheuristic. TheTSPDL is a variation of the classical TSP applied to maritime transportation, and itconsists of visiting and delivering products for a set of ports using a ship initially lo-cated at a depot. Each port has a delivery demand and the ship can visit each portexactly once, returning to the initial port performing the lowest cost tour. The restric-tion is in the draft limit of each port, which imposes a constraint on the sequence ofvisits made by the ship. As the TSPDL can be reduced to the asymmetric TSP, it isclearly a NP-Hard problem, which makes exact approaches limited to a few numberof instances. The results to be presented in this paper have shown to be sound andvery competitive when compared with other solutions in the literature, expanding thepossibilities of addressing larger real-scale applications.;metaheuristics, logistic, optimization;en_US;Declined;0;2018;2018-02-14 21:18:22
80539;Assuero Fonseca   Ximenes;Universidade Federal Rural de Pernambuco;AS PRINCIPAIS DIFICULDADES PARA A IMPLANTAÇÃO DA GESTÃO POR PROCESSOS EM UMA ORGANIZAÇÃO PÚBLICA;This article described the main difficulties encountered when implementing business process management in a public organization. The case study used participant observation and interviews to collect data. As a result, the main difficulties encountered in the organization were presented with the purpose of allowing the understanding of the current situation and, subsequently, based on the analysis described, a proposal was made that allows the future implementation of process management, with a focus on promoting improvements in processes. your business processes. This approach aimed to create a proposal so that a public organization could optimize its processes and services in order to maximize the value generated for society.;Process management, process improvement, public organization;pt_BR;Declined;0;2018;2018-02-23 17:06:14
80605;Leonardo   Goliatt;UFJF;An extreme learning machine with features selected by an evolutionary algorithm for estimating mechanical properties of lightweight aggregate concretes;In this paper, a Particle Swarm Optimization algorithm is used to adjust the parameters of an Extreme Learning Machine and select features in order to predict mechanical properties of lightweight aggregate concretes. Unlike the approaches found in the literature, the proposed procedure set the model parameters and select the most beneficial subset of features  while simultaneously estimates two important outcomes: the compressive strength and elasticity modulus. These properties can be modeled as a function of up to four features: water/cement fraction, lightweight aggregate volume, cement quantity and lightweight aggregate density. The Particle Swarm Optimization algorithm performs the parameter and feature selection and automatically tunes the number of neurons in the hidden layer and the activation function. The results are compared with a model selection based on exhaustive search on the parameter space. The proposed approach arises as an alternative tool to select the most relevant features and to estimate the mechanical properties of lightweight aggregate concretes.;Extreme Learning Machines, Particle Swarm Optimization, Lightweight Aggregate Concretes,;en_US;Declined;0;2018;2018-02-26 22:40:17
80648;Dayan de Castro   Bissoli;Universidade Federal do Espírito Santo;A Clustering Search metaheuristic for the Flexible Job Shop Scheduling Problem;The problem known as Flexible Job Shop Scheduling Problem (FJSP) is an extension of the Job Shop Scheduling Problem (JSP). In FJSP we have a set of jobs and a set of machines. A job is characterized by a fixed order of operations. Each operation can be processed in a specific set of machines and each of these machines can process at most one operation at a time, respecting the restriction that, before starting a new operation, the current one must be finished. Scheduling is an assignment of operations at machine time intervals. The goal of the FJSP is to find a schedule that minimizes the maximum completion time (makespan) of the jobs. This article describes a hybrid Clustering Search (CS) algorithm for the FJSP. Computational experiments with a standard set of instances of the problem indicated that the proposed CS implementation is robust and competitive to find approximate solutions for the FJSP.;Flexible Job Shop Scheduling, Clustering Search, metaheuristic, hybridization;en_US;Declined;0;2018;2018-02-28 10:26:15
80684;Alane Marie   de Lima;Federal University of Paraná (UFPR);Exact Algorithms for the Graph Coloring Problem;The graph coloring problem is the problem of partitioning the vertices of a graph into the smallest possible set of independent sets. The main exact algorithms for the problem are scattered in the technical literature in scientific papers. Hence, the goal of this work is to group and contextualize some of these algorithms. We discuss the solutions based on Integer Linear Programming, Branch-and-Bound and Dynamic Programming.;Graph Theory, Graph Coloring, Exact Algorithms;en_US;Declined;0;2018;2018-02-28 23:12:09
80704;Renê Douglas   Morais;Universidade Federal Rural de Pernambuco;Finding Multi-objective Shortest Paths with Traffic Congestion in Large-Scale Road Networks;The complexity of real-world problems requires, in most cases, optimized solutions considering multiple objectives. For this reason, the multi-objective optimization has been increasingly used to treat this kind of problems. In this work, an approach is proposed to deal with multi-objective routes generation considering multiple metrics and traffic congestion estimates. A new mutation operator is also proposed to deal with problems that have pre-computed data to create the chromosomes in an evolutionary algorithm. The experiments include vehicles that intend to perform routes with multiple stops in large-scale road networks. The OpenStreetMap data is used to create the road network that contains all information needed. Four scenarios are simulated with different levels of traffic congestion. After this, the obtained results are compared with the best solutions computed by Dijkstra’s Algorithm. The proposed approach has obtained good computational performance and shown efficiency, offer good trade-offs, highlighting the best results for scenarios with higher traffic congestion levels.;Smart mobility, Multi-objective Optimization, Multi-objective Shortest Path Problem, Multi-objective Route Planning Problem, Open street map, Traffic, Road Network;en_US;Declined;0;2018;2018-03-01 22:58:45
80708;Luciano Jose   Senger;Universidade Estadual de Ponta Grossa;Parallel data mining in multicore computers and P2P networks: the FastWeka tool;This paper investigates  the usage of multicore  computers and peer-to-peer distributed computing systems for decreasing  processing times in agricultural data mining tasks.The inherent parallelism of the data mining cross-validation phase (using k-fold technique) is exploited, allowing to achieve a good performance improvement.A classification model, obtained by applying a data mining algorithm on a dataset composed of $581,012$ records (with $55$ attributes each) that describe a forest cover vegetation, was created for evaluating the performance of the proposed parallel tool. A speedup of $9$ was achieved when using $10$ folds on $10$ processing elements, without prejudicing the quality of the classification.It was observed that better results can be obtained when the number of folds is multiple of the quantity of available processing elements and when it is processed only $1$ fold per computer of a peer-to-peer system.;parallel computing, data mining, agriculture;en_US;Declined;0;2018;2018-03-01 11:24:27
80714;Marcelo   Petri;Universidade do Estado de Santa Catarina - UDESC;Resource Scheduling in Service Discovery to MANETs Operating in Post-Disaster Scenarios;This paper presents an approach for resource scheduling in service discovery to MANETs operating in emergency scenarios. The shared resources are for example, ambulances or rescue cars. With an efﬁcient model of resource scaling, it is intended to provide the largest number of victims in the shortest time. In this context, this work presents a solution for the resource scheduling modeled on two approaches: Genetic Algorithm and A-Star Algorithm. The results obtained from the Network Simulator (NS3) validate that the mechanism is efﬁcient in relation to the service time and scalable for different numbers of victims.;;en_US;Declined;0;2018;2018-03-01 12:04:30
80722;Danilo Monteiro   Souza;Programa de Pós-graduação em Engenharia de Computação da Escola Politécnica da Universidade de Pernambuco (POLI-UPE);Planning a WLAN IEEE 802.11n with Cultural Algorithms for VoIP implementation;The satisfaction that an user has when using a VoIP service is, often, related to the service quality. The maximization of this correspondence is conditioned to a good topology planning. However, this requirement is linked to the expert's experience which are, generally, unaware about the main degrading factors: excess access points, interference and imbalance. Therefore, an approach that minimize such problems is necessary. Thus, a Evolutionary Algorithm (Cultural) was adopted to determine the optimal access points placement that maximize quality coverage and minimize deterioration factors. The selected technique was submitted to an environment with 400 users in an area of 10.000 square meter. The 50 simulations brings out that with 8 access points is possible a coverage of 81.00%, of the environment, with imbalance of 5.21%  and interference of 1.55%. The client station had signal quality of -50.2205 dBm, which makes possible to operate in maximum capacity of the main market access points.;Cultural Algorithm, VoIP, WLAN planning;en_US;Declined;0;2018;2018-03-01 19:15:38
80739;Julia Manfrin   Dias;;Applying two energy functions with the HP-2D model in the Ant Colony Optimization.;This work applies a computational optimization algorithm, the Ant Colony Optimization (ACO) with backtracking method for correction of infeasible solutions, to the Protein Structures Prediction problem (PSP), considered a problem of high complexity. This problem is a global health issue, since from the known structure of a protein there is the possibility of its functionalities being explored, effectively collaborating for advances in the development of new medicines. Therefore, the main objective of this work was to analyze the performance of the ACO for PSP using two different energies in the HP-2D representation model: traditional and simplified energies, both found in the literature, in order to make a comparison between them.  A set of proteins applied to the FireFly algorithm was used as the benchmark, which confirmed the good results of the ACO, more specifically with simplified energy.;;en_US;Declined;0;2018;2018-03-01 22:48:45
80740;Pablo Luiz Araújo   Munhoz;Universidade Federal de Viçosa;Locality sensitive heuristics for solving  the  Data Mule Routing Problem;A usual way to collect data in a Wireless Sensor Network (WSN)   is by the support of a special agent, called data mule, that moves between  sensor nodes and performs all communication between  them. In this work, the focus is on the construction of the route that  the data mule must follow to serve all nodes in the WSN. This paper deals with the case when the data mule does not have a global view of the network, i.e., a prior knowledge of the network as a whole. Thus, at each node,  the data mule makes a decision about the  next node to be visited based only on a limited local knowledge of the WSN.Considering this realist scenario, two locality sensitive heuristics are proposed. These heuristics differ by the criterion of choice of the next visited node, while the first one uses a  simpler greedy choice, the second one uses the geometric concept of convex hull. They were executed in instances of the literature and their results were compared both in terms of route length and  in number of sent messages as well.Some theoretical results, a mathematical formulation, and some lower bounds for the global view scenario are also proposed, in order to provide some parameters to evaluate the quality of the solutions given by the  proposed heuristics. The obtained results show that the proposed heuristics give good solutions in a reasonable time when compared with the optimal  solutions and lower bounds.;Data Mule, Routing Problem, Locality Sensitive Heuristics, Convex hull;en_US;Declined;0;2018;2018-03-01 23:58:11
80916;Thiago Militino Santos   Gonçalves;UNINASSAU;SEGURANÇA DA INFORMAÇÃO E AS FERRAMENTAS DE PROTEÇÃO DIANTE DE UM UNIVERSO DE PERCEPÇÃO DO RISCO EM PEQUENAS E MÉDIAS EMPRESAS;Information security is a current issue that must also be addressed in the context of small and medium-sized companies. However, the list of available tools and the type of protection that each of these tools provides is a topic that still does not have the correct treatment by organizational managers. Information security has physical, technological and human aspects, and it is quite common to find companies with protections in the technological and physical areas, leaving the human side of information security without any protection. This fact is even more present when the manager's perception of risk does not point to the threats that the information is subject to. This article deals with information security tools and how the organizational manager's perception of risks can influence the use or not of these tools in the technological, physical and human areas of information security.;Information Security, Small and Medium Businesses, Risk Perception, Protection Tools;pt_BR;Declined;0;2018;2018-03-08 14:53:34
81027;Jeferson Queiroga   Pereira;Programa de Pós-Graduação em Ciência da Computação, UERN/UFERSA;APLICAÇÃO DE METAHEURÍSTICAS HÍBRIDAS AO PROBLEMA DE ATRIBUIÇÃO DE LOCALIDADES A ANÉIS SONET/SDH;Telecommunications systems are undergoing major transformations and expansions, which make telecommunications network planning problems increasingly complex. Therefore, many of these problems can be formulated as combinatorial optimization models, and the use of heuristic algorithms can help resolve these issues in the planning phase. This work proposes an implementation of the BRKGA (Biased Random-Key Genetic Algorithm) metaheuristic – in addition to two hybrid implementations – BRKGA with Vocabulary Building (BRKGA+VB) and BRKGA with Q-learning (BRKGA+QL) – for the Assignment Problem Locations to SONET/SDH Rings (or PALAS for short). In this problem, each client location must be assigned to a ring, also called a local ring. A capacity restriction is imposed on each ring. The objective of the problem is to find an assignment of client locations that minimizes the total number of rings used. This problem is NP-hard, therefore, the use of the aforementioned heuristic methods is proposed to solve this problem.;Network Design, BRKGA, PALAS, Vocabulary Building, Q-learning;pt_BR;Declined;0;2018;2018-03-12 16:38:07
81088;Breno   Costa;UnB - Universidade de Brasília;Comparative Analysis of Performance on Cloud Computing Environments;The use of public cloud services is growing at a rapid pace and many organizations either have started using these services or plan to do so in a short time. This is due to the need to collect the benefitsof the platform, including cost reduction and agility in providing new information technology services, both of which are considered critical factors in meeting the mission of organizations. Public cloud providers have similar offers of infrastructure as a service, but with different characteristics and costs, and it is necessary to evaluate how the resources of an organization’s internal infrastructure compare to the resources offered by those providers, creating a mapping between them. This takes advantage of the experience and knowledge that the organization’s technical team has over the internal infrastructure and reduces the risk of cost increase, timeincrease, or even to offer a cloud service with lower performance than it is already provided using organization’s own resources. This study compares the performance of a computational unit of an organization with a similar unit on two public cloud providers, using metrics to measure processing, storage and network performance,and comparing the costs charged by these providers. The results show that there is a significant variation in performance: in network performance, one provider outperformed the other by approximately one order of magnitude. However, since none of the two providers outperforms the other in all metrics, a mapping between the local infrastructure of the organization and the infrastructure of each provider is created. It will guide provider choice and help on sizing of infrastructure on providers, according to measurement data and characteristics of the workload to be migrated.;Cloud Computing, Performance Analysis, IAAS;en_US;Declined;0;2018;2018-03-14 9:56:46
81542;Omar Andres   Carmona Cortes;Instituto Federal do Maranhão;A Privacy Aware Multi-Agent Data Mining System;The agent-based approach is appealing to Distributed Data Mining (DDM) since the concept of agency offers some relevant features including scalability, flexibility, robustness, and modularity. Additionally, any agenaat-based DDM system has to cope with the problem of ensuring data security and privacy. In this paper, we investigate whether and how the multi-agent system metaphor might be used in a privacy-preserving environment. We implemented a multi-agent architecture called SeAMS, which is capable of mining patterns and preserve the privacy. SeAMS was developed in JADE and designed to be easily extensible and to protect the privacy of any local datasets. Results show that the agent-based approach was able to identify patterns efficiently using three different datasets in distributed time series.;Multi-Agent, Data Mining, Pattern Detection, Machine Learning.;en_US;Declined;0;2018;2018-03-29 19:09:15
81720;SUELLEM STEPHANNE FERNANDES   QUEIROZ;Universidade do Estado do Rio Grande do Norte;Combate à Criminalidade Com Uso Da Geoinformática Para Mapeamento De Possíveis Ocorrências Criminais;Crime is one of the biggest problems faced in Brazil and in many other countries, geoinformatics appears as an alternative that allows for a better understanding and analysis of the problem, thus allowing the creation of more precise public policies to combat crime. This work presents geoinformatics as a viable and effective alternative, capable of providing information to assist managers in developing their policies, mapping the crimes that have occurred, seeking to deduce and predict areas of possible homicides, being able to observe the problem from different angles.;Geoinformatics, Georeferencing, Crime mapping, PostGIS;en_US;Declined;0;2018;2018-04-03 18:19:59
81736;Hemerson Aparecido da Costa   Tacon;Universidade Federal de Juiz de Fora;Human action recognition exploiting frequency domain techniques - A Systematic Literature Review;Human actions can be defined as any kind of significant movement that a person can perform, whether to interact with another person, with some tool or with the environment around them. The task of recognizing human actions deals with the extraction of information from these movements, identification of different characteristics and classification of the action. Some efforts have been done until today regarding the analysis of video in the frequency domain for the mentioned task. The aim of this study is to provide a detailed overview of the state of the art in the topic of human action recognition exploiting frequency domain techniques. A Systematic Literature Review was conducted to address this issue. This study showed that Gabor filters, Wavelet transforms and Fourier transforms are the most used techniques related to the frequency domain and the Support Vector Machine (SVM) is main classifier adopted. One of the conclusions achieved by this work indicates that only recently the frequency domain have being explored in order to execute such tasks.;action recognition, Gabor filter, Wavelet transform, Fourier transform, SVM;en_US;Declined;0;2018;2018-04-04 12:02:22
81941;Carla Katarina   Monteiro;UERN e IFRN;Specification and Detection of Antipatterns in Open Grid Service Architectures;Grid computing architecture is a collaborative, network-based model that enables shared resources. Grid applications are based on the services defined by OGSA (Open Grid Service Architecture). OGSA is a set of standards defining the way in which information is shared among diverse components of large and heterogeneous grid systems. An OGSA architecture evolves through adding new or modifying existing functionalities. Those changes may deteriorate the grid systems and introduce antipatterns (poor and recurrent solutions that may degrade the quality, hindering their maintenance and evolution). In this paper, we propose the rule-based approach to specifying and detect OGSA antipatterns. We apply and validate the detection algorithms using the middleware GPO (Grid Process Orchestration), in terms of precision and recall. We specify and detect 16 OGSA antipatterns in an initial experiment with 13 OGSA processes. Results show that this approach has an average detection precision greater than 89% and recall of 99%.;service architecture, GRID, OGSA;en_US;Declined;0;2018;2018-04-12 14:09:59
81998;Paloma Ribeiro   dos Santos;Universidade Federal do Pampa;Interval definition of the integral Trapezoidal method;When working with numerical calculations in computational environments, we operate on floating-point numbers.  This way, the result is an aproximation of a real number and numbers generated in this process may lead to incorrect results. One alternative to avoid this errors is the utilization of interval arithmetic, which makes possible to obtain interval results with greater accuracy and with less contained error. Being the numerical integration obtained with aproximation, his result is subject to errors. In the literature exist interval integration methods such as the Moore's, Bedregal's and Rall's integration methods and Simpson's interval. In this context, this article defines the interval definition of the integral Trapezoidal method, using the interval extension method and implements the method in a environment that supports the interval type. To verify the obtained results, a numerical analysis was made using the calculation of the interval diameter and the relative and absolute errors. Furthermore, was made a comparation with the Simpson's interval method. By using the interval Trapezoidal method, it was possible to obtain interval results with acceptable errors.;interval arithmetic --- numerical methods, numerical integration, trapezoidal method;en_US;Declined;0;2018;2018-04-15 21:51:41
82071;Flávia Gonçalves   Fernandes;Universidade Federal de Goiás - UFG;A Importância da Realidade Aumentada na Atualidade;Augmented Reality (AR) is a set of technologies that allows you to create graphic environments that simulate existing reality or projected reality. It integrates virtual information with the real environment, and has been used in entertainment, leisure, education and medicine. In this way, Augmented Reality allows the user to interact in the virtual space, experiencing the sensation of locomotion in three dimensions, perceiving and manipulating figures and graphic objects, with application in different areas, assuming an increasingly important role in specific fields of economic, social and cultural life. From this perspective, this work aims to present applications that use augmented reality and their importance for society.;Virtual environment. Augmented Reality. Technology.;en_US;Declined;0;2018;2018-04-18 14:59:40
82101;Dhyonatan Santos de   Freitas;Universidade Federal do Pampa;Representação Baseada em Superpixels para Segmentação de Lesões Melanocíticas em Imagens Macroscópicas;Due to the high incidence of skin cancer and the need for early diagnosis, computer systems have been developed as an alternative capable of assisting in medical analysis. These systems depend on adequate segmentation of the region that delimits the skin lesion. In this work, an unsupervised method to segment malignant melanocytic lesions in macroscopic images is presented. Initially, shadow areas and undesirable artifacts are mitigated and pre-segmentation is achieved using a superpixel-based representation. Then, each superpixel is represented by a set of features extracted from channels R, G and B. In the segmentation step, the graph normalized cut method is used to classify part of the superpixels into two classes, lesion and non-lesion. From these superpixels, an SVM classifier is trained without supervision and used to classify the remaining superpixels. Finally, post-processing methods are applied to improve the obtained segmentation. The results achieved, using a very relevant image base in this area, indicate that the proposed methodology presents better results than other segmentation methods in terms of the XOR error, in addition to reducing the computational cost required during this process.;segmentation, melanocytic lesions, macroscopic images, XOR error.;en_US;Declined;0;2018;2018-04-19 16:27:28
82664;Arthur Giesel   Vedana;;V: a language with extensible record accessors and a trait-based type system;This article introduces the V language, a purely functional programming language with a novel approach to records.Based on a system of type traits, V attempts to solve issues commonly found when manipulating records in purely functional programming languages.;Functional Programming Languages, Records, Traits;en_US;Declined;0;2018;2018-05-07 20:00:18
82759;Mônica   Martins Feitosa;Centro Universitário UnirG;CARACTERÍSTICAS QUALITATIVAS PARA DESENVOLVIMENTO DE JOGOS DE SOBREVIVÊNCIA;Although survival is one of the most acclaimed genres among Steam users, there is still criticism that shows discontent about survival games not really being about survival. Therefore, we tried to remedy this situation through some qualitative characteristics for developing games of this genre, in order to highlight the fundamental aspects that must be considered when designing a game. The identified issues include: simulation, gameplay, difficulty, setting and graphics. These were identified based on analyzes carried out by users (players) of 15 survival games on Steam. The analysis carried out will point the way for developers to approach survival mechanics in a systematic, but not rigid, way. It was created based on successful games of the same genre, and aims to highlight the importance of the five components as a methodology for developing survival games.;Survival Games, Features of Survival Games, Game development.;en_US;Declined;0;2018;2018-05-11 12:21:33
82809;Diógenes Antonio Marques   José;Universidade do Estado do Mato Grosso (UNEMAT);Performance Evaluation of Wireless Mesh Networks Using the OLSR Protocol and Extensions;MESH wireless networks are ad-hoc, self-organizing, fault-tolerant networks capable of supporting different types of applications. As a result, several works on performance evaluation of MESH networks have been produced. However, most of these assessments are applied to specific cases that do not take into account a real environment. Therefore, the objective of this work is to propose an environment for evaluating MESH networks based on a real scenario. Thus, a simulation environment was modeled in NS-2 using the wireless network of the City Hall of FC00::FEED/96 (Brazil) as a model. The OLSR protocol and five route choice criteria were used in the evaluation, hop-count, FC, ETX, ML and MD. The results showed an advantage of the hop-count and FC criteria based on: throughput, packet delivery rate and end-to-end delay. Furthermore, it was observed that characteristics of the environment such as mobility and signal interference can negatively affect routing metrics that use probe packets to calculate their routes.;MESH — Networks — Routing — OLSR;en_US;Declined;0;2018;2018-05-14 13:40:30
82870;Samara Luiza da   Silva;Pontifical Catholic University of Minas Gerais;Using Clustering and Summarization Techniques on Patent Database through Computational Intelligence;The granularity of large patent classification systems hampers the reclassification process by which patent categories are broken down into smaller ones, suggesting new categories. As these groups belong to a constricted domain of knowledge, keywords and subject descriptors tend to be similar and therefore insufficient to differentiate documents. In this context, the identification of common cited references can be useful to define semantic relationship among patents. This work presents an automatic method to cluster patents using Self Organizing Maps networks and common occurrence of cited patents as attribute. Beside this, two multi-document, extraction based, summarization techniques are implemented in order to suggest sentences that better represent the new groups created. An empirical experiment was conducted using a patent database from the United States Patent and Trademark Office with all patents of four subgroups classified by the Cooperative Patent Classification system. The obtained results show that patents clusters were successfully identified through their cited patents. The results were compared with clusters generated by another algorithm using word frequency as attribute. This study can contribute with the reclassification process at subgroup level of current patent classification systems, showing the citation analysis as an alternative attribute of the automatic clustering process. ;Computational Intelligence, Information Systems, knowledge Organization, Patent Databases;en_US;Declined;0;2018;2018-05-15 19:38:00
84005;Hudson Geovane de   Medeiros;Universidade Federal do Rio Grande do Norte;Investigation of Archiving Techniques for Evolutionary Multi-objective Optimizers;The optimization of multi-objective problems from the Pareto dominance viewpoint can lead to huge sets of incomparable solutions. Many heuristic techniques proposed to these problems have to deal with approximation sets that can be limited or not. Usually, a new solution generated by a heuristic is compared with other archived non-dominated solutions generated previously. Many techniques deal with limited size archives, since comparisons within unlimited archives may require significant computational effort. To maintain limited archives, solutions need to be discarded. Several techniques were proposed to deal with the problem of deciding which solutions remain in the archive and which are discarded. Previous investigations showed that those techniques might not prevent deterioration of the archives. In this study, we propose to store discarded solutions in a secondary archive and, periodically, recycle them, bringing them back to the optimization process. Three recycling techniques were investigated for three known methods. The datasets for the experiments consisted of 91 instances of discrete and continuous problems with 2, 3 and 4 objectives. The results showed that the recycling method can benefit the tested optimizers on many problem classes.;Archiving techniques, Multi-objective evolutionary algorithms, Recycling techniques;en_US;Declined;0;2018;2018-06-18 17:42:31
84388;Dalton Foltran   de Souza;Universidade Federal de Goiás;Escalonamento de Recursos Considerando Comportamento de Fila e Qualidade de Canal para Redes 5G Baseadas em LTE;With the increasing challenges imposed on mobile wireless communication systems, new technologies are being studied with a view to developing 5G. Among them is the use of modulations, such as F-OFDM and UFMC and the search for more efficient scheduling algorithms. In this article, we propose a scheduler that considers the size of the buffer queue and the channel quality in order to increase the throughput and the fairness index in the LTE network downlink. The metrics evaluated for the schedulers considered in this work were transmission efficiency, throughput, fairness index, delay and losses. We also evaluate the impact of OFDM-based modulations on the performance of different schedulers. Through computational simulations, we show that the proposed algorithm provides better results in all evaluated metrics in relation to the other compared algorithms.;;en_US;Declined;0;2018;2018-06-30 17:18:15
84690;Fernando   Ayabe;Universidade de São Paulo - USP;Fatores de sucesso na terceirização da Tecnologia da Informação: Uma revisão sistemática da literatura;This research aims to identify the success factors of information technology outsourcing (TTI). This is a bibliographical research that is characterized by being a qualitative study. The Systematic Literature Review (SLR) was used as a bibliographic review technique, in contrast to a review using ad-hoc literature selection. Two databases (ACM and IEEE) were consulted, from which 321 articles were extracted. The application of the research protocol obtained 32 articles, which were analyzed in full. The research highlighted two dimensions of the outsourcing relationship that are the most referenced in scientific literature: the Behaviors dimension and the Interactions with a Contractual Focus dimension. The result confirms the importance attributed to outsourcing contracts highlighted in the literature since the 1990s when the adoption of TTI intensified. Furthermore, the Behavior dimension was related to the importance of the human factor in IT projects, also highlighted in the literature.;Success Factors, Outsourcing, Information Technology;en_US;Declined;0;2018;2018-07-10 0:46:51
84722;Fernando   Ayabe;Universidade de São Paulo - USP;Fatores de sucesso na terceirização da Tecnologia da Informação: Uma revisão sistemática da literatura;This research aims to identify the success factors of information technology outsourcing (TTI). This is a bibliographical research that is characterized by being a qualitative study. The Systematic Literature Review (SLR) was used as a bibliographic review technique, in contrast to a review using ad-hoc literature selection. Two databases (ACM and IEEE) were consulted, from which 321 articles were extracted. The application of the research protocol obtained 32 articles, which were analyzed in full. The research highlighted two dimensions of the outsourcing relationship that are the most referenced in scientific literature: the Behaviors dimension and the Interactions with a Contractual Focus dimension. The result confirms the importance attributed to outsourcing contracts highlighted in the literature since the 1990s when the adoption of TTI intensified. Furthermore, the Behavior dimension was related to the importance of the human factor in IT projects, also highlighted in the literature.;;en_US;Declined;0;2018;2018-07-10 18:33:08
84766;Paulo César Florentino   Marques;Universidade Federal Rural de Pernambuco;HealthDrones - Navegação de VANTs Autônomos Baseada em Autômatos Celulares;Instituted by Law 9985/2000, the National System of Conservation Units regulates management and oversight of natural resources in environmental preservation areas. However, the large amount of Conservation Units in different locations with a wide range of territorial extension weakens its oversight regarding enviromental crimes. As such, using techonologies capable of assisting in the process of inspection can be of great help. In this work we investigate ways to assist this process by means of a detailed analysis of autonomous unmanned aerial vehicles (UAVs). This work's objective is to define and validate a computational model capable of performing manouvers and flights to inspect a certain area. The possibility of using these UAVs in an autonomous and controlled manner was analyzed. Experiments were performed to measure automated flight manouvers accuracy, and the results obtained were compatible with what the manufacturer atests to deliver when it comes to the remote control software of the UAV. The same maneuvers were tested using the maker's remote control software and the automated scripts developed using a Node.js API. Besides, a simulation environment was implemented along with a cellular automaton capable of generating pathways and executing the vehicle's simulated actions. The scripts generated by the automaton follow the same developing patterns of the scripts in the first experiments, showing that it is statistically compatible with the maker's software. Finally, solutions to make the studied UAV more autonomous for environmental preservation areas inspection are proposed, and problems with selected UAV are pointed.;UAV, Drone, Environmental monitoring, Celullar Automata, Environmental monitoring.;en_US;Declined;0;2018;2018-07-12 12:23:14
85479;Flávia Gonçalves   Fernandes;Universidade Federal de Goiás;SISTEMA PARA CONTROLE DE NÍVEL DE LÍQUIDO EM UM TANQUE;Among the many assignments of an engineer, systems control is a prime task for the success of a business. This management is essential to ensure production control, reduce costs, avoid losses and target profits. However, managing control systems is a challenge that can be time-consuming for the manager, making other actions of extreme importance for productivity and company growth unfeasible. To facilitate this work, the market has developed and perfected software that enables this control in a simpler and more functional way. From this perspective, this work aims to use fundamentals of control systems to maintain the desired level of a liquid in a tank. For this, we also inserted controllers with independent actions in the system: proportional (P), proportional-integral (PI), proportional-derivative (PD) and proportional-integral-derivative (PID), presenting the results obtained from performance of the system for each case, with their respective discussions and conclusions.;Performance, Transfer Function, Control System.;en_US;Declined;0;2018;2018-08-02 12:10:44
86171;Maurício Aronne   Pillon;Universidade do Estado de Santa Catarina;Uma taxonomia para segurança de contêineres em nuvens computacionais: problemas e solucões;Virtualization in cloud computing has been used in combination with Platform-as-a-Service (PaaS) and Infrastructure-as-a-Service (IaaS) environments to provision performance, isolation, and scalability. However, containers and virtual machines (VMs) are susceptible to vulnerabilities present in the operating system core, as well as container solutions, which are a risk to the operation of information and services of all entities sharing the same host. Recommendation guides help mitigate security in this scenario, but selecting containerization solutions, taking security requirements into account, is a complex task. Therefore, this work presents a proposal for a security taxonomy focused on containers for cloud computing, with the aim of helping to classify and evaluate security mechanisms and solutions for containers.;Security, Container, Taxonomy;en_US;Declined;0;2018;2018-08-25 15:24:31
86244;Alexandra Katiuska Ramos   Diaz;Universidade de São Paulo;Coagrupamento e biagrupamento: conceitos, algoritmos e viabilidade para mineração de texto - Parte I;Cogrouping and biagrouping are data analysis tasks that allow the extraction of relevant information by applying similarity criteria simultaneously to the rows and columns of data matrices. In reality, these criteria can be seen as ways of analyzing partial similarities between objects (data). Algorithms used to solve these tasks simultaneously group objects and attributes, enabling the creation of cogroups or bigroups. Although similar, the tasks of cogrouping and bigrouping have different natures and objectives, and  cogrouping can be seen as a generalization of bigrouping. Understanding the characteristics of each task and the algorithms related to them is important to provide efficient use of them in real-world problems, especially when these problems have characteristics that make it difficult to determine the parameters of the algorithms. For example, to solve cogrouping or bigrouping problems in textual data (text mining) it is necessary to use a text representation in a vector space model which commonly leads to the generation of vector spaces characterized by high dimensionality and sparsity, affecting the performance of many of the algorithms. This tutorial aims to present, in a didactic way, the concepts relating to cogrouping and bigrouping tasks, the way in which these concepts are approached in a basic algorithm for each task, and experimentation in high-dimensional and high-sparse data contexts, generated synthetically and also represented by a corpus of news. This tutorial discusses both tasks within the same data contexts, which makes it easier to understand the differences between them. The tutorial is divided into two parts, with this text referring to the first part, which highlights the task of cogrouping.;Cogrouping, Bigrouping, Text mining;en_US;Declined;0;2018;2018-08-28 10:51:20
86362;Tiago do Carmo   Nogueira;Instituto Federal Baiano;Systematic Review of Visually-Impaired and Blind User Experience of Web Trends;For visually impaired people, interaction with the Web can be a challenging task this is due to poor accessibility, usability, and User eXperience (UX) of websites. Therefore, it is necessary to conduct a thorough investigation on the UX of websites, especially considering new trends on the Web. In this study, we identified, classified, and analyzed 34,906 scientific papers published in the last eight years to show the originality and relevance of investigating the UX of visually impaired and blind users. We considered new Web trends, focusing on Flat Design and Responsive Web Design. We performed a systematic review and selected 1 015 scientific papers that addressed the importance of UX or other issues relevant to UX. In this literature, we found only five articles addressing issues faced by blind or visually impaired users. None of the studies compared the experiences of users who are blind or visually impaired with those of sighted users. Considering the lack of scientific studies that address the impact of new web trends on UX and studies that examine the importance of UX, we concluded that it is original and relevant to investigate the UX of visually impaired, blind, and sighted users on the Web. From our research, it was possible to identify recurrent subjects of research relevant to UX among them were UX methods applied to mobile, Approach to Agile UX, Usability techniques UX, and Centered Design to User.;Web Acessibility, Usability, User Experience, Blind User;en_US;Declined;0;2018;2018-09-03 18:09:41
86458;Tiago Carmo   Nogueira;Instituto Federal Baiano;Impact of Accessibility and Usability Barriers on the Emotions of Blind Users in Responsive Web Design;With the emergence of new web design trends, as the Responsive Web design, new problems concerning users experience emerges, such as the importance of investigating the impact of these new web trends on blind user’s experience. Thus, this work identifies and ranks the emotional impact and barriers faced by blind and sighted users experience when interacting with responsive and non-responsive web designs. Six websites were selected, three responsive and three non-responsive. The users performed six tasks in each website. To understand the emotional responses of blind and sighted users, we used the Affect Grid Method to classify user’s emotions during interactions. We also applied statistical tests during data analysis. The results show that non-responsive websites presented a higher percentage of pleasant emotions and high excitement when compared to responsive ones. We also found evidence that barriers faced by users during interactions that impacted on the emotions of users have been triggered by non-compliance to WCAG guidelines.;;en_US;Declined;0;2018;2018-09-05 16:16:29
86616;Igor Rosberg de Medeiros   Silva;Universidade Federal do Rio Grande do Norte;BO-MAHM: A Multi-agent Architecture for Hybridization of Metaheuristics for Bi-objective Optimization;Several researches have pointed the hybridization of metaheuristics as an effective way to deal with combinatorial optimization problems. Hybridization allows the combination of different techniques, exploiting the strengths and compensating the weakness of each of them. MAHM is a promising adaptive framework for hybridization of metaheuristics, originally designed for single objective problems. This framework is based on the concepts of Multiagent Systems and Particle Swarm Optimization. In this study we propose an extension of MAHM to the bi-objective scenario. The proposed framework is called BO-MAHM. To adapt MAHM to the bi-objective context, we redefine some concepts such as particle position and velocity. In this study the proposed framework is applied to the bi-objective Symmetric Travelling Salesman Problem. Four methods were hybridized: PAES, GRASP, NSGA2 and Anytime-PLS. Experiments with 11 bi-objective instances were performed and the results show that BO-MAHM is able to provide better non-dominated sets in comparison to the ones obtained by algorithms existing in literature as well as hybridized versions of those algorithms proposed in this work.;Optimization, Bi-objetive problems, Hybridization, Metaheuristics, Swarm Intelligence, Intelligent Agents;en_US;Declined;0;2018;2018-09-14 9:25:26
86741;José dos Santos   Machado;Universidade Federal de Sergipe - UFS;FogSys: Sistema para Implementação da Fog Computing para Fornecer StaaS a Dispositivos IoT;This work presents the concept of Fog Computing, its theoretical contextualization, related work and develops the FogSys system with the main objective of simulating, receiving, validating and storing data from IoT devices to be transferred to Cloud Computing, functioning as Fog Computing to provide the StaaS (Storage as a Service) service. The results demonstrated that implementing this service in embedded systems devices can be a good alternative to reduce one of these problems, in this case, data storage, which currently affects IoT devices.;Fog Computing, Cloud Computing, Distributed Computing, IoT, Cloud Integration with IoT, Embedded Systems, StaaS, FogSys;en_US;Declined;0;2018;2018-09-17 18:10:09
86970;José dos Santos   Machado;Universidade Federal de Sergipe - UFS;FogSys: Sistema para Implementação da Fog Computing para Fornecer StaaS a Dispositivos IoT;This work presents the concept of Fog Computing, its theoretical contextualization, related work and develops the FogSys system with the main objective of simulating, receiving, validating and storing data from IoT devices to be transferred to Cloud Computing, functioning as Fog Computing to provide the StaaS (Storage as a Service) service. The results demonstrated that implementing this service in embedded systems devices can be a good alternative to reduce one of these problems, in this case, data storage, which currently affects IoT devices.;Fog Computing, Cloud Computing, Distributed Computing, IoT, Cloud Integration with IoT, Embedded Systems, StaaS, FogSys;en_US;Declined;0;2018;2018-09-26 10:39:32
87081;Alexandra Katiuska Ramos   Diaz;Universidade de São Paulo;Coagrupamento e biagrupamento: conceitos, algoritmos e viabilidade para mineração de texto - Parte II;Cogrouping and biagrouping are data analysis tasks that allow the extraction of relevant information by applying similarity criteria simultaneously to the rows and columns of data matrices. More specifically, these criteria can be seen as ways of analyzing partial similarities between objects (data). Algorithms used to solve these tasks simultaneously group objects and attributes, enabling the creation of cogroups or bigroups. The first part of this tutorial dealt with the basic differences between the two tasks (cogrouping and bigrouping) and presented in detail a basic algorithm for solving the cogrouping task (NBVD - Non-Negative Block Decomposition). Cogrouping can be understood as a task that generalizes the objectives of the bigrouping task. Still in the first part, aspects of solving the cogrouping task in high-dimensional and high-sparse problems were treated, in a didactic manner, more specifically, using the context of text mining. The tutorial is divided into two parts, and this text, referring to the second part, aims to discuss, in detail and in a didactic way, the basic algorithm of Cheng and Church, which was specially designed to solve the bigrouping task . The algorithm is presented in detail and several experiments illustrating the role of the algorithm's parameters and its sensitivity to high-dimensional and sparse data are discussed. The synthetic and real datasets (the news corpus) used in the first part of the tutorial are also used here. In general and in comparative terms, the results obtained indicate that the cogrouping algorithm is more suitable for the experimental context used. Although the use of Cheng and Church's bigrouping algorithm presented results of lower relevance in the context of textual data than those obtained with NBVD, its application to high-dimensional and sparse data provided a useful study environment for understanding how it works. of the algorithm.;Cogrouping, Bigrouping, Text Mining;en_US;Declined;0;2018;2018-09-30 19:09:40
87196;Tiago Francisco Andrade   Diocesano;Universidade do Estado de Santa Catarina - UDESC;Infância Segura: Um Jogo Sério Colaborativo para a Prevenção do Abuso Sexual Infantil;Child sexual abuse is a global public health problem due to its high prevalence, as well as the psychological and social damage caused to victims and their families. In response to this problem, programs to prevent child sexual violence have been developed. In this work, a strategy is defined to support the teacher to act as coordinator in a collaborative game to prevent child sexual violence. The game developed, entitled Safe Childhood, is based on the 3C Model of collaboration, enabling communication, cooperation and emphasizing teacher coordination. The results indicate that the game allows the teacher to act as coordinator in the prevention of child sexual violence. The game also allows the coordinator to observe, being able to analyze any signs of violence manifested by the child both through interaction with the game and through natural manifestations.;;en_US;Declined;0;2018;2018-10-04 18:12:34
87309;Dalton Cézane Gomes   Valadares;Instituto Federal de Pernambuco (IFPE)Universidade Federal de Campina Grande (UFCG);Avaliação de Desempenho de uma Rede IEEE 802.11g em Ambiente Industrial;In the industrial context, wireless networks are commonly more recommended, as they have low implementation costs, greater flexibility and are less invasive to the environment. In the literature, little emphasis is given to traditional 802.11a/b/g for this type of environment. In this work, the performance of an 802.11g network in a thermoelectric plant was evaluated. Three metrics were considered: packet loss rate, throughput and response time. Tests were carried out with communication between points in the engine room and a point in the administration room. The network performance did not suffer significant degradation, even with electromagnetic interference and other characteristics intrinsic to the study environment.;802.11g Networks, Wireless Networks, Industrial Environment, Performance Assessment;en_US;Declined;0;2018;2018-10-10 1:14:43
87334;Diego Vieira   Neves;Universidade de São Paulo Escola de Artes, Ciências e Humanidades Comissão de Pós-graduação Bacharelado em Sistemas de Informação;Use machine learning to analysis reliability of specialized data for public transport obtained with crowdsourcing;Researchers from different areas are studying the development of what we call Smart Cities: integrating Information and Communication Systems with technologies Internet of Things to use the resources of a city more intelligently. One objectives of smart city initiatives is to solve problems related to the quality of public transport services. To address these problems, such initiatives propose the use of several distributed systems (for example, Intelligent Transport Systems) to collect data on public transport. Theoretically, the use of this data allows the creation of new approaches that help improve the management and quality of the services provided. However, various factors contribute to insufficient or low quality data for real-time use. In this work, we investigated the use of data obtained through crowdsourcing as a complement to this information. To assuage the uncertainties introduced by use crowdsourcing, this study proposes the use of machine learning algorithms to create a reliability analysis model of the specialized data collected for the public transportation system (modal bus) of the city from São Paulo. This research also presents a comparative analysis of the algorithms used, as the objective of identifying the algorithm that presents the best performance in terms of efficiency and effectiveness.;Crowdsourcing, Machine learning, Intelligent transport systems, Smart cities;en_US;Declined;0;2018;2018-10-10 23:04:24
87427;Gustavo Simões   Carnivali;Laboratório Nacional de Computação Científica;Accelerating an Operator Set Through Fourier Transform;The manipulation, processing and visualization of large data sets is a current need. Processing large data can become a slow task or its storage can be complex for existing technology. This article proposes a way to accelerate mathematical operations, generating little loss for the result found, by performing symmetric operations in a domain different from the original data domain. To this end, the work presents a transformation suitable for the objective of the work and a set of nine operators that could compose complete algorithms and that can be carried out in the new domain. The work also analyzes the complexity and loss of quality generated by the acceleration of these operators using the presented method, allowing the safe use of these operators in different contexts.;;en_US;Declined;0;2018;2018-10-15 20:37:45
87458;Cícera Brena   dos Santos Macêdo;;Teste de invasão em uma aplicação web do Instituto Federal do Sertão Pernambucano;Web applications have become one of the main ways of exchanging information between companies and users. With the increasing development of applications, attacks have also increased. Companies see Penetration Testing as a new alternative to protect their applications from attacks. Penetration tests are simulations carried out against systems with the purpose of mitigating vulnerabilities. A public body that has been suffering from attacks is the Federal Institute of Sertão Pernambucano, which suffered around 4,746 attacks in the 2nd quarter of 2018, and in response is investing in Invasion Testing. This article presents a vulnerability analysis carried out through Penetration Testing on a web application from the Instituto Federal do Sertão Pernambucano with the aim of verifying and validating the presence of flaws that could put the application at risk. The vulnerabilities tested in this article are part of the OWASP project, which aims to provide guidance to developers on safe programming practices. The OWASP ZAP and Burp Suite tools were used in the test, identifying a total of 509 flaws, of which 456 are high risk and 59 are medium risk. The test results present a worrying scenario regarding the security of the tested application.;Web applications, Penetration Testing, Instituto Federal do Sertã o Pernambucano, OWASP;en_US;Declined;0;2018;2018-10-16 0:35:41
87667;Danilo   Silva;Universidade Federal de Sergipe;Mapeamento Sistemático sobre Gerenciamento de  Recursos em Ambiente Fog Computing;This work investigates the Fog Computing paradigm as an alternative to the centralized cloud environment for latency-sensitive IoT applications, presents its concept, characteristics and the taxonomy of its applications. In this paper, the systematic literature mapping method is used to find gaps and future directions related to resource management in a Fog Computing environment. The mapping identified seven main challenges for Fog Computing. The findings of this research work can help practitioners and researchers understand the operational context of Fog Computing resource management, for IoT applications and provides a series of useful information for future research work and development in the academic environment.;Fog Computing, Cloud Computing, Resource Management, IoT, Distributed Computing, Systemmatic Mapping;en_US;Declined;0;2018;2018-10-24 20:48:30
87670;Danilo   Silva;Universidade Federal de Sergipe;Uma Estratégia Autonômica para Alocação de Recursos em Ambientes Fog Computing;In recent years, the number of smart devices (e.g. smartphones, sensors, autonomous vehicles) has grown exponentially. In this scenario, the computational demand of latency-sensitive applications in domains such as IoT, Industry 4.0 and smart cities has grown and the traditional cloud computing model is no longer capable of meeting all the needs of this type of application alone. In this direction, a new computing paradigm called Fog Computing was introduced. This paradigm defines the architecture that extends computing capacity and storage from the cloud to the edge of the network. However, many challenges need to be overcome, especially with regard to issues such as security, energy consumption, high latency in communication with critical IoT applications, and the need for quality of service (QoS). Unlike other works that present solutions to resource allocation problems in an environment integrating the Internet of Things and Fog Computing, our work emphasizes optimizing performance and energy consumption through an autonomic architecture based on the MAPE-K control loop. Furthermore, the ongoing work also presents and discusses resource allocation policies with different strategies, lists challenges that can improve resource management capabilities in the context of IoT, and provides a basis for the analysis and design of optimization architectures for support IoT applications. Finally, we present a list of promising general research directions for future work.;Fog  Computing, Cloud  Computing, Resource  Management, Autonomic, Distributed Computing, IoT;en_US;Declined;0;2018;2018-10-24 22:42:00
87892;Carla Diacui Medeiros   Berkenbrock;UDESC;Visualization and Filtering Awareness Information in a Mobile Collaborative Game;This paper presents a cycle of action research conducted to investigate the adoption of visualization and filtering awareness information techniques in a mobile collaborative game. Furthermore, this study aims to identify how, when and where awareness information should be presented to the users as well as how to arrange these information on mobile devices. Due to mobile devices constraints, awareness information is presented in a game using a context-based filtering approach. The evaluation was conduced using a set of 24 requirements and 23 usability metrics for mobile collaborative systems. The results demonstrated that through the techniques adopted, the awareness information was well absorbed by users and the collaborative features were provided through the interface.;Awareness visualization, Awareness filtering, Mobile collaborative systems, CSCW;en_US;Declined;0;2018;2018-11-01 16:45:41
88118;José dos Santos   Machado;Instituto Federal de Sergipe - IFS;Um Estudo dos Algoritmos de Criptografia Leve Baseado em Internet das Coisas (IoT);IoT devices are increasingly present in various areas of human activities, collecting, processing, storing and sharing sensitive information about their users. However, due to the reduced physical dimensions and limited computational resources of these devices, implementing traditional algorithms to provide security becomes a challenging task. To overcome this limitation, lightweight encryption algorithms have been proposed. These types of algorithms are adapted for implementation  in  constrained  environments,  including  RFID tags, sensors, smart cards, healthcare devices, etc. Studies on implementing security solutions in a limited hardware environment were carried out with well-known cryptographic algorithms. However, there are numerous encryption ciphers in the literature with varying specifications and if the choice of an encryption algorithm is not appropriate, this can directly affect factors determining the functioning of the device, such as battery life, hardware memory , computational latency and data communication bandwidth. In this context, this work aims to compare lightweight encryption algorithms cited in recent literature for resource-limited devices and present future directions for research work.;Cryptography, Lightweight Ciphers, Resource Limited Devices, Internet of Things;en_US;Declined;0;2018;2018-11-13 10:12:41
88141;Carla Diacui Medeiros   Berkenbrock;UDESC;Uma Abordagem Colaborativa para Aprendizagem de Programação de Computadores com a Utilização de Dispositivos Móveis;In Computing courses, students have learning difficulties in subjects involving programming, which leads to a high rate of failure and dropout in these subjects. Thus, this research presents a collaborative learning approach, which we call Collaborative Session Cycle, with the aim of contributing to the reduction of learning difficulties. In this approach, students work using different strategies: individual work followed by group work, or directly in a group in order to exchange experiences and learn Object Oriented Programming (OOP). The approach is based on the flipped classroom concept and the practice of collaborative learning. To support the use of the defined approach, an application was developed that implements a set of 15 requirements related to collaboration, learning, as well as technical requirements of implementation on mobile devices. The application was developed to run on smartphones and tablets and allows the use of three types of activities, which are: multiple choice questions, open-ended problems and an algorithm puzzle (Parson's Problem). To evaluate the approach and the application developed, a case study was carried out. The results achieved indicate the potential of the approach to support student learning and consequently reduce failure rates.;;en_US;Declined;0;2018;2018-11-14 13:56:06
88258;José Erico Gomes   da Silva;Universidade do Estado do Rio Grande do Norte - UERN;SOS SOCORRISTA: SISTEMA PARA AUXILIAR EQUIPE MÉDICA NA TOMADA DE DECISÃO DE EMERGÊNCIA;Overcrowding in Hospital Emergency Services is a constant problem that plagues public health in Brazil, with regard to humanized patient care in emergencies. An intelligent monitoring, monitoring and decision-making assistance system was developed, called SOS Socorrista, to facilitate the management, communication and response to urgent and emergency incidents received by the Mobile Emergency Care Service (SAMU). The system has adaptive questionnaires that are filled out by those on duty, with information on emergency incidents. To assist professionals in decision-making in an emergency, a domain ontology was modeled and implemented that determines the most appropriate emergency support. The specified ontology was tested and its results were compared with those of three emergency doctors, through a case study. The system presented satisfactory performance, aiding decision making with an accuracy rate of 90%. SOS Socorrista was developed and tested, a decision-making support system for emergency medical teams, which proved to be a viable method as a proposal for reducing errors and improving effectiveness and reliability in the process of responding to medical emergencies.;Ontology, Medical Emergency Service, E-Health, System.;en_US;Declined;0;2018;2018-11-18 23:21:47
88381;Guilherme Ramos   Casimiro;Universidade de São Paulo;Atribuição de Autoria utilizando os dados do fórum Reddit;With social networks increasingly becoming part of people's daily lives, analyzes of the content posted on these media to avoid the circulation of news with dubious content or authorship become necessary. The present work analyzes comments from a community on the Reddit forum, in order to evaluate different representations of the text and using classification techniques in artificial intelligence to attribute authorship in the context of forum-style social networks. The results showed that for each scenario a given combination of classifier and selected features (different representations) is most recommended and presents good efficiency in distinguishing between authors.;Authorship Attribution, classifier, Reddit, n-grams;en_US;Declined;0;2018;2018-11-23 18:32:09
88414;Felipe Bertelli   Levez;Instituto Federal de Educação, Ciência e Tecnologia de São Paulo (IFSP);A comparison of sorting algorithms;This article discusses a comparative analysis of several sorting algorithms. Throughout the work, allalgorithms are developed in textit Python. The methodology consists in analyzing the efficiency of such in threesituations, applied in vectors of size 10, 100, 1000 and 50.000, in the ascending, decreasing and random orders.Subsequently, three algorithms were selected based on their execution time for a second analysis, using thesame situations but applied to vectors of 1,000,000 positions. Several graphs and tables were generated toillustrate the performance obtained during the tests.They explain the differences of the codes, highlighting themost appropriate use for each scenario and need.;;en_US;Declined;0;2018;2018-11-25 18:14:36
88463;Murilo Machado   Pagliuso;Fundação Educacional de Fernandópolis;Real-Time Applications With WebSocket And Node.JS;The WebSocket technology is a protocol based on HTTP that allows the interaction between client and server in real time, because it’s based on HTTP, it has the same feature of opening a connection, sending requests and closing the connection, but with the difference that the connection is kept open until the moment that the user closes the browser window, or until the own system redirect to another page, where the connection is open again. This article has the objective of developing a system that shows how WebSocket allied with Node.JS can help in the development of applications, providing exchange of information between client and server in real time, ensuring integrity and security. WebSocket can be implemented in multiple languages as JavaScript, Java and PHP, but in this article it was implemented in the Node.JS platform. To demonstrate the operation of the protocol, a web application was developed that it’s about an online chat where a user enters the chat and can send messages to the other present users, that communication is done in real time through the protocol. For the development of the application, it was used third-party dependencies as Express, Socket.IO which is the WebSocket implementation in JavaScript, and Nodemon. In the future, this technology may help in the communication of web applications in multiple areas such as health, education, business and industrial.;WebSocket, Programming, Real-Time, Communication Protocol, Node.JS;en_US;Declined;0;2018;2018-11-27 14:47:17
88464;Igor Carlos Piva   Piva;FEF - Fundação Educacional de Fernandópolis;USO DE TECNOLOGIA WEBSOCKETS PARA SOFTWARES DE AGENDAMENTO;This article proposes a new way of creating software using a completely innovative technology for real-time updates, avoiding data duplication problems. To achieve this objective, software was created using websockets where it presents how this platform works in practice. As a result, this technology made it possible for this platform to function correctly, which has become very useful. This article resulted in a study on this little-known platform, which can be used by the entire community to expand their knowledge about it, as well as opening the doors to new research and more results.;;en_US;Declined;0;2018;2018-11-27 15:04:26
88468;BRUNO FERNANDO SILVA   MENDONCA;FUNDAÇÃO EDUCACIONAL DE FERNANDOPOLIS;APLICATIVO QUE RECONHECE E SINTETIZA CARACTERES DE UMA IMAGEM EM SOM;The search for accessibility in virtual environments is already very advanced, on the market it is possible to find different types of screen readers and speech synthesizers for the visually impaired, however when the subject refers to non-virtual environments there is a great lack of software that help people with disabilities in their daily lives. This article aims to create an application for the Android platform with the aim of promoting accessibility for the visually impaired, through OCR and speech synthesis technologies. To this end, in addition to research on accessibility standards, tests were carried out with people with partial and total vision impairment. As a result, it was found that the application can greatly assist in reading everyday texts, thus bringing greater inclusion to these people.;Accessibility. Visually Impaired. Optical Character Recognition. Voice Synthesizer.;en_US;Declined;0;2018;2018-11-27 16:41:40
88469;BRUNO FERNANDO SILVA   MENDONCA;FUNDAÇÃO EDUCACIONAL DE FERNANDÓPOLIS;APPLICATION THAT RECOGNIZES AND SYNTHESIZES CHARACTERES OF AN IMAGE IN SOUND;The search for accessibility in virtual environments is already very advanced, in the market it is possible to find several types of screen readers and voice synthesizers for the visually impaired,oem when it comes to non-virtual environments there is a great lack of software that helps the disabled in their daily lives. This article aims to create an application for the Android platform with the purpose of promoting the accessibility of the visually impaired, through OCR technologies and voice synthesis. Therefore, in addition to research on standards of accessibility, tests were performed with people with partial and total vision impairment. As a result, it has been found that the application can be very useful in reading texts from day to day, in this way bringing greater inclusion to these people;Accessibility. Visually impaired. Optical Character Recognition. Synthesizer of Voice.;en_US;Declined;0;2018;2018-11-27 16:46:15
88471;EDUARDO Ferlete   FERLETE;FEF;COMPARAÇÃO ENTRE OS MODELOS MD5 E SHA-256 DE CRIPTOGRAFIA HASH;With the advancement of technology, a need arises to increase data security through digital media. Security data protection methods become obsolete each year and require new forms and structures that ensure greater security for the latest applications. This article has the object of the scorcal forms in the digital security and in the security security in the security security. The job is a high technology of the present, it is to verify the vulnerabilities related to the degree of protection of these already, demonstring the advantages and the disadvantages of each the best examples of application. Comparing the best result for the creation and completion of the project to the type of technology selected.;;en_US;Declined;0;2018;2018-11-27 16:58:57
88472;Giovanni Ximenez   dos Santos;Fundação Educacional de Fernandópolis-SP (FEF).;HOLOPHONE: DISPOSITIVO MÓVEL HOLOGRÁFICO;HOLOPHONE: HOLOGRAPHIC MOBILE DEVICE;;en_US;Declined;0;2018;2018-11-27 17:07:40
88473;Gustavo Ferreira   Almeida;FUNDAÇÃO EDUCACIONAL DE FERNANDÓPOLIS - FEF;THE USE OF GAMIFICATION IN THE AID OF THE LEARNING PROCESS OF MATHEMTICS IN ELEMENTARY SCHOOL WITH UNITY;With the great advancement of technology, especially in the area of ​​education, there is still a certain withdrawal from learning processes that end up outdated and blocked in old methodologies. The general objective of this article is to develop a playful way with intuitive illustrations in conjunction with technology to assist in the mathematics learning process in Elementary School. With the ease of technology nowadays, using gamification methods, it is possible to advance a few years ahead of this old teaching methodology, aiming to keep up with technological evolution, adapting schools for the future, applying technology to help teachers manage their tasks. classes using gamification, which have methods used in electronic games to induce good behavior in the students involved. The project was developed using the Unity graphics engine, which has several tools for creating the game, such as animations and programming, as well as specific software for defining the visual part. The game was used at the municipal school of Meridiano - SP, EMEF. Prof. Paula Zangrando, has tablets for students so they can expand the learning environment.;Educational, Elementary, Unity, Mathematics, Programming.;en_US;Declined;0;2018;2018-11-27 17:43:44
88501;GUSTAVO FAMEA   PEREIRA;Fundação Educacional de Fernandópolis;A Importância da Segurança de Dados na Integridade Empresarial;Information technology (IT) has been increasingly present in the area of ​​business security, as businesses are changing, and today, practically all of them are managed by a computer system. Therefore, this work aims to present some of the most frequent attacks used by crackers and their fateful consequences. Also relying on forms of defense to maintain the three pillars of information security: reliability, integrity and availability through audits, ISO standards and laws created specifically for this area. Finally, detailing the performance of a scan and the creation of a backdoor on the internal network, making all the files on the target machine available to the attacker.;Security, Confidentiality, Integrity, Availability, Infrastructure, Critical attacks, Forms of defense.;en_US;Declined;0;2018;2018-11-28 13:04:59
88523;Paulo Henrique de Oliveira   Fachin;Fundação Educacional de Fernandópolis;VIRTUAL CRIMES AND ANONIMATE ON NETWORKS: IDENTIFICATION AND REGISTRATION METHOD;This article shows how the rate of virtual crimes has increased in recent years, mainly due to computerization and the universalization of Internet access. It also explains how the identification of users univocal Internet users was lost long ago, shortly after the exhaustion of addresses in version 4. It also indicates how the adhesion to the IP address in version 6 is still low, and as a consequence preserves the internet in the version 4. The method used here encourages and guides the creation of a means to record the activities of users on the Internet in compliance with the parameters defined by the legislation. It is necessary to identify the time of use and online activities performed by users, in the case of attending to judicial requests.;Virtual Crimes, CGNAT Routing, User Identification, Connection Logging, IPv4 Depletion;en_US;Declined;0;2018;2018-11-28 21:08:19
88533;Hugo Leonardo Nascimento   Almeida;ISI-TICsCesar School;Case Study CUG BIM: better deliveries to the end user in software projects with the use of a model of usability tests;The Project CUG BIM, developed by the Institute Senai of Innovation for Information and Communication Technologies, has been interfered with from the point of view of process and has become an essential case study for this research. The focus of this research was the way the project was tested on point of view of usability resulted in considerable benefits for the team of participating developers and the client. It was possible to extract data that prove the positive results of the use of the model of usability tests used after the process of development of the proposed project. All stakeholders involved in the CUG BIM project obtained advantages related to their area of action with the actions performed and reported by this work, and all these actions together form an specialy adapted model to this project. The proposal was based on scientific concepts well defined and diffused in academy and industry.;Human-Centered Design, Software tests, Usability tests;en_US;Declined;0;2018;2018-11-29 11:46:02
88549;Joao Vitor Costa   Oliveira;Fundação Educacional de Fernandópolis;USO DE RFID E ARDUINO PARA GERENCIAMENTO DE GADO EM CONFINAMENTO;This article discusses the use of RFID and Arduino to improve livestock confinement on farms. This article aims to propose the implantation of an RFID microchip in cattle containing their respective registered number and antennas for reading the chip in an area delimited by the owner, to automate the weighing of the same and alert the animal to leave the demarcated area. After interviewing employees and owners of local ranches and farms, a delay and failures in controlling the animal's weight were found, in addition to research showing a high rate of cattle theft in the country. Based on the studies carried out, it was possible to create a prototype to demonstrate the proposed operation. Through RFID technology implanted in cattle and Arduino to assist in reading and communicating with computers, it will be possible, once applied, to optimize and bring dynamics to the confinement process, in addition to correcting possible flaws in controlling the animal's weight.;, RFID, Arduino, Animal Management, Cattle Confinement;en_US;Declined;0;2018;2018-11-29 20:49:52
88626;João Vitor Simão   Reynaldo;Fundação Educacional de Fernandópolis;Uso da Realidade no Tratamento de Traumas e Fobias;Using the virtual reality in the treatment of traumas and phobias, by means of immersion in the cozy environments, with the treatment of the possible possible or means of audition and probe of the patients of human patients for the real possible. The objective is to update the ways of treating traumas and phobias with virtual reality. A phobia is nothing more than a great increase in anxiety that generates uncontrollable fear, the tremors are not a body, the acceleration of the heartbeat causing greater discomfort, the trauma is also a little similar, but is, in general, caused by some agent external as an accident. The treatment with the function of placing the patient with phobic disorders in environments that are very similar to the real ones, it has no effect, so that it can reduce their phobic levels throughout sections. According to the articles reviewed, it can be seen that the results demonstrate improvements in anxiety levels, and patients are more suitable for a new form of treatment. The may be not worth the value for the real virtual domain, which may be important and the processing the virtual them in the same the current them are in the real estate there are some as described are realways.;Virtual Reality, Augmented Reality, Treatment, Trauma and Phobias, Visualization and Interaction Devices.;en_US;Declined;0;2018;2018-12-03 19:41:19
88667;Beatriz Panko   Lira;Instituto Federal Catarinense - Blumenau;Artificial Intelligence Tendencies: Opportunities and Threats;The human being is progressing more and more in technology area, expanding your trends for all sides. With the Artificial Intelligence it doesn't have been different: in the year 2018, was the year of most progress and expansion for have receive a lot of investment facing to researches and innovations that will change the future's direction. There are positive questions to be considerate that will advance the humanity evolution, influencing psychology, medicine, jobs and even cultural areas. Seen this way, is possible to imagine that the changes future's will be great from a miracle way, in order to satisfies a common good. From another perspective, is a technology that needs a lot of study and careful because has a broad comprehensive power. The preparing and application of this technology needs to be very structured, with the aim of avoid possible disasters that cause a lot of scare in society for make great consequences that won't be undid. This thought needs to be deconstructed from a basement in a analysis made among the opportunities and threats that Artificial Intelligence will provide to the future.;Artificial Intelligence --- Technology --- Human Being --- Machine;en_US;Declined;0;2018;2018-12-04 22:23:54
88673;Luan Trovo   Furtile;Faculdades Integradas de Fernandópolis;DESENVOLVIMENTO DE SISTEMA DE GERENCIAMENTO DE CONTEÚDO WEB (SGC);The content management system can be created worldwide, it is an online system, where the user creates, edits and manages publications, pages or a website. In the literature review, it was possible to survey the advantages and disadvantages of the technologies most used to develop the system. This article is under development for the SGC (Content Management System), which must be practical and intuitive, based on a company proposal such as this edition of the article. Several technologies were developed, such as HTML, CSS and JS for layout development, PHP as a programming language and MySQL database. The result was a modular system that can be suitable for each specific model of each business and project. user control with permissions for each module and logs of actions performed within the system. The idea was to develop a CMS that is simpler to use than the query systems that exist on the current market, so that any type of user with great knowledge of computing can use it.;Web, CMS, SGC, Content Management, Website, HTML, PHP, MySQL.;en_US;Declined;0;2018;2018-12-04 23:59:59
88678;Gustavo Ferreira   Almeida;FUNDAÇÃO EDUCACIONAL DE FERNANDÓPOLIS - FEF;THE USE OF GAMIFICATION IN THE AID OF THE LEARNING PROCESS OF MATHEMTICS IN ELEMENTARY SCHOOL WITH UNITY;With the great advance of technology, especially in the area of education, there is still a certain withdrawal from the learning processes that ends up being out of date and blocked in the old methodologies. The overall goal of this article is to develop a playful way with intuitive illustrations in conjunction with technology to assist in the process of learning math in Elementary School. With the ease of technology nowadays, using gamification methods, it is possible to advance a few years ahead of this old methodology of teaching, aiming to follow the technological evolution, adapting the schools for the future, applying the technology to help the teacher to administer their classes with the use of gamification, which have methods used in electronic games to induce good behaviors in the students involved. The development of the project was produced in the graphic engine Unity, which have several tools for the creation of games. A research was carried out with 25 students, to obtain data about the experience they had.;Educational, Elementary, Unity, Mathematics, Programming.;en_US;Declined;0;2018;2018-12-05 15:33:33
88680;Anderson Tiago   Poato;;MONITORAMENTO EM TEMPO REAL DE SISTEMAS DE REFRIGERAÇÃO;: With the growth of technology, several processes that were previously done manually have become automated. This article aims to develop a system, where the refrigeration system for groceries or products can be monitored in real time, being installed in one or more equipment, with the help of an online database system, for storing this information and keeping them available in real time, thus providing a more precise monitoring method in order to avoid failures or even loss of equipment and product, also enabling the equipment to be monitored with the help of a simple smartphone with an Android system or even being integrated with another management system.;Refrigeration System, Automation, Real Time, Firebase, ESP8266, Wireless.;en_US;Declined;0;2018;2018-12-05 15:59:16
88682;Bruno Antoniassi   Canassa;Fundação Educacional de Fernandópolis;CONFSYS: SOFTWARE PARA CONTROLE DE CONFINAMENTO DE GADO;The search for software in the agricultural sector is great and is necessary for greater control over what is done, what is spent and the final profit. The existence of a large volume of data to collect, process, store, retrieve and distribute requires a transformation of manual information systems into electronic systems, aiming for better organizational results. The objective of this article is to understand the main need for confinements, in order to develop software, finding the best one to be developed, bringing accurate and correct information for the purpose that the manager needs, bringing more security in decision making and increasing profits. . The article relates the development of software for data management in cattle confinement, from its initial structure, using object-oriented programming (OOP), and the MVC model (Visual Control Model). The users involved in the tests demonstrated enthusiasm and lack of basic knowledge, immediately showing that adjustments will have to be made, thus showing that a specific, exclusive software is the best way among the problems encountered are the lack of infrastructure, bringing unforeseen changes and expenses. The software developed helps producers and their employees monitor their cattle accurately and quickly, especially when making decisions.;Livestock Management, Information Technology in Agriculture, JSP.;en_US;Declined;0;2018;2018-12-05 16:45:17
88712;Elias Augusto   Fank;Federal University of Fronteira Sul;INSIDe: Image recognition tool aimed at helping visually impaired people contextualize indoor environments;Visually impaired (VI) people face a set of challenges when trying to orient and contextualize themselves. Computer vision and mobile devices can be valuable tools to help them improve their quality of life. This work presents a tool based on computer vision and image recognition to assist VI people to better contextualize themselves indoors. The tool works as follows: user takes a picture r using a mobile application r is sent to the server r is compared to a database of previously taken pictures server returns metadata of the database image that is most similar to r finally the mobile application gives an audio feedback based on the received metadata. Similarity test among database images and r is based on the search of nearest neighbors in key points extracted from the images by SIFT descriptors. Three experiments are presented to support the feasibility of the tool. We believe our solution is a low cost, convenient approach that can leverage existing IT infrastructure, e.g. wireless networks, and does not require any physical adaptation in the environment where it will be used.;Visually impaired, mobile, computer vision, SIFT;en_US;Declined;0;2018;2018-12-06 18:07:42
88716;Josemar Antonio   Silva;FUNDAÇÃO EDUCACIONAL DE FERNANDÓPOLIS;JOGOS DIGITAIS COMO AUXÍLIO NO PROCESSO DE APRENDIZAGEM E ALFABETIZAÇÃO DE CRIANÇAS NOS ANOS INICIAIS DO ENSINO FUNDAMENTAL I;It is known that digital educational games, when inserted into children's learning as a pedagogical tool, can help in the literacy process and be allies in the construction of knowledge, since technologies are increasingly inserted in school spaces. It is therefore understood that the role of the teacher is to stimulate and manage the learning process. Therefore, teaching through digital educational games is producing knowledge, using a significant tool for learning as a means. In conclusion, it is clear that it is possible to combine the use of technologies with classroom activities, as they are already part of the daily lives of the vast majority of children. It is only necessary to direct the use of these tools to the objective and explore it to enrich knowledge. This research aims to analyze the importance of digital games in early childhood education.;Literacy, Technology, Digital Games, Elementary Education.;en_US;Declined;0;2018;2018-12-06 22:25:15
88718;Luis Guilherme da Silva   Modolo;Fundação Educacional de Fernandópolis;REALIDADE AUMENTADA APLICADA À HISTOLOGIA E HISTOPATOLOGIA;The augmented reality microscope aims to improve teaching concepts focused on cell studies and present a better definition of a project to be shown. This article aims to present the concepts of introducing Augmented Reality in the Histology Laminary. This project will work like a normal microscope, however, its operation will be based on Augmented Reality, however, what will be shown will be on a flat table in the form of real projections, as shown in science fiction films. However, in the projections, as it will be a study on animal cells, whether wild or domestic, it could be more interactive. In addition to studying the cells, it will be possible to demonstrate the cell type and an indicator of the type of disease. However, its objective is to be used by university students, as it is a type of modification of a microscope where it will be possible to interact with objects.;Augmented Reality, Optical Microscope, Histology, Histology Laminar.;en_US;Declined;0;2018;2018-12-06 22:51:18
88721;João Vitor Costa   Oliveira;Faculdades Integradas de FernandópolisFundação Educacional de Fernandópolis;USO DE RFID E ARDUINO PARA GERENCIAMENTO DE GADO EM CONFINAMENTO;This article discusses the use of RFID and Arduino to improve livestock confinement on farms. This article aims to propose the implementation of an RFID tag in the form of an earring, to be placed in the cattle's ears containing their respective registered number and RFID antennas positioned in the confinement corral, where the cattle pass, and the code can be read. earring. After interviewing employees and owners of local ranches and farms, a delay and failures in controlling the animal's weight were found, as well as difficulties in controlling vaccination and identifying the cattle to their respective batch. Based on the studies carried out, it was possible to create a prototype to demonstrate the proposed operation. Through RFID technology implanted in cattle and Arduino to assist in reading and communicating with computers, it will be possible, once applied, to optimize and bring dynamics to the confinement process, in addition to correcting possible flaws in controlling the animal's weight and vaccination.;;en_US;Declined;0;2018;2018-12-06 23:51:33
88747;Sabrina Lorena   Pereira;Faculdade Educacional Fernandopolis;A INFORMÁTICA NA EDUCAÇÃO INFANTIL: INFLUÊNCIAS DAS MÍDIAS;Starting from the context, the work aimed to discuss information technology in early childhood education and its influences. Thus, a literature review was carried out, which sought, through articles and academic journals, to evaluate this premise. An exact period was not established, but emphasis was placed on the most up-to-date and most relevant material.;Learning. Child education. Digital Media.;en_US;Declined;0;2018;2018-12-09 15:39:54
89045;Christiane   Gresse von Wangenheim;INE/UFSC;CodeMaster – Uma Ferramenta para a Avaliação automatizada de programas em App Inventor e Snap!;The teaching of computational thinking in basic education has been considered of great importance. Many of the approaches in this context focus on teaching through programming activities using block-based languages. As with all teaching activities, it is important that students receive instructional feedback. However, in practice, it can be difficult to provide objective, consistent, and personalized feedback. Thus, automated assessment has gained relevance. Although there are several automated evaluation tools for programs in textual languages, support for block-based programming languages ​​is still scarce. This article presents CodeMaster, a free web application that, in a problem-based learning context, allows you to automatically evaluate projects programmed with App Inventor or Snap!. The tool uses a rubric that measures computational thinking through a static analysis of the code. Students can use the tool to get feedback to encourage them to improve their programming skills. The tool can also be used by teachers to assess entire classes, reducing their workload.;Computational thinking --- Programming --- Assessment --- App Inventor --- Snap!;en_US;Declined;0;2018;2018-12-18 9:03:30
89157;Amarildo Jeiele Ferreira   de Lucena;Universidade Federal Rural de Pernambuco;Proposal of Solution for Location-Allocation of Police Vehicles Using a Multi-Period Mathematical Model;Public safety today occupies a prominent position in any discussion in the political, economic and social context of the country, given the state of insecurity that now exists in Brazilian society in the face of increasing urban violence rates. In order to address this problem and considering the scarcity of financial resources, several studies have been proposed to guide the implementation of public security policies, particularly those involving the optimization of resources already available. This work presents a mathematical model of location-allocation of police cars in multi-periods, which allows the managers of the police patrol service a prior analysis of the vehicle allocation scenarios, as well as the costs involved in the displacement of these vehicles to the points of occurrences. Results show that the use of the proposed model can be feasible for the management of resources, since the entry parameters, which include the exact positioning of the candidate points for the allocation of vehicles and the possible locations of police occurrences, can be accurately obtained.;;en_US;Declined;0;2018;2018-12-21 20:02:12
89370;Rafael Alexandre   Piemontez;Universidade do Vale do Itajaí - Univali;RAP3DF - Base de dados 3D de faces;Developing research in the area of ​​3D biometrics requires a large set of 3D images, either for training or evaluating algorithms. Several bases can be found internationally, but these bases do not have the 3 main types of image per sample: infrared, visible light and three-dimensional depth image, in addition to having access restrictions or scope of application. Given the difficulties of finding a 3D database to test a 3D facial recognition system and compare them with two-dimensional imaging techniques, this work sought to create this public database, making the entire imaging acquisition process available. 3D, as well as its visible light image and infrared spectrum, from the Kinect 2 device. The work resulted in 267 samples from 64 volunteers, where each volunteer has a frontal facial image and 3 images in random positions. Enabling the database to be used for 3D facial recognition.;3D Biometrics, 3D face images, Image database;en_US;Declined;0;2019;2019-01-02 15:21:09
89395;Janderson Jason Barbosa   Aguiar;Universidade Federal de Campina Grande;Analyzing the Influence of the Big Five Personality Traits in the Recommendation of Educational Resources;Recent research has considered the use of the theory of Personality Traits to build user profiles in Recommender Systems. This paper presents a study of the influence of the five traits of the Big Five model in the construction of user profiles in Recommender Systems for Learning. Particularly, we analyzed the possibility of using only some traits to simplify this construction, while maintaining accurate personalized recommendations. Although it has not been possible to highlight precisely the traits of the Big Five model with the most significant influence on the recommendation, the results showed that the five traits do not have the same influence, and there are indications that the use of the trait Openness to Experience is sufficient.;;en_US;Declined;0;2019;2019-01-04 11:11:37
89511;Diógenes Ermeson da Silva   Pires;Universidade Federal do Pará;Analysis of requirements of a socioeconomic database;Developing the design of a database requires an intense understanding of business rules and their influences on database infrastructure. In this process, the analysis of requirements is a step that must take into account the mapping of an information system, which in turn, must be well structured for the use of information as an opportunity in corporate environments. However, database management is evolving from a specialized application to the core of a modern computing environment. Thus, when directed to the socioeconomic databases it is very favorable to support the operations that involve the analysis and exploration of projects that directly impact the population close to the enterprise. In this sense, the present study has the objective of describing the implantation of a socioeconomic database of the company Vida ser Planejamento e Gestão Socioambiental LTDA. As a result of the work, the process of building the requirements of a socioeconomic database used enabled the searches and interpretations by the domain developers and specialists.;database, information, requirements. socioeconomic.;en_US;Declined;0;2019;2019-01-10 13:50:18
89912;Alessandra de Fátima Galvão   Rosa;Universidade Tecnologica Federal do Paraná;Systematic Mapping for obtaining SpO2 without physical contact;The objective of this study is to identify the primary studies on obtaining SpO2 without physical contact.To achieve this goal, the technique of systematic mapping was used. This technique consists of searchingscientific databases. To this end, automatic searches and the snowballing technique were carried out in threedigital libraries (ACM Digital Library, ScienceDirect, IEEE Xplore Digital Library) and in the Scopus searchengine. The initial search returned 791 articles, which were filtered, as described in the mapping protocol,resulting in a list of 18 articles for a full reading. With this mapping, we determined that, the first study waspublished in 2005, and many studies address obtaining non-contact photoplethysmographic signals, but fewstudies discussed the obtainment of SpO2, a topic that has been rarely explored.;“Contactless pulse oximetry”, “Systematic mapping sobre SpO2”, iPPG, rPPG;en_US;Declined;0;2019;2019-01-28 20:14:19
89982;Renato de Freitas   Bulcão Neto;Instituto de Informática (INF)Universidade Federal de Goiás (UFG)Campus Goiânia, Goiás;Mitigating common errors in istar-based requirement models: An ontological approach;The istar modeling language represents system’s and organization’s goals and brings several advantages. However, it faces problems regarding the quality of requirement models, which include common mistakes of misuse of istar constructs, the presence of ambiguities on the interpretation of those constructs, and the complexity of the resulting istar models. This work presents an ontology-based approach towards mitigating the most common errors while constructing istar-based requirement models. That approach includes: the OntoiStar-NG ontology with OWL restrictions which reduce frequent errors in istar models and the TAGOOn-NG tool, which automatically transforms iStarML-based models into an error-free OntoiStar-NG instance. Our results demonstrated an approximate coverage of 70% of those common errors in the context of two case studies.;Requirements engineering, istar language, ontology, evaluation;en_US;Declined;0;2019;2019-01-30 11:41:26
90143;Diego Correa   da Silva;Federal University of Bahia;Ouvido Musical: Exploring metadata in a music recomendation system;Music is one of the oldest humanity works. Passed from generation to generation and used in so many sectors and for many purposes. The evolution of digital music made possible, from the 2000s, onwards the emergence of music streaming services, that produced a highly lucrative effect on the music sector. These services use recommendation systems to find tracks that will appeals to users, collecting rich information about them and what they listen to. The obteined volume of data enables a scenario rich in characteristics that describe both, thus making recommendations more reliable. So, is possible to find recommendations in a scenario with scarcity of data? The problem this work aims to solve is the difficulty of recommendations systems have to suggesting new songs for users in front of a scenario with scarcity information, exploring metadata combinations to find recommendations. Throughout this work a theoretical survey will be conducted, as well as a survey of commercial applications, the proposed system, will use similarity between metadatas to find personalized recommendations. The necessary models for development this system are presented and exemplified. The results show it is possible to make recommendations in a scenario with scarcity information. The used metrics to evaluate the system results were Mean Average Precision and Mean Reciprocal Rank. The evaluation showed in an unbalanced environment where only 11\% of songs are considered relevant is possible to obtain, in the metric MAP, approximately 20\% of assertiveness along the recommendations lists, as well as a recommendation list with a larger number of songs helps to obtaining a better result. The evaluation also showed it is possible to obtain more than 35\% assertiveness in the metric MRR, just as the recommendation list with a larger number of songs interferes directly with the positive metric result.;Recommender Systems --- Song --- Music --- Metadata --- Recommendation List --- Content-based Filtering;en_US;Declined;0;2019;2019-02-06 20:42:17
90301;Sidiney Sousa   Araujo;Federal University of Piauí;Model of Cluster Classification based on Labeling and Fuzzy Logic;The techniques of clustering and classification are frequently used to obtain patterns and classify new data. The combination of those techniques can be applied to problems where there is no label, using the clustering process to extract information that will assist the classification process. Usually, the clusters are analyzed by an expert to obtain that information, but this process can also be done by automatic labeling models. Those are models capable of identifying the most relevant characteristics of the clusters and use them to create a label. Based on the automatic labeling models and the classification techniques, this paper proposes a model of classification that uses the clusters labels to compose rules and membership functions of a Fuzzy system. The efficiency of the proposed model was evaluated by comparing the accuracy and standard deviation with other classification algorithms, as well as individually analyzed each rule through the metrics based on the contingency matrix. For different databases available in the UCI repository, the results show that the rules reached precision and specificity rates above 94 \%, with accuracy and standard deviation similar to the algorithms found in the literature.;Machine Learning, Fuzzy, Rules, Labeling;en_US;Declined;0;2019;2019-02-13 17:52:43
90532;Natan   Severo;Instituto federal de educação ciência e tecnologia da paraíba - IFPB;An approach to detect false-design patterns;A false design pattern exists when developers, either inexperienced or lacking the necessary knowledge about design patterns, use software vocabularies to indicate that in a given class there is a design pattern implemented, there is. Occurrences of false design patterns can lead developers to have difficulty understanding, maintaining, and evolving the project. And consequently, the quality of software decreases. Taking these points into account, the paper presents an approach to detect false standards by evaluating and crossing information on vocabulary extraction and detection of design patterns. In this study it was found that the mean value of the metric for classes that implement the Factory Method pattern behaves between the values 0 and 2 and among the more present terms, is the factory. In total, 241 instances / indicatives of false design patterns were identified after analyzing the Axion, Collections, Jext, Xalan and Xerces projects belonging to the Qualitas.class suite.;Design patterns, Software vocabulary, False design patterns, Software quality;en_US;Declined;0;2019;2019-02-25 7:11:31
90536;Anderson   Prante;Universidade do Estado de Santa Catarina;EZClass - The professor as coordinator in a collaborative mobile learning environment;In collaborative learning tools supported by mobile devices, message exchanges are performed by users in order to support the collective construction of knowledge by the members of a group. The entry of activities in the group can provide evidence of how the learning progress occurs. Coordination mechanisms together with learning analytics techniques  can be used in teaching environments, in order to support the teacher in the coordination, allowing him/her to adapt his pedagogical proposals. This work aims to identify the coordination mechanisms for mobile teaching-learning collaborative environments, as well as to apply them to modeling a system (EZClass) with emphasis on teacher coordination in a virtual learning environment (CLinClass). The mechanisms are represented by means of functional requirements and are used in the definition of the EZClass system. The EZClass was designed to assist the teacher in coordinating activities on a virtual learning environment, so that the teacher can make decisions based on the indicators presented, allowing him/her to adapt the pedagogical proposal to better supply the students' demands.;Collaborative systems, Coordination, Learning Analytics, E-learning;en_US;Declined;0;2019;2019-02-25 10:29:42
90569;Joiner dos Santos   Sá;Universidade Federal do Pará;Olha o Ônibus Software: A Collaborative Alternative For Public Transport Users;In this work is presented a software to support urban mobility using mobile devices, called Olha o Onibus. The research analyzed the literature and the mobile Android application market, in order to show the differential of the proposed application. A case study was conducted in the metropolitan region of Belem, where users were able to use the application in real day-to-day situations. The software has been evaluated for the number of installations, the average acceptance of Google Play users, the number of hours of use of the application, and the efficiency of presenting accurate information. The obtained results showed high rates of acceptance, demand and use, and highlight the potential of the tool to present accurate geolocation information of buses.;Android, software, buses, urban mobility;en_US;Declined;0;2019;2019-02-28 10:45:01
90697;Juliana de Castro   Rabelo;;NotifyMe! A System of Physical Quantities Notifications - A case study with beehive monitoring;One of the ways to reduce inappropriate management of hives and monitor bee health is to send notifications/alerts about the data collected through sensors. This study presents NotifyMe!, a solution for sending notifications through Telegram, E-mail, and SMS. The notifications warn about the level of temperature, humidity, sound, carbon dioxide, oxygen, hive weight and delay in data gathering. From this data, researchers and beekeepers can be informed and make changes in the locations of the hives, avoiding catastrophes and possible diseases. The results obtained with the processing time in the sending of messages showed that the messages sent via SMS and Telegram have a shorter processing time compared to the sending via E-mail. In regards to sending notifications according to user preferences, all notifications were sent correctly.;Notifications, Beekeeping, Environmental monitoring;en_US;Declined;0;2019;2019-03-05 13:46:56
90742;Felipe Ricardo dos Santos   Fernandes;Programa de Pós-graduação em Ciência da Computação,Universidade do Estado do Rio Grande do Norte/Universidade Federal Rural do Semi-Árido, Mossoró-RN, Brasil.;A new approach to school patrol problem: case study and experimental in the city of Mossoró/RN;This paper presents a new approach to the School Patrol Problem (in portuguese, PPE), as well as two metaheuristics for its resolution. The PPE refers to a public safety program of cooperative support for education. In this new approach the visit cycle is decomposed into contiguous and optimized sub-cycles, where each sub-cycle represents a day and is formed satisfying a service time/day constraint. The problem consists of determining the Hamiltonian cycle that results in a minimum final cost, so that it simultaneously optimizes the attendance to the vertices taking into account their priorities. The PPE is NP-Hard, since TSP is, and is contained in the proposed approach. The proposed model is created from the case study carried out in Mossoró, Rio Grande do Norte. In order to make possible an optimized solution for the case study, this work proposes an algorithmic study through the implementation, computational experiments and analysis of the metaheuristics ILS and Memetic Algorithm. An instance of the real problem is created for the experimental tests. In possession of the results, the metaheuristics present themselves as being promising in obtaining good solutions. The proposed approach allied with metaheuristics present better results than the case study.;Combinatorial optimization, Metaheuristics, Public security, School violence;en_US;Declined;0;2019;2019-03-07 13:57:13
90779;Rafael Alexandre   Piemontez;Universidade do Vale do Itajaí - Univali;RAP3DF - Base de dados 3D de faces;Developing research in the area of ​​3D biometrics requires a large set of images, either for training or evaluating algorithms. Several bases can be found internationally, but these bases do not have the 3 main types of images in the same sample: infrared visible light and three-dimensional light from a depth image, in addition to having access restrictions or scope of application. Given the difficulties of finding a 3D database to test a 3D facial recognition system and compare them with two-dimensional imaging techniques, this work sought to create this public database, making the entire imaging acquisition process available. 3D, as well as its visible light image and infrared spectrum, from the Kinect 2 device. The work resulted in 267 samples from 64 volunteers, where each volunteer has a frontal facial image and 3 images in random positions. Enabling the database to be used for 3D facial recognition.;3D Biometrics, 3D face images, Image database;en_US;Declined;0;2019;2019-03-08 14:45:24
90903;Marla Pereira   Melo;Universidade Federal do Rio Grande;Descoberta de conhecimento em dados não estruturados: Uma análise em um chat de jogo online;This work addresses a study on knowledge discovery applied in the chat of a massively multiplayer online game (MMO). For this, the Text Mining Suite tool was used, where the knowledge discovery process, in addition to text mining, is based on the creation of concepts defined by a person who has some understanding of the texts to be analyzed. Also as a complement to the research, the Sobek text mining tool was used to support the Text Minig Suite for creating concepts. This article proposes an experimental methodology for the application of knowledge discovery in textual data generated from player conversations. With this methodology, we evaluated the results of three tests. The first test involved the Text Mining Suite tool to extract knowledge from the textual database, in the second test the Sobek tool was used to extract concepts from the text, finally, the last test combined the two tools. A quantitative analysis made it possible to present the quality of the text mining results. An improvement in results was observed, a gain in knowledge when the Text Mining Suite and Sobek tools were used, together, for the knowledge discovery process.;text mining – knowledge discovery – online games;en_US;Declined;0;2019;2019-03-12 11:39:51
90946;Almir Pereira   Guimarães;Federal University of Alagoas;An analytical approach for designing computer networks considering communications and power infrastructures integration.;Nowadays, computer networks are critical to the success of small and large businesses. They connect people, support applications and services, and provide access to the resources that keep the businesses running. Our work proposes a methodology and analytical models for supporting optimization of the network infrastructure, considering both technical and business oriented metrics, such as availability, reliability, total cost etc. The integration of communication and power infrastructures is supported in this methodology. The dependability (availability/reliability) models were created using the Reliability Block Diagram and Stochastic Petri Net modeling mechanisms following a hierarchical approach. A case study considering the design of a real-world network infrastructure is presented to illustrate the proposed methodology. The results showed a signi¯cant reduction in the design complexity as well as the improvement of the relationship between technical and business aspects.;Availability, Stochastic Petri Net, Reliability Block Diagram, Reliability Importance, Infrastructure Design.;en_US;Declined;0;2019;2019-03-14 10:59:26
90963;Mateus Junior   Cassaniga;Universidade do Vale do Itajaí;Detection and classification of cracks and potholes in images of roads using texture descriptors;Traffic security is directly affected by poor road conditions. Automating the detection of defects in highways allow speedups in the maintenance process. The identification of defects such as cracks and potholes can be performed automatically by using image processing techniques and supervised learning. In this work, we propose the detection of cracks and potholes in images of pavemented roads. The images are subdivided into blocks, where the texture descriptors Gray-Level Co-Occurrence Matrix (GLCM), Local Binary Pattern (LBP) and Gabor Filters are extracted. The classification is performed with Support Vector Machines (SVM), K-Nearest Neighbors (KNN) and Multi-Layer Perceptron (MLP) networks. Experiments were performed in a dataset built with images from brazilian highways. Two experiments were performed. The former experiment obtained a mean f-measure of 75.16%. The latter experiment obtained a mean f-measure of 79.56% in the task of classifying blocks into blocks without defects, cracks, or potholes. For the classification task of blocks with and without defects, the mean value of f-measure was 87.48%. Finally, the experiments with the classification of defective blocks into distinct classes (crack or pothole) obtained a mean f-measure of 87.06%;Image processing, Texture descriptors, Cracks, Potholes, Classification;en_US;Declined;0;2019;2019-03-14 17:19:02
90988;Luis Guilherme   Ribeiro;State University of Ponta Grossa;Comparative analysis of clustering of an ensemble model for classification of soil bacteria;In a gram of soil can contain 8.3 million species of bacteria, including bacteria that contribute and compete for plant growth. Due to the need to identify soil bacteria has been developed classification algorithms. Among them, the models are grouped in clusters, these models are performed together with classifiers to increase assertiveness, the clustering is applied in a training phase to group the sets with the objective of improving the performance of the base classifiers. Clustering is one of the main stages of data analysisprocesses. The quality of clustering is affected by the algorithm and the nature of the data, and there is no major majority method. This work was carried out in a comparative analysis between different clustering methods, the methods compared were: K-means, ART2A, Birch, DBSCAN and hierarchical agglomeration. The testes wereperformed on a soil bacterial data set through the MALDI-TOF type mass spectrum. The methods of comparison of the cluster methods were: compactness, separation and quality. In addition, each method was applied in a set of models and a performance evaluation in terms of accuracy. The result is more or less the same as the metrics, but in terms of model classification and text together, is not important among clustering methods.;Machine Learning, Ensemble Classifier, Clustering, Soli Bacteria;en_US;Declined;0;2019;2019-03-15 11:49:43
91029;Iago   Vargas;;Electronic Point System Based on Facial Biometric;Computer vision has been a frequently used tool in the most diverse technology devices, in this field of study, face recognition is a technology that has great advantages because it allows the identification and authentication of users independent of contact. One of its main applications is in the security market, for example in the development of biometric systems. In this perspective, this paper presents the implementation of an electronic point management system based on facial recognition techniques, aiming at proposing a more secure and effective system in the process of electronic point authentication within organizations. The information system was architected and developed being submitted to numerous validation tests in which five different face datasets were used.;computer vision, face recognition, eigenvalues and eigenfunctions, biometrics;en_US;Declined;0;2019;2019-03-16 15:05:57
91650;Marco Aurélio   Spohn;Universidade Federal da Fronteira Sul;Um estudo de caso para identificação de elementos e funcionalidades para uma possível arquitetura de referência para a Internet das Coisas;The main proposal of the Internet of Things is the creation of a network of interconnected heterogeneous devices, similar to the Internet. Its purpose is to make any devices/things, such as automobiles, household appliances, among others, become intelligent, performing tasks and sharing information. The Internet of Things has gained popularity and demonstrates great importance for innovation and evolution in several areas. Because of this, the growth in the number of solutions developed for the Internet of Things is evident and, therefore, it is essential to establish a reference architecture to improve the development process and implementation of these solutions. There are different initiatives that seek to establish a reference architecture for the Internet of Things, however, so far no consensus has been reached. Aiming to contribute to the state of the art of these initiatives, the present work aims to identify, through a case study carried out on a specific set of Internet of Things platforms, elements and functionalities for a possible reference architecture, analyzing the consequences of its adoption.;;en_US;Declined;0;2019;2019-04-05 15:33:54
91743;Carla Diacui Medeiros   Berkenbrock;UDESC;Desenvolvimento e Avaliação de um Recurso Colaborativo de Tecnologia Assistiva;Communication is the way to share information, develop culture and interact in society. Computer technologies together with Collaborative Systems are increasingly contributing to people's communication accessibility and the inclusive process. This article aims to present the results of the evaluation of a mobile application developed to support the communication of deaf subjects and Libras speakers. The results obtained demonstrate good performance of the developed application, as well as the potential to contribute to expanding the vocabulary of users interested in learning Libras.;collaborative system, Libras, deaf;en_US;Declined;0;2019;2019-04-09 16:06:22
91831;Alessandro Cordeiro   de Lima;University of Brasília;Performance Evaluation of SDN Controllers: A Comparative Study;The Software Defined Networks (SDN) paradigm basically requires 3 components for its full operation:application layer, control plane and data plane. In the application layer we find modules developed to be executedin the controller. In the control and data plans, the first is able to obtain control and centralized managementand the second we visualize the physical equipment of the network. This article has as its main objective thecontrol plan. SDN controllers play a key role in an SDN network. Therefore, an in-depth analysis of the use ofcomputing resources in virtualized environments and a view of the performance of the SDN controller on thenetwork is needed, thereby providing guidance on how they should be configured to function properly. Thisarticle presents a performance analysis comparing various SDN controllers through experiments, noting theresource consumption of the virtual machines in which they are running. We evaluate different aspects ofperformance, such as CPU, memory, throughput, disk storage and processing load. Our analysis shows howcontrollers treat the machine resources on which they are located and the impact on their performance.;SDN, Performance, Virtualization, Controllers;en_US;Declined;0;2019;2019-04-12 16:59:01
91906;GILSON AUGUSTO   HELFER;Universidade do Vale dos SinosUniversidade de Santa Cruz do Sul;PhotoMetrix: a computational model for colorimetric analysis in smartphones;This paper describes the development of computational model for mobile colorimetric analysis. The PhotoMetrix employs single linear regression algorithms for univariate calibration and multiple linear regression algorithms for multivariate calibration. It also applies principal component analysis and hierarchical cluster analysis for multivariate exploratory analysis. The image data are acquired using the device main camera and converted in RGB histograms. In addition, single color channels of RGB, HSV, HSL and HSI systems are used during the univariate and multivariate processes. It is possible to send by e-mail the image data, analysis data and charts. In order to validate the obtained results, the same sets of data were tested using Microsoft Excel© and ChemoStat© and the results compared were identical. Besides the use in didactic activities, this system has been used in the daily classes of teachers and researchers from different areas of knowledge. Research on food technology, medicine, chemical speciation and water quality are reported frequently;colorimetry, multivariate calibration, exploratory analysis, smartphone;en_US;Declined;0;2019;2019-04-15 16:45:01
91936;Lássion Laíque   Santana;Federal University of Bahia;Exploiting Relations Between Users in a Film-Based Hybrid Recommendation Systems;Recommender Systems have become popular and widely applied across the world in the mostdiverse lines of industry and academy. Websites and services have been implementing these concepts to help users filter relevant information which are in fact relevant, thus making their experience more personalized. There are several ways to build a Recommendation Systems, such as content-based filtering and collaborative filtering. Hybrid Recommender Systems have set out to combine the benefits of both approaches by making it a more robust solution to address the needs and challenges of this area. This work proposes a strategy such asanalyzing the descriptions of films as a user model in order to improve the predictions of the algorithms, the proposed algorithm is evaluated using the Root Mean Square Errormetric and statistical tests. The results show that the proposed hybrid approach presents an improvement compared to the classic algorithm based on collaborative filtering.;Recommendation Systems, movies, collaborative filtering, hybrid approach;en_US;Declined;0;2019;2019-04-16 11:51:21
91964;Almir Pereira   Guimarães;Federal University of Alagoas;An analytical approach for designing computer networks considering communications and power infrastructures integration.;Nowadays, computer networks are critical to the success of small and large businesses. They connect people, support applications and services, and provide access to the resources that keep the businesses running. Our work proposes analytical models and a methodology for supporting the optimization of the network infrastructure design, considering both technical and business oriented metrics, such as availability, reliability, total cost etc. The integration of communication and power infrastructures is supported in this methodology. The dependability (availability/reliability) models were created using the Reliability Block Diagram and Stochastic Petri Net modeling mechanisms following a hierarchical approach. A case study considering the design of a real-world network infrastructure is presented to illustrate the proposed methodology. The results showed a signiﬁcant reduction in the design complexity as well as the improvement of the relationship between technical and business aspects.;Availability, Stochastic Petri Net, Reliability Block Diagram, Reliability Importance, Infrastructure Design.;en_US;Declined;0;2019;2019-04-16 23:31:11
92302;Bruno S.   Araujo;Universidade de São Paulo;Ethnic, gender and age features in the synthesis of facial images;Human faces contain several different features that are important to individualize them, such as ethnic groups, gender and age. Knowing how to synthesize facial images with these features in an efficient way is essential in many types of applications, such as person recognition, digital games, etc. One example of application we are working on is a serious game to support the treatment of people with psychiatric disorders with difficulty to recognize emotions in human faces, where ethnic, gender and age characterization will be important.The avatars can be generated with faces more familiar or less familiar to the patient's relatives, for instance. This dynamic avatar generation, on the fly the execution of an application which logic was previously programmed, is not a trivial task using the current game engines. The objective of this study was to identify which facial features are influenced by ethnic, gender and age diversities and present a proof of concept of our proposed strategy for automatic synthesis of facial images based on the effects of these diversities on anthropometric measurements. The results show that: 1) among these three diversities, the gender diversity was the most difficult to characterize only through the facial features (without hair or beard) 2) the representation of wrinkles plays an important role in the characterization of age groups and 3) it is possible to characterize ethnicity based only on facial features, with skin color being a contributing or confounding factor depending on the ethnicity being represented. Whereas this proof of concept is based on the generation of caricatures, future works will extend the results to generate more realistic images.;Ethnic diversities, Gender diversities, Age diversities, Face representation, Psychiatric disorders treatment;en_US;Declined;0;2019;2019-04-28 20:56:06
92663;Fabíola M.   Kretzer;INE/UFSC;Desenvolvimento Profissional de Professores para o Ensino de Computação na Educação Básica: Um Estudo de Mapeamento Sistemático;Nowadays, computing has become increasingly influential in our daily lives. Due to this importance, computing needs to be popularized in Basic Education, giving students the opportunity to learn basic computing skills. Integrating computer education at school requires trained teachers, however, these teachers are currently not enough. Therefore, some initiatives aim to integrate computing training in an interdisciplinary way, training teachers from other areas who are working in the classroom. In this context, this article presents the results of a systematic mapping aimed at identifying existing instructional units (UIs) for training teachers working in the classroom and their characteristics. As a result, 16 instructional units were found. Most UIs focus on teaching algorithms and programming, with few also covering pedagogical and technological knowledge. The UIs found vary widely in terms of teaching mode and duration. We also observed, due to the lack of information about how UIs were developed, opportunities for future research in this area. However, the results also demonstrate first signs of the feasibility and positive contribution of training teachers working in the classroom for teaching computing, contributing to the popularization of computational skills.;computing, basic education, teacher training;en_US;Declined;0;2019;2019-05-07 14:40:46
93520;Alexandre Alvarenga de Oliveira   Monteiro;Federal University of Santa Catarina;Weed Mapping in Aerial Images through Identification and Segmentation of Crop Rows and Weeds using Convolutional Neural Networks;In this paper we present an experimental comparison of state-of-the-art convolutional neural network  models for the task of weed mapping, the differentiation and segmentation of crops and weeds in agricultural aerial images. State of the art in aerial weed mapping is focused upon multi-spectral images. The main goal of this work is to investigate whether only RGB-based visible light input channels are sufficient to achieve good results and which model provides the best performance. For this purpose, we conducted a systematic literature review of recent methods specifically designed for aerial image weed segmentation, and, for comparison purposes, we implemented four promising semantic segmentation  models. The obtained results were compared against  expert-generated ground-truth images, using two distinct evaluation metrics, F1-score and IoU. We were able to solve the segmentation and weed mapping problem with a mean F1-score of 95.59\% and a mean IoU of 79,35\%. These results are much better than results previously reported in the literature, even those using special color-spaces and enhanced light spectrum ranges.;Digital Image Processing, Deep Learning, Convolutional Neural Networks, Semantic Segmentation, Unmanned Aerial Vehicles, Precision Agriculture;en_US;Declined;0;2019;2019-06-05 17:03:49
93837;Mauricio Aronne   Pillon;Universidade do Estado de Santa Catarina (UDESC)Programa de Pós Graduação em Computação Aplicada (PPGCA);Energy-Aware Job Scheduling in Grid Computing with Easy Backfilling and HEFT Algorithms;Grid computing, dynamic and flexible computational infrastructures managed using Resource Management Systems (RMS), have been employed for more than two decades in hosting High Performance Computing (HPC) applications. The scheduling algorithms used in computational grids usually prioritize the provision of the infrastructure in favor of the performance of the applications, mainly ignoring approaches which takes into account energy saving. However, with the ecological and financial appeal, some initiatives for the conscious and efficient use of energy have been created. Among them, the proposal of green heuristics which consider energy consumption and application performance (execution time) in grid computing environments. We adapted the traditional algorithms EASY-Backfilling and HEFT for scheduling tasks in computational grids using a set of  predefined heuristics. The principles of filling time gaps and overlapping tasks on a single resource are the foundation of our proposal. Our results using the Batsim simulation environment revealed a reduction of energy consumption between 2% and 49%  and, at task execution time, between 1% and 32%.;Scheduling algorithms, Grid Computing, Overlap, Power;en_US;Declined;0;2019;2019-06-19 15:17:32
93988;Rafael   Pinto;Universidade Federal do Rio Grande do Norte;A Systematic Mapping Study on Requirements Engineering and Big Data Analytics;Context: The real value of Big Data is in the potential to leverage ideas for evidence-based decision making. The analysis of large amounts of data requires technologies to efficiently process its volume and deliver results so that decision-makers can understand and act. Objective: This article analyses  studies which relate the areas of requirements engineering and big data analytics. Our goal is to provide an overview on how the papers in this field of research are characterized, both methodologically and in relation to the subjects, techniques, and requirements addressed. Method: A systematic mapping of the literature is carried out. After applying the inclusion and exclusion criteria, 63 studies were selected for complete reading. Results: We detected a growth in the number of studies involving these two areas from 2014. Most of them address the proposition of a solution, but few studies present tools. We identified two topics and five subtopics which these articles deal with. There are more studies focused on using big data analytics techniques to support requirements engineering activities than the opposite. Also, the studies mainly deal with elicitation and modeling activities. There are a variety of types of systems, techniques and requirements being addressed. Conclusions: The use of big data analytics systems is on the rise and requires that all software engineering sub-areas evolve to meet the new demands. This mapping organizes the studies found and reveals gaps to be further researched.;Systematic Mapping Study, Big Data, Analytics, Requirements Engineering;en_US;Declined;0;2019;2019-06-25 11:06:45
94639;Fabio Fonseca Barbosa   Gomes;UNIRB;Um Programa Móvel como Solução para Otimização dos Processos em Instituições de Ensino Superior;Computing is constantly evolving and popularizing, as a result of the increase in processing capacity and miniaturization of computers. In addition, there are new forms of wireless communication, such as Wi-Fi, satellites and radio. This allows humanity to improve a series of procedures in companies. Focusing on Higher Education Institutions, a computational solution for improving various processes would be the use of web systems. This would solve problems such as bureaucracy and lack of quick communication between sectors, as they take a long time to reach resolutions, resulting in waiting lines and wear and tear as well as hassles. This article proposes the creation of such a tool, with the ability to communicate with the sectors responsible for each demand and a field research among students;Academic Systems, Mobile Applications, Information System;en_US;Declined;0;2019;2019-07-19 8:32:13
94694;Daniel Vieira   de Souza;Universidade Estadual do Rio Grande do Norte (UERN);A Hyperheuristic Approach to the Vehicle Routing Problem with Time Window;The concept of hyperheuristics is somewhat new in the field of optimization, it is a method thatproposes a strategy of resolution that operates in a new level of abstraction, where without the use of specificinformation of the treated problem the method is able to offer solutions through the management of a set ofavailable heuristic methods, and learning and / or training mechanisms may be employed. These characteristicsallow this type of approach to adapt to different problem domains or to different classes of instances. Especiallyin problems where having a set of heuristic methods is not known which technique of resolution is the mostadequate. The present work proposes as approach a hyperheuristic with learning integrated to GRASP (GreedyRandomized Adaptive Search Procedure) Metaheuristic applied to a variant of the classic Vehicle RoutingProblem (PRV), the Vehicle Routing with Time Window (PRVJT). Having this method as learning mechanism aReinforcement Learning (RA) technique, the algorithm Q-Learning that will have the task of indicating whichheuristic method is most suitable to compose the constructive phase of GRASP. Like hyperheuristics withlearning, another hyperheuristic method of managing random heuristics was implemented, trying to compareand analyze the performance of the learning method. The algorithms were tested in computational experimentswith known instances in the literature for the PRVJT and the results obtained compared to the cost of solution,execution time and choice of the constructive heuristic method used in the GRASP construction phase;;en_US;Declined;0;2019;2019-07-21 23:17:32
94739;Sidney   Lima;Department of Electronic and Systems - UFPE;NGAV (Next-Generation Antivirus) Specialist in Behavioral Analysis of Malware;Instead of conventional cyber-intrusions, modern cyber-attacks involve some type of script, almost always written in JavaScript. So, this work creates an NGAV (Next Generation Antivirus – Next Generation Antivirus). The proposed mechanism is equipped with machine learning, specialized in detecting JavaScript malware. In our methodology, JavaScript is purposely executed in a controlled environment. The objective is to examine the behavior of the suspicious file. In total, our NGAV statically monitors and considers 7690 suspicious behaviors in the Windows Operating System. Our NGAV achieves an average of 99.65% in distinguishing between benign JavaScript and malware.;Malware, Antivirus, Artificial Neural Networks, Real-time Malware Detection, Computer forensics;en_US;Declined;0;2019;2019-07-23 12:55:08
95598;Leandro Alberto   Lonardoni;;Redes Neurais Recorrentes para Previsão de Demandas Assistenciais na Saúde Suplementar;The use of large data sets to help companies in decision making is in emphasis today. The scientific base in the analysis and exploration of data has inspired academic studies and generated interest of public and private companies. Data Science enters in this context as a focused and strategic study area for companies that wish to create a competitive advantage and generate new business. Some examples of technology advances in this area are: image and voice recognition, crime prevention, robotics, medical diagnostics and health care. The Private Health Insurance and Plans is an important activity to be explored in Data Science, with applications in the forecast of assistance demands and identification of frauds and abuses in medical bills. The risks of this activity require changes in the private health and plan business and the analytical study of the historical data generated by their agents are fundamental to these transformations. This dissertation presents the construction of a machine learning model that uses recurrent neural networks to make predictions of health care demands in private health plan operators. The methodology was applied to a dataset obtained from two sources: outpatient care data and meteorological data from the Maringá-PR region, which made it possible to compare the results of the forecast with and without the use of meteorological data. In the exploratory analysis stage the initial data were stratified resulting in new variables for the model construction. The data were normalized and the variables with high correlation were identified. From this, some simulation scenarios were created with the most relevant variables for the model. Each proposed scenario was trained with the recurrent neural network algorithm tensorflow. The results of each simulation were analyzed and compared with the indicators that measure the prediction quality: mean absolute error (MAE), mean absolute percentage error (MAPE) and coefficient of determination (R2). The best MAPE was 10.73% in the emergency medical scenario using meteorological data. The presented results showed that the use of meteorological data improves from 22% to 35% the forecast when compared to scenarios that not use meteorological variables. The methodology used has potential to forecast health care demands and can help companies in decision making, being extended to other data sets.;Data Science, Recurrent Neural Networks, Time Series, Machine Learning;en_US;Declined;0;2019;2019-09-16 22:49:15
95611;Márcio   Dorn;Federal University of Rio Grande do Sul, Institute of Informatics, Porto Alegre;teste;test;;en_US;Declined;0;2019;2019-08-18 8:42:46
97525;Antônio Carlos   Rocha Costa;PPGComp-C3/FURG e PPGC-PGIE/UFRGS;Slavery in Material Agent Societies;This paper formally characterizes \emph{slavery systems} in material agent societies. The concepts of \emph{master-slave economic relationship}, \emph{slavery-based economic system}, \emph{slavery-supporting legal system}, and \emph{slavery-based material agent society} are formally defined. A first case study recasts, for material agent societies, North \& Thomas' economic model determining the objective conditions under which it is rational for a society to choose a \emph{slavery-based economic system} over a \emph{free labor-based economic system}. A second case study makes use of elements of F. H. Cardoso's study of slavery in the south of Brazil to illustrate the application of the formal concepts introduced in the paper.;;en_US;Declined;0;2019;2019-10-20 15:25:37
97535;Érick Fernandes   Moreira;UFPel;Reconhecimento de textos escritos à mão por crianças do ensino fundamental;Texts written by hand by students in the early grades of elementary school present several challenges to text recognition, among which we can mention writing errors and poorly developed handwriting. Texts in Portuguese are still little explored in this type of application. Among them, we can find some works that try to recognize writing on bank checks, an application with less freedom in writing. In this work, we intend to develop a system for recognizing handwritten texts for students in the initial grades of elementary school. The quality of handwritten text recognition has advanced considerably in recent years, due to the use of Artificial Neural Networks. In this work, we use Tesseract OCR to build a model based on the LSTM architecture and then compare the performance of the model created in relation to the original model provided by Tesseract OCR and also to the performance found when using OCR present in Google Drive.;Child Texts, LSTM, Optical Character Recognition;en_US;Declined;0;2019;2019-10-20 18:56:19
97554;Diulia Justin   Deon;UFPel;Padrões linguísticos para detecção de ironia em múltiplos idiomas;Most studies in Sentiment Analysis aim to classify statements according to their polarity. Irony presents itself as a challenge to this area, as it involves the inversion of meaning in the text. On the other hand, the large volume of data published on Social Networks and the characteristics of the micropost genre draw the attention of scholars. In this article, we propose to analyze linguistic patterns identified to detect irony in microposts in Portuguese, English, Italian and Spanish.;Irony Detection, Multiple Languages, Patterns;en_US;Declined;0;2019;2019-10-20 23:05:39
97929;João Carlos   Epifânio;Federal University of Rio Grande do Norte (UFRN);A Tertiary Study on Computer Science Technologies for Autism;Autism is characterised by a great diversity of disabilities and intensities observed in the development of individuals since their infancy. The search for treatment has increased, and new forms of interventions have emerged, including those involving technology. The literature presents a large number of papers describing technologies for autism however, given the volume of primary and secondary studies, it is difficult to have an overview of the existing solutions and gaps to deal with in future research. This paper analyses review studies on technology and autism in order to summarise their main subareas of the studies, the characteristics and comorbidities of individuals, the most used and developed technologies, research gaps, besides future research. A systematic mapping containing 8 research questions related to the area in focus in the articles, in addition to the support offered, participants' development phase, exercised skills and quality criteria used. A total of 33 literature review studies (which analysed 1298 primary studies) were examined. It is essential to know the state of research involving technology and autism given the significant increase in demand for systems for that audience. This will help researchers to identify topics and challenges to be explored by new research.;Literature systematic mapping, Tertiary study, Autism, Technology;en_US;Declined;0;2019;2019-11-02 11:55:18
97930;João Carlos   Epifânio;Federal University of Rio Grande do Norte (UFRN);A Tertiary Study on Computer Science Technologies for Autism;Autism is characterised by a great diversity of disabilities and intensities observed in the development of individuals since their infancy. The search for treatment has increased, and new forms of interventions have emerged, including those involving technology. The literature presents a large number of papers describing technologies for autism however, given the volume of primary and secondary studies, it is difficult to have an overview of the existing solutions and gaps to deal with in future research. This paper analyses review studies on technology and autism in order to summarise their main subareas of the studies, the characteristics and comorbidities of individuals, the most used and developed technologies, research gaps, besides future research. A systematic mapping containing 8 research questions related to the area in focus in the articles, in addition to the support offered, participants' development phase, exercised skills and quality criteria used. A total of 33 literature review studies (which analysed 1298 primary studies) were examined. It is essential to know the state of research involving technology and autism given the significant increase in demand for systems for that audience. This will help researchers to identify topics and challenges to be explored by new research.;Literature systematic mapping, Tertiary study, Autism, Technology;en_US;Declined;0;2019;2019-11-02 12:03:03
98220;Jhonatan Gonçalves   Astrogildo Dantas;O Instituto Federal de Educação, Ciência e Tecnologia do Espírito Santo (Ifes) é uma instituição pública federal brasileira, vinculada ao Ministério da Educação;Free Hardware Platform To Assist Programming Teaching;The objective of this work is to develop a low cost fast prototyping board model capable of equipping automation and robotics projects, especially educational robotics, that can be distributed as a replacement for the Arduino product. In addition, we seek to develop the product concept for the prototyping of electronic circuits in automation projects, aiming at the market, the very network of the Federal Institute of Espírito Santo, thus adding an academic value to a possible brand. As for the methodology, there is the need for in-depth studies regarding the making of circuit paths and the component models that can be used, considering that some of these are created for industrial scale manipulation. For a satisfactory result, many challenges are noted, including the use of Surface Mount Devices (SMD), which are part of the interest of this project.;Prototyping Platform --- Education and robotics --- Programming Logic --- Hardware;en_US;Declined;0;2019;2019-11-14 17:32:07
98230;Gideão Pelegrino de   Abreu;;Computer Vision to assist moving Autonomous MobileRobots: A case study for automatic recharge - Part 1;The ability to move autonomously is critical for intelligent animals and organisms. Parallel to this a new challenge is presented: How to teach machines the recognition of visual patterns, helping the movement and increasing the autonomy and precision in the performance of tasks? The answer is the joint use of technological developments that have emerged in the fields of Artificial Intelligence and Robotics. From this information the present work sought to develop Computer Vision algorithms to assist the movement of Autonomous Mobile Robots, through the identification of visual patterns, to map the environment with which it interacts, as well as to facilitate the process of electrical replenishment through the identification. of power supplies. From the initial stages, an image bank was built, applying them in the training of detection models that use deep neural networks. Secondly, it was found that the detection models were able to detect outlets. Finally, the detection algorithms and models trained in a physical robot prototype were validated.;;en_US;Declined;0;2019;2019-11-14 22:42:00
98358;Alfio Ricardo   Martini;Av. Marechal Andrea 11/210, Porto Alegre/RS/Brasil;Reasoning about Partial Correctness Assertions in  Isabelle/HOL;Hoare Logic has a long tradition in formal verification and has been continuously developed and used to verify a broad class of programs, including sequential, object-oriented and concurrent programs. The purpose of this work is to provide a detailed and accessible exposition of the several ways the user can conduct, explore and write proofs of correctness of sequential imperative programs with Hoare logic and the Isabelle proof assistant. With the proof language Isar, it is possible to write structured, readable proofs that are  suitable for  human understanding and communication.;Hoare Logic, program verification, theorem proving;en_US;Declined;0;2019;2019-11-20 0:01:14
98488;Mateus Sturmer   Pioner;Universidade do Vale do Rio dos Sinos;Uma Implementação de Autenticação baseada em Eletrocardiograma Integrada ao Blockchain;With the growth in the use of biometrics for authentication, a new approach has been growing in recent years. Cognitive biometrics has presented relevant results in the studies carried out. Likewise, in recent years blockchain has been growing and expanding its use to much more than just cryptocurrencies, and can be used in the most diverse market sectors. This work aims to analyze a new method for authentication in Electrocardiograms based on the Mean Square Error formula and the storage of samples for user authentication in a private blockchain, evaluating the feasibility of this approach. The results obtained show that this method can be used for authentication through Electrocardiogram due to its level of accuracy in relation to comparing the ECG of each user and distinguishing between them. Furthermore, the use of blockchain with its own resources presents an implementation comprising some security aspects related to the storage of information.;ECG, Electrocardiogram, MSE, Authentication, Blockchain;en_US;Declined;0;2019;2019-11-25 16:41:20
98555;Iara   Silva;Universidade Tecnológica Federal do Paraná;Estudo Comparativo entre a Implementação Sequencial e Paralela dos Métodos Gauss-Jacobi e Gauss-Seidel;This article aims to analyze and compare the difference in response time of numerical methods known as Gauss-Seidel and Gauss-Jacobi, using sequential and parallel programming approaches in their implementations. Furthermore, a hybrid numerical method will be presented as a parallelization option for the Gauss-Seidel method, proposed for solving linear system problems that satisfy the line criterion. Tests were carried out to demonstrate that there are cases in which the sequential Gauss-Seidel method can be more efficient than the parallel execution of the Gauss-Jacobi method.;;en_US;Declined;0;2019;2019-11-27 13:21:02
99646;Carolina   Rosseti Matheus;Instituto Federal de Educação, Ciência e Tecnologia de São Paulo;Establishment of a Requirements Catalog forCyber-Physical Systems (CPS) in the Context of Industry4.0;Cyber-Physical Systems (CPS), even with benefits in terms of automation and management in Industry 4.0, present challenges that need to be explored, such as the absence of standardization in defining the characteristics and requirements of its development. We believe that the definition of a catalog of specific requirements for these systems is one of the relevant steps to ensure greater suitability and quality of industrial practices. Thus, this project has the objective of proposing a catalog of requirements for Cyber-Physical Systems (CPS) in the context of Industry 4.0, serving as a guide for the development and improvement of these systems. The catalog will be developed based on the implementation of a Systematic Review and the experience of experts (including evaluation and elicitation experiences for Cyber-Physical Systems (CPS) requirements). The objective of this catalog is to help users, who are managers or directors, to compare, select and improve theunderstanding about this type of system, being compatible with the production, socio-cultural, functional and economic criteria, ensuring higher quality and standardization for the practices of Industry 4.0.;;en_US;Declined;0;2020;2020-01-21 20:16:31
99704;José Gomes   Lopes Filho;Universidade Federal do Rio Grande do Norte;Traveling Salesman Problem with Optional Bonus Collection, Pickup Time and Passengers;This study introduces a variant of the Traveling Salesman Problem, named Traveling Salesman Problem with Optional Bonus Collection, Pickup Time and Passengers (PCVP-BoTc). It is a variant that incorporates elements of the Prize Collecting Traveling Salesman Problem and Ridesharing into the PCV. The objective is to optimize the revenue of the driver, which selectively defines which delivery or collection tasks to perform along the route. The economic effect of the collection is modeled by a bonus. The model can be applied to the solution of hybrid routing systems with route tasks and solidary transport. The driver, while performing the selected tasks, can give rides to persons who share route costs with him. Passengers are protected by restrictions concerning the maximum value they agree to pay for a ride and maximum travel duration. The activity of collecting the bonus in each locality demands a specific amount of time, affects the route duration, and is interconnected with the embarkment of passengers. Two mathematical formulations are presented for the problem and validated by a computational experiment using a solver. We propose four heuristic algorithms three of them are hybrid metaheuristics. We tested the mathematical formulation implementations for 24 instances and the heuristic algorithms for 48.;Travelling salesman Problem, Travelling salesman Problem with profits, Ridesharing;en_US;Declined;0;2020;2020-01-17 20:29:53
99841;Ruymar Araújo   Mendes Neto;Universidade Estadual do Piauí;Application and evaluation of data mining techniques in the process of predicting the rainfall index in the north of the state of Piauí;The amount of rain is very valuable information when carrying out various activities of society, such as agriculture, tourism and aeronautics. Being important also for day-to-day decisions. Most of the methods currently used for weather forecasting are effective only for short-term forecasting, since they are not accurate enough for long-term forecasting. One of the most important meteorological variables is the rainfall index in a particular are. In this paper, two data mining techniques were performed, Artificial Neural Networks (ANN) model called Multi-layer Perceptron (MLP), is used in this work to predict a monthly rainfall amount in the coastal region of Piaui, Brazil. and Decision Tree (J48) to perform the categorization of the parameter that has the greatest influence on the prediction of the rainfall index, The coastal microregion of Piaui has 14 municipalities where some of the main economic activities are tourism and agriculture. This study uses a meteorological data from a 25-year period (1990-2015) provided by Embrapa Meio Norte. These data were submitted to the network and a training process using the Backpropagation algorithm. At the end of this process, we obtained the best network, which had an accuracy of 83.8\%, satisfactory to show the ability of RNA to predict temporal beings. Then the parameter with the greatest influence on obtaining the results was found, through the Decision Tree, which serves to gain information for new tests on RNA or using another data mining technique.;Artificial neural network, Data mining, Pluviometric index, Tree decision;en_US;Declined;0;2020;2020-01-23 23:53:43
100020;Lidiane Teixeira   Pereira;Universidade Federal de Juiz de Fora;Photorealism in Augmented Reality: A Systematic Literature Review;In Augmented Reality systems, virtual objects are combined with real objects, both three dimensional, interactively and at run-time. In an ideal scenario, the user has the feeling that real and virtual objects coexist in the same space and is unable to differentiate the types of objects from each other. To achieve this goal, researches on rendering techniques have been conducted in recent years. In this paper, we present a Systematic Literature Review aiming to identify the main characteristics concerning photorealism in Augmented Reality systems to find research opportunities that can be further exploited or optimized.;photorealism, augmented reality, real-time;en_US;Declined;0;2020;2020-01-30 14:30:09
100256;Cleir Araujo   Junior;Fundação Educacional de Macaé (FeMASS/FUNEMAC);Computação distribuı́da aplicada à análise estrutural linear;Analytical approaches used to determine axial forces in structural elements invariably incur practical limitations. Algebra contributes valuable tools capable of solving linear systems, and consequently, for the design of support structures. Therefore, this article proposes numerical/algebraic approaches, with the intention of allowing the development of a parallel computer program capable of determining the forces under which truss-like structures are subjected. Experimentally, the results create evidence of the adherence of computational methods to this typical Engineering problem.;Structural analysis, Knot method, Parallelism, Linear systems;en_US;Declined;0;2020;2020-02-04 18:08:55
100497;Yosvany   Medina Carbó;UPR;Herramientas tecnológicas en Android para la formación de mapeadores y promotores de la metodología de Mapa Verde en el municipio Consolación del Sur.;When we talk about technologies and the environment, we normally imagine a large amount of equipment, techniques, technologies and tools contaminating the natural environment. The good and bad consequences of our development have been projected onto the planet for years, and part of that development is reflected in new technologies, among which is the mobile phone. In the municipality of Consolación del Sur and from the Municipal University Center, work is being done on the project “Implementation of the Green Map Methodology in the management of environmental education in Consolación communities” for the formation of an environmental culture for sustainable development by creating awareness of the care and protection of the environment. The present work is intended to solve the following problem: how to contribute to the construction of a package of computer tools for the implementation of the Green Map methodology in environmental management in Consolar communities and the training of mappers and promoters of Green Map for the development of green maps of the communities of the Consolación del Sur municipality? To this end, two Android applications for mobile devices were developed based on the Mapa Verde methodology, thus responding to the following objective: Develop a package of computer applications for the implementation of the Mapa Verde methodology in the management of environmental education in communities in Consolar and the training of mappers and Green Map promoters.;;en_US;Declined;0;2020;2020-02-13 16:54:27
101542;Gustavo Simões   Carnivali;Universidade Federal de Minas Gerais;A Comparison of Genetic Factors for Neurodegenerative Diseases;The genetic process determine all positive and negative characteristics of individuals, they can also determine and contribute to an individual's susceptibility to various diseases and how they will develop. In this context, it is interesting and important to know the metabolic and genetic pathways that contribute to the appearance and operation of a disease. The objective of this study is to determine unknown disease characteristics by comparing their genetic characteristics. For this, the gene network of a set of 10 neurodegenerative diseases will be compared. The use of genetic networks allows comparison of properties as metabolic pathways or factors that cause diseases phenotype patterns. This type of study also allows the applications as the reuse of drugs and treatments or the choice of functional pharmaceutical therapies. This work found as a result strong genetic similarities between diseases of a specific group called Spinocellebellar Ataxia. It was also found similarities more subtle between the groups of different diseases.;Genetic diseases, Neurodegenerative diseases, Spinocerebellar Ataxia, Coexpression;en_US;Declined;0;2020;2020-04-01 10:49:42
101637;Silvia   Gaftandzhieva;;A Comprehensive Approach to Learning Analytics in Bulgarian School Education;The wide range of data produced by participants in learning processes has led to increased interest in the collection and analysis of data to support data-driven decision making at all levels of educational institutions. The paper presents a comprehensive approach to Learning Analytics in the field of School Educationfromtheperspectiveofalldifferentstakeholders, which aims to improve its methods of approaching and analyzing learning data. On the basis of a literature review in the field and an investigation of requirements for quality evaluation of learning in school education, the corresponding stakeholder groups are identified - students, teachers, headteachers, principals, parents, inspectors, experts and 6 models (1 model per each stakeholder group) for data collection and personalized and meaningful analysis are proposed for the needs of Learning Analytics. Each model consists of measurable indicators allowing the relevant stakeholder to track data for students’ learning or training for different purposes, e.g. monitoring, analysis, forecast, intervention, recommendations, etc., but finally to improve the quality of learning and teaching processes.;Learning Analytics, Stakeholders Perspective, Learning Data, Models, School Education;en_US;Declined;0;2020;2020-04-04 13:38:50
103175;Caio Agostini   Calheiros;Hospital do Câncer, Fundação Cristiano Varella (FCV);Interpretation conflict and disequilibrium of linkage in  BRCA1 and BRCA2 genetic variants;The aim of this study was to analyze the BRCA1 and BRCA2 genetic variants in order to compare in silico predictions by different tools. Furthermore, we investigated linkage disequilibrium (LD) in genetic variants observed in cancer patients. ClinVar, SIFT, PolyPhen2, VEP, PROVEAN and Fathmm-MKL were performed for in silico analysis. Linkage disequilibrium investigation was carried out using the Linkage Disequilibrium Calculator software. We observed 60 different variants and the most common was the T>C variant. The SIFT, PolyPhen2 and PROVEAN programs showed similarities in the degree of pathogenicity achieved. VEP, Fathmm-MKL and ClinVar predicted the majority of analyzed variants. Sixteen genetic variants, manually selected, were analyzed as LD and 33 linkage disequilibria were confirmed in pairs and then pooled into 5 groups. The genetic variants observed in our sample are generally observed in other populations, such as in South America, Asia and East Asia, Africa, South Asia and Europe. The correct association of phenotype/genotype and epidemiological information can provide important epidemiological information, such as prognostic and treatment aspects, seeking a better understanding of the quality of life of diseases and associated genetic evolution factors.;Bioinformatics, BRCA1 and BRCA2, Linkage Disequilibrium;en_US;Declined;0;2020;2020-05-20 21:02:23
104166;Hiury Nogueira   Araújo;Universidade Federal Rural do Semi-Árido;Applying Supervised and Semi-Supervised Multi-View Learning: A Comparative Study in Hierarchical Multi-Label Classification;Data classification is a task applied in various areas of knowledge, this can be divided according tothe available data, which are labeled or not labeled. One approach has proven very effective when working withdata sets containing labeled and unlabeled data, this called semi-supervised learning, your objective is to labelthe unlabeled data by using the amount of labeled data in the data set, improving their success rate. Such datacan be classified with more than one label, known as multi-label classification. Furthermore, these data may beorganized hierarchically, thus containing a relation therebetween, this called hierarchical classification. On thispaper was used the Co-Training that is a multi-view semi-supervised learning algorithm and the supervisedlearning, both applied in problems of hierarchical multi-label classification, which are problems that combinehierarchical and multi-label classification. An experimental analysis of the methods found that supervisedlearning had a better performance than Co-Training in a general metrics scenario, however, in a specific metricfor multi-label hierarchical classification, Co-Training got the best result.;Multi-label classification, Hierarchical classification, Supervised learning — Semi-supervised learning — Co-Training;en_US;Declined;0;2020;2020-06-11 19:49:30
104182;Luiz Henrique Custódio Mendes   Marques;State University of Maringá;Cache-Based Side-Channel Attacks: An Overview;The implementation of secure systems which guarantee privacy of the user’s data is getting a great attention nowadays. To evaluate the system's security level, invasion tests capable of detecting existent vulnerabilities are essential. So that, such invations can be prevented when it comes to real attacks. The cache-based side-channel attack is one of the main attack approaches, when the subject is leaking cryptographic information. Several researches have proposed techniques capable of detecting and prevent the aformentioned attacks. This article aims to provide an overview of the concepts surrounding such attack. In addition, a summary of the relevant researches from the last 5 years is presented.;cache attacks, side-channel, cache architecture;en_US;Declined;0;2020;2020-06-12 13:31:44
104563;ERRITALI   Mohammed;;A blockchaine authentication scheme for e-health applications based Ethereum;e-health systems and telemedicine have grown rapidly, benefiting from the development of network and communication technologies. By using electronic health care systems, the patient can take advantage of the remote medical service provided by the medical server. Medical data is important privacy information for the patient, so it is important to ensure the security of medical data transmitted over the public network. This document describes the design and implementation of an e-Health authentication architecture based on the blockchaine. This architecture was developed to authenticate online health users accessing gnuhealth ERP data. The architecture described in this work is based on a Blockchain network with the Ethereum platform using the geth client with the GO language, as regards authentication to the GNUHealth ERP, we have developed a smart contract using the language solidity, this smart contract will be linked to gnuhealth and will be deployed in the ethereum network that we have created.;;en_US;Declined;0;2020;2020-06-21 8:41:10
105607;Antonio Luciano Lopes   Uliana;Universidade Federal de São Carlos;An Updated Review of Density-Based Clustering Algorithms for Data Streams;The production of data has grown exponentially in recent years, due to the improvement in the use of sensors, expansion of social networks and data from browsing and shopping online. As a result, the extraction of knowledge from data streams has gained increasing importance on the world stage. However, the data of a streaming is characterized by having infinite volume, a lot of noise and variations over time. In this way, clustering algorithms are used to extract real-time information from this data. In particular, density-based algorithms have gained notoriety in this scenario, for being able to create clusters with arbitrary shapes, which adapt to variations in data characteristics, and also for being able to detect noise. Moreover, the adaptation of these algorithms to the stream allows the data to be read in single pass. Thus, the purpose of this work is to summarize the density-based algorithms for data streams developed between the years 2014 and 2019. In addition to a summary of the operation of the algorithms, they are compared according to quality and performance metrics and, subsequently discussed according to their benefits and limitations. This study is expected to promote a facility for researchers interested in understanding, in a centralized way, the functioning and results of these algorithms.;data stream --- density-based clustering, micro-clustering, evaluation algorithms;en_US;Declined;0;2020;2020-07-22 18:06:14
105613;KIRAN   narang;SRM UNIVERSITY;An Innovative Reliability Allocation Scheme for Component Based Software using Soft-Skills;Software reliability is a main feature for the computation of software quality. Unlike hardware, software does wear out due to its age or rust, but it is unreliability that makes it down, which occurs due to bugs or design faults in the software. Software reliability can be improved by adequate understanding of thoughtful software design, reliability apportionment, and thorough understanding of characteristics of software. Literature survey showed that reliability allocation in an essential task in the software design process. Increasing complexities in software and demand for bug free software has made reliability allocation a mandatory mission during design and planning phase. The component-based approach could potentially overcome difficulties associated with developing and maintaining monolithic software applications. This research proposes an approach to utilize a hardware reliability allocation technique to the reliability allocation of component based system integrating soft set skills. This method can be used to set reliability goals for individual components of component based system and respond to the query “what should be the reliability of individual components to get the target system reliability?” Sensitivity analysis has been done to compare the model with existing model. Finally, an example has been given to illustrate the effectiveness and feasibility of the proposed method.;Component based software, Fuzzy logic, linear programming, Proportionality factor, Reliability apportionment;en_US;Declined;0;2020;2020-07-23 7:00:56
105749;Luiz Galvão   Martins;UNIMEPFATEC;Engenharia de Requisitos na Construção de Compiladores;This article presents an investigation into compiler Requirements Engineering. Almost nothing is found in specialized literature on this topic. Some work was carried out with the aim of employing Software Engineering techniques in the construction of compilers, but these works practically ignore the challenges of systematically defining compiler requirements. As a result of our investigation on the topic, in this article we present a discussion that points out possible ways of carrying out Compiler Requirements Engineering, using techniques already consolidated in the Requirements Engineering area. We also present a classification of the types of non-functional requirements in the compiler domain. To illustrate the process of defining compiler requirements, we present a case study adopting a simple compiler (called the TINY compiler). Throughout the case study description, ways of systematizing the specification of compiler requirements are suggested.;Non-Functional Requirements, Front-End Requirements, Back-End Requirements, Context-Free Grammar (GLC), Compilers;en_US;Declined;0;2020;2020-11-06 13:59:10
106931;Roberval Gonçalves Moreira   Filho;;Optimization In The Context Of The Agricultural Productive Chain, An Application In The Collection Of Milk From The Small Producer;The context of the productive chain of agribusiness, there are a number of optimization problems that are currently being studied in the world. Because the great complexity of many problems, the efforts of research aimed at reducing computational efforts, optimize business profit growth, reducing final product prices and promoting the purchase of better-quality products. Of the various products in the agribusiness production chain, milk has its fundamental role in the Brazilian economy, as it stands out in production and is the basis of several other products. This paper will be displayed an optimization proposal for the products collection in the agribusiness supply chain, focusing on the small rural producer, with an application in the collection of milk with context of state of Rio Grande do Norte of Brazil. The problem under study will be modeled as a variation of the Traveling Salesman problem with Prize collecting where vertices outside the main route will be assigned to another vertex. Is part of proposal of this work, make a study the of metaheuristics, focusing in the metaheuristic Greedy Randomized Adaptive Search Procedure, applied to the problem under study.;;en_US;Declined;0;2020;2020-08-28 10:53:20
107015;Leonardo Henrique   Moreira;University of Brasília;An adaptive three-phase flow with lightweight coordination in multi-agent planning;A key issue in multi-agent planning is the agents’ coordination process that may lead to high execution time. Thus, many works focus on the planning strategy considering mainly the coordination process, agents’ distribution roles, information privacy, and the resources coupling level. Nevertheless, as far as we are concerned, domain-independent models that explore all these factors together leading to an efficient execution solution are missing. Thus, this manuscript presents the Lightweight Coordination Multi-Agent Planning (LCMAP), a novel independent domain model to combine these factors that includes three phases. In the verification phase, eachagent verifies its capabilities of reaching the goals by itself. In the transformation phase, the coordinator selects agents through their capabilities and distributes the goals transforming the original problem into single-agent problems. Finally, the plans individually defined are validated in order to check whether they can be carried out centralized or distributed in parallel. Since the proposed model defines the way agents interact based on their capabilities, it provides a performance gain considering time response and scalability. Experiments regarding loosely and tightly coupled domains were carried out and LCMAP presented gains of 100× in response time and scalability compared to other models.;Multi-agent system, Planning, Scheduling;en_US;Declined;0;2020;2020-08-30 15:37:41
107018;Leonardo Henrique   Moreira;Univerisity of Brasília;An adaptive three-phase flow with lightweight coordination in multi-agent planning;A key issue in multi-agent planning is the agents’ coordination process that may lead to high execution time. Thus, many works focus on the planning strategy considering mainly the coordination process, agents’ distribution roles, information privacy, and the resources coupling level. Nevertheless, as far as we are concerned, domain-independent models that explore all these factors together leading to an efficient execution solution are missing. Thus, this manuscript presents the Lightweight Coordination Multi-Agent Planning (LCMAP), a novel independent domain model to combine these factors that includes three phases. In the verification phase, each agent verifies its capabilities of reaching the goals by itself. In the transformation phase, the coordinator selects agents through their capabilities and distributes the goals transforming the original problem into single-agent problems. Finally, the plans individually defined are validated in order to check whether they can be carried out centralized or distributed in parallel. Since the proposed model defines the way agents interact based on their capabilities, it provides a performance gain considering time response and scalability. Experiments regarding loosely and tightly coupled domains were carried out and LCMAP presented gains of 100× in response time and scalability compared to other models.;Multi-agent system, Planning, Scheduling;en_US;Declined;0;2020;2020-08-30 16:07:47
107033;Rodrigo   Rodrigues;Universidade Federal de Santa Catarina;Integrating neural networks into the agent's decision-making: A Systematic Literature Mapping;AI systems have been playing a crucial role in many different fields of study. Even though connectionist methods, more precisely deep neural networks, are more prevalent nowadays,  many of its limitations have been delaying the deployment of AI systems in relevant areas, such as healthcare, financial, and legal. One of its main criticism relays on the fact that deep neural networks require large data sets, have poor generalization, and lack of interpretability. Specialists believe that the next level of AI will require the integration of these connectionist methods with different AI's fields. Although many different studies explore this research topic, many of them are surveys or do not cover AI's new advances. To fill this gap, a Systematic Literature Mapping is performed, which aims to explore the integration of neural networks into the intelligent agent's decision making. In this study, we analyzed over 1000 papers, and the main findings are (i) many studies employed deep neural networks to define the agent's action or a reward policy, leaving unexplored the integration of these connectionist methods in different stages of the agent's decision making (ii) on the one hand, it was noticed a higher variation on different types of neural networks usage, on the other hand, most of the studies used reactive agents, reinforcement learning agents combined with a multi-agent system approach and (iii) there was an increase in designing simulation AI systems to model behaviors and risk environment scenarios.;intelligent agent, artificial neural network, integration;en_US;Declined;0;2020;2020-08-30 20:22:33
107095;Arthur Alexandre   Artoni;;The most relevant features selection in Autism Spectrum Disorder diagnosis using Machine Learning.;Autism Spectrum Disorder (ASD) is a common disorder, but complex to diagnose, as there are no imaging or blood tests capable of identifying ASD. Various techniques can be used, such as diagnostic scales that contain specific questionnaires formulated by experts, which serve as a guide in the diagnostic process. In this work, Machine Learning (ML) was used in three databases containing results of the AQ-10 tests for adults, adolescents and children, as well as other characteristics that could influence the diagnosis of ASD. Experiments were carried out in the databases in order to list which attributes would be really relevant for the diagnosis of ASD using AM, which could be of great value to students/residents in the field of medicine, as well as doctors who are not specialists in ASD. The experiments showed that it is possible to reduce the number of attributes to just 5, maintaining an Accuracy above 0.9. In the other Database, to maintain the same level of Accuracy, the smallest number of attributes was 7. The Support Vector Machine stood out from the other algorithms used in this work, obtaining superior results in all scenarios.;Autism, Machine Learning, Diagnosis;en_US;Declined;0;2020;2020-08-31 14:42:38
107115;Junia Maisa de Oliveira   Pereira;Universidade Federal de São João del-Rei;Internet of Things for Identification of Burns in Environmental Reserves;Burning in conservation areas is a major concern for environmentalists because of the catastrophicproportions that the fire can achieve. This work shows the development of a module that detects the incidence offires in open areas and sends an alert to a site that the user can access from anywhere. The module is based onthe Internet of Things concept and has an ESP8266 microcontroller, sensors, battery and solar panel. Softwarehas been developed that read the sensors in real time and send the information for storage in the cloud. Forefficiency in large areas, the modules will be installed every 100 meters, covering the perimeter of the area tobe monitored, so that the information between the modules is transmitted in WI-FI Mesh communication. Thesystem meets expectations and delivers results as designed. It is possible to check the values presented by thesensors in the cloud and act from the changes presented, avoiding major environmental catastrophes.;IoT, Internet of Things, Arduino, ESP8266;en_US;Declined;0;2020;2020-08-31 17:34:15
108173;Ariovaldo Caldeira   Bono;Universidade Estadual de Maringá;Analysis of VNS-based algorithms for solving the classroom allocation problem in higher education;This paper addresses the Classroom Assignment Problem (PAS) in an academic institution of higher education. Four versions of algorithms based on the VNS metaheuristic are investigated: classic GVNS and three algorithms found in the literature that implement different techniques to define the order of execution oflocal searches in the neighborhood structure. Experiments applied to instances extracted from the institution’s database showed that the investigated algorithms, compared to the currently used manual solution, obtained better quality solutions. In addition, there were also signs that the order of exploration of the neighborhood is notdecisive for improving the final result of the solution.;;en_US;Declined;0;2020;2020-10-06 9:50:59
108603;Allysson Chagas   Carapeços;Fluminense Federal University;A taxonomy and survey of packet loss diagnosis on wireless networks;Packet losses are a common occurrence on wireless networks. These packet losses can be caused by collisions or simply by the low SNR of the channel, causing a decrease in the network capacity and throughput. The correct distinction and diagnosis of the type of packet loss makes it possible to optimize the use of the medium. For example, it is possible to reduce overhead with unnecessary energy consumed for retransmitting packets. In recent years, some approaches have emerged with the aim of distinguishing and diagnosing the type of packet loss, using different techniques. With the correct distinction of the type of packet loss, there are also proposals for applications of this knowledge for the optimization of subsequent transmissions. However, there are no studies in the literature that organize these approaches. Thus, this work proposes a taxonomy. In addition, the approaches are described in a survey format, according to the branches of taxonomy. In the analysis of the proposals, the evaluation methods used by the authors, feasibility and efficiency of the approaches are discussed.;Packet loss, Collision detection, Collision recognition, Wireless LAN;en_US;Declined;0;2020;2020-10-22 12:24:08
109377;Luiz Gustavo Sousa   Oliveira;;Predição de Proteínas de Bactérias Secretadas Por Vias Não Clássicas;One of the steps that contributes to the development of diagnoses and vaccines for diseases caused by (pathogenic) bacteria is knowing which proteins are secreted by the infectious agent. Related literature shows that these proteins can be secreted via classical and non-classical pathways. But there is no evidence in the literature of an efficient set of characteristics that could indicate that a given protein can be secreted via non-classical pathways. Therefore, this knowledge is fundamental for the control of pathologies. The article presents a prediction methodology for the identification of non-classical bacterial secretion proteins based on neural networks. To this end, a list of bacterial proteins from prokaryotic organisms secreted by currently known non-classical pathways was compiled. They were then cataloged and a training and validation set for the network was created. A bibliographical research was also carried out in order to find probable descriptors/signaling characteristics of this type of secretion. A supervised neural network was created using the WEKA software, which trained the models in order to find the best group of descriptors. The proposed method was evaluated by comparing the developed predictor with two others present in related literature. The results were satisfactory, as they obtained a balanced network with 92.33% assertiveness in the classification. It was concluded that it is possible to obtain an efficient classifier using neural networks by combining certain propensity indices and a balance of samples in the training set.;Neural networks, Bioinformatics, Non-classical secretion, Bacterial proteins;en_US;Declined;0;2020;2020-11-23 23:01:58
109399;Riham   Alhomsi;;The EXPLAINABLE BUSINESS PROCESS (XBP) - An Exploratory Research;Providing explanations to a business process, its decisions and its activities is an important factor to achieve the objectives of the business process and to minimize and deal with any ambiguity in the process that may cause multiple interpretations, as well as to engender the appropriate trust of the users in the process. As a first step towards adding explanations to business process, we present an exploratory study to merge the concept of explainability and business processes, and we propose a conceptual framework to use explainability with business process in a model that we called the Explainable Business Process (XBP). Furthermore, we propose an XBP lifecycle, based on the Model-based and Incremental Knowledge Engineering (MIKE) approach, in order to show in details the phase where explainability fits in the business process lifecycle, noting that we focus on explaining the decisions and activities of the process in its as-is model, without transforming it into a to-be model.;business process, explainability, explainable business process;en_US;Declined;0;2020;2020-11-24 22:35:52
109491;Caio Rafael do Nascimento   Santiago;Universidade Adventista de São Paulo (UNASP);Abordando o problema de balanceamento em redes neurais convolucionais utilizando multitask learning: Um estudo de casos utilizando características faciais binárias;In neural networks, a technique to obtain better results in a classification or regression process is the use of auxiliary attributes (or classes) that help improve the gradient. In convolutional neural networks, this has been widely used in the detection of facial markers (landmarks), which are trained using other binary features. However, this method does not solve the problem of balancing the input data, a common problem in the study of these algorithms, and even makes it more complicated to carry out. In this work, a study was presented comparing the classification of binary characteristics, individually and using multitask learning. The results show an improvement in one of the four classes studied in more depth, and results close to individual training, but still worse than those compared to the use of classifications with balanced data.;Artificial neural networks, convolutional neural networks, balancing, classification, multitask learning;en_US;Declined;0;2020;2020-11-29 23:51:41
110392;Partha   Chakraborty;Comilla University;Identifying Meaning of Word And Phrases From Images Using Tesseract OCR Engine And NLTK;Optical Character Recognition (OCR) is a technology that extracts text from images, scanned files, or PDF documents. The OCR systems generally take input uneditable and unsearchable documents and convert them into an editable and searchable format by extracting text data. As a consequence, It becomes easy for content search and recognition from scanned documents and images. Tesseract OCR engine is considered the best opensource OCR engine at the moment because of its high accuracy in text extraction from scanned documents and images. Here, a system was built with the aid of Tesseract OCR technology for extracting texts from images. The proposed OCR system takes an input of any image and transforms it into a text-searchable document. The system also can conduct word search within the output text and show Bangla meaning of each word. Besides OCR, This framework also incorporates a Natural Language Processing method to classify widely used phrases with Bangla meanings from the output text.;Tesseract, OCR, NLTK;en_US;Declined;0;2021;2021-01-02 8:58:47
110446;João Victor   da Costa;Instituto Federal de Educação, Ciência e Tecnologia do Ceará - IFCE;Comparative Approach of Computational Models Applied to the Traveling Salesman Problem: A Case Study Carried Out in Tourist Points in the Ibiapaba Mountains, CE, Brazil;The region of Ibiapaba mountains, in Ceará, stands out as a region with great tourist potential in the state. Due of this, the present work carried out comparative tests between four algorithms to solve the Traveling Salesman Problem applied to tourist places in the region. The general objective is to verify which of the algorithms obtained the best performance, measured through the execution time, to find an optimal route between a set of tourist sites. The studied algorithms were Brute Force, Ant Colony Optimization, Genetic Algorithm and 2-OPT algorithm. For the tests, a Dell (R) Inspiron (TM) 3442 notebook equipped with a 1.70GHz processor, 4GB of DDR3 RAM and 256GB of SSD storage was used. The Traveling Salesman Problem was modeled using graphs and distances and real locations were captured using Google Maps. The results showed a faster 2-OPT algorithm in all tests, although any of the tested algorithms can be used to perform this function, depending on the number of points of interest. This work can be used as a basis for future optimized tourist itinerary planner applications.;Optmization, Traveling Salesman Problem, Sightseeing Tours, Graphs, Comparission,;en_US;Declined;0;2021;2021-01-05 11:08:55
110768;Luiz Henrique Custódio Mendes   Marques;State University of Maringá;Transient Execution Attacks: An Overview;After the first transient execution attack, such attacks has grown over the years. Transient attacks arise from hardware resources, in fact from lack of security with exposes vulnerabilities. These attacks consist of two phases: (1) an transient channel for data leakage, and (2) a cache side channel for capturing user’s data. The industry and the academy have developed techniques to mitigate hardware vulnerabilities, however despite the efforts it is still possible to exploit several microarchitectures. In this context, this survey presents the concepts related to transient execution attacks, describing the phases, the main works in this area and techniques to mitigate such attack.;Side-channel, transient execution, transient execution attack;en_US;Declined;0;2021;2021-01-19 0:08:44
110816;Aloysio Augusto Rabello de   Carvalho;Universidade Federal de São Paulo;Operating Systems for Embedded Software: A Systematic Mapping of Literature;Embedded systems are constantly growing today, becoming ubiquitous in people's lives, today we have a wide variety of devices, so every day we have new technologies, optimizations and techniques being applied to embedded systems, as they need a high degree reliability and security, generate new challenges in development, this systematic mapping of the literature (MSL) aims to search for signs that show the real impact of using a real-time operating system (RTOS) in embedded software. We conducted an MSL using the ACM Digital Library, IEEE Digital Library, ISI Web of Science, Science @ Direct, Springer Link and Scopus databases, looking for articles that relate RTOS and Embedded Systems to be reviewed.245 articles were found on the topic, we excluded articles that were out of context, maintaining 21 articles on performance, RTOS, embedded system, embedded software development, advantages and disadvantages regarding the use of RTOS. We conducted an MSL with the purpose of identifying the main methods, challenges and solutions in the embedded development. We conclude that we have no articles that make a clear conclusion because none of the articles found shows clearly the relationship between the use of an RTOS in embedded systems and the real impact, advantages, disadvantages and difficulties.;Operational systems, Embedded Software, Embedded System, Real-Time Operating System;en_US;Declined;0;2021;2021-01-20 17:23:34
110946;Paulo Victor Rios   Pinto;UTFPR - Ponta Grossa;Behavioral Signature and Predictability Using ARIMA;Predicting the behavior of a computational entity is a complex process, but it has become afundamental skill for the most efficient use of available resources. The present work presents the process ofcreating and using a Behavioral Signature from the observation of the level of CPU usage of a computer. In thetwo scenarios presented, greater assertiveness was observed in the daily analysis, and the results stabilizedafter the eighth week of testing.;ARIMA, Behavioral Signature, Forecast, Prediction;en_US;Declined;0;2021;2021-01-25 8:47:16
111061;Marcello Scarpel   Contini;Universidade Federal de São Paulo (UNIFESP), Instituto de Ciência e Tecnologia.;Wearable Device Sensing Technologies: A Systematic Literature Review;This work aims to review and discuss reliable technologies for collecting biological and environmental data signals that are appropriated sensors for Wearable Devices (WD) to investigate the more appropriate techniques to monitor the health status of the individuals using them. In addition to this aim we analyzed environmental sensing technologies to identify risks in operation with the monitored individual. The final goal was to define the most appropriate techniques that can be used in the health monitoring and environmental sensing applicable to wearable devices, in terms of accuracy, low cost, and robustness. For this review, four databases have been consulted: IEEE Explore, ACM Digital Library, Springer Link, and Science Direct. A total of 2,598 papers were selected. After applying the systematized review protocol, 28 articles were defined as the source to be analyzed in this review. In order to get an appropriate and manageable number of studies for selection and analysis, a period was defined for the paper selection. The period defined was between 2010 and 2019 for the databases of Springer Link and ACM. For the IEEE database, a shorter publication period was defined, due to a large number of papers returned by the searches in this database (2015 to 2019). The Science Direct database has shown few results for the topic, so its publication period for searches was 2007 to 2019.;Wearable Device, Sensors, Biological Signals;en_US;Declined;0;2021;2021-01-27 22:07:07
111129;Marcello Scarpel   Contini;Universidade Federal de São Paulo (UNIFESP), Instituto de Ciência e Tecnologia.;DEVELOPMENT OF A WEARABLE DEVICE TO PROVIDE ELECTRONIC ASSISTANCE TO SEARCH AND RESCUE DOGS;The dog's ability to find people and indicate their location is biologically efficient however, this work suggested that it is possible to increase dog performance by associating it with technology resources. Dogs are trained to search and rescue, working under the supervision of their handlers efficiently. Also, the handler can identify signs of animal stress or fatigue that may compromise the animal's integrity and thus act to avoid such situations. The goal of this project is to create a wearable device that allows sensing, geolocation, and communication to the search and rescue dog, allowing it to monitor the state of health of the animal and increasing its efficiency in rescue operations and at the same time sending of commands to the dog. This equipment was implemented into a dog vest, thus characterizing a wearable device (WD). Commercial hardware modules were used to equip a tactical vest, and integrated them, using Python program developed on a raspberry PI. The animal used for testing was not trained for search and rescue dog tasks. The validation test was done to verify, in a controlled environment, if the prototype meets the project requirements, which are the capture of sensor information, geographical location, and online video transmission, besides the ability to receive signals to activate devices of command in the animal vest. The results showed that the hardware responded to the software up to a distance of 50m from the trainer without signal loss.;Monitoring, Sensors, Rescue dog, GPS, Raspberry Pi, ECG, wearable device;en_US;Declined;0;2021;2021-01-28 22:40:40
111431;Aloysio Augusto Rabello de   Carvalho;Universidade Federal de São Paulo;Operating Systems for Embedded Software: A Systematic Mapping of Literature;Embedded systems are constantly growing today, becoming ubiquitous in people's lives, today we have a wide variety of devices, so every day we have new technologies, optimizations and techniques being applied to embedded systems, as they need a high degree reliability and security, generate new challenges in development, this systematic mapping of the literature (MSL) aims to search for signs that show the real impact of using a real-time operating system (RTOS) in embedded software. We conducted an MSL using the ACM Digital Library, IEEE Digital Library, ISI Web of Science, Science @ Direct, Springer Link and Scopus databases, looking for articles that relate RTOS and Embedded Systems to be reviewed.245 articles were found on the topic, we excluded articles that were out of context, maintaining 21 articles on performance, RTOS, embedded system, embedded software development, advantages and disadvantages regarding the use of RTOS. We conducted an MSL with the purpose of identifying the main methods, challenges and solutions in the embedded development. We conclude that we have no articles that make a clear conclusion because none of the articles found shows clearly the relationship between the use of an RTOS in embedded systems and the real impact, advantages, disadvantages and difficulties.;Operational systems, Embedded Software, Embedded System, Real-Time Operating System;en_US;Declined;0;2021;2021-02-08 19:58:05
111863;Paulo Henrique Maia   Soares;;Entity Learning to Rank Applied to Brazilian Government Data;With the growth in the amount of information, according to the current governmental transparency in recent years due to law requirements, access to information has become increasingly difficult. Traditional search engines like Google, Yahoo, and Bing return desired information ordered by the relevance of the document before the informed query. The area whose goal is to return relevant documents to the user is known as Information Retrieval which can be aided by machine learning algorithms to improve the ordering of documents, named Learning to Rank (L2R) in this context. There are several algorithms in the literature to solve L2R problems, each one seeks to solve the ranking problem in the best possible way. In the context of government documents, there is a possibility of identifying which are the main entities present in the most relevant documents relevant to a given query. This work aimed to obtain an ordering of the documents available on the Brazilian Government Data Portal using Learning to Rank and extracting information from entities from unstructured, semi-structured, and tabular databases, which are common among the sources available on the Portal. To achieve this goal, we use state-of-the-art techniques to recognize named entities and convex optimization models to model the L2R. The results obtained were superior to the traditional L2R without entities and to the search engines available in the market (Google, Yahoo, and Bing) for not indexing complete information in the Data Portal.;Learning to Rank, Information Retrieval, Machine Learning;en_US;Declined;0;2021;2021-03-03 10:09:32
113196;Michael Tadeu Alves de   Oliveira;;Aspect-Oriented Requirements Engineering - A Systematic Literature Review;Aspect-Oriented Requirements Engineering (AORE) is a research field that provides the most appropriate strategies for identification, modularization and composition of crosscutting concerns. A concern, in the context of AORE, encapsulates one or more requirements specified by stakeholders, and a crosscutting concern is a concern whose requirements cut across requirements of other software concerns. Several AORE approaches have been developed recently, although with different features, strengths and limitations. The aim of this paper is updating a previous systematic mapping on AORE, in which existing AORE approaches were catalogued until 2012. We extended this period from 2011 to march 2021, selecting and analyzing 58 papers, from which we identified 45 AORE distinct approaches.;Aspect-Oriented Requirements Engineering, Systematic Literature Mapping, Requirements Engineering;en_US;Declined;0;2021;2021-04-20 8:51:41
113767;Kranthi   S;;SMNN: SECURED INTRUSION DETECTION APPROACH FOR SDN BASED CLOUD IoT NETWORKS;The rapid proliferation of artificial intelligence via pervasive networking has significantly expanded IoT communication in the cloud world, opening up new attack surfaces for cyber-attacks. Conventional protection techniques are inadequate and inefficient in dealing with protection risks in cloud-depend Internet of Things systems. In this context, NFV, SDN, and machine learning methods  give a slew of benefits to help cloud-based IoT systems overcome cybersecurity concerns. Current methods for dealing against threats in IoT systems based on SDN and cloud platform approaches have significant disadvantages, such as complex classification algorithms and great computational activity for real-time traffic monitoring. We proposed a Spider Monkey Neural Network (SMNN)-depend intrusion detection system for software-defined networking-depend cloud Internet of Things network to fix these problems. The framework detects anomalies and stops malicious traffic as quickly as possible by deploying powerful optimization with Convolution Neural Network. The optimization method is utilized to minimize dimensionality, and the resulting dataset has been fed into a Convolutional Neural Network(CNN). Finally, our SMNN approach outperforms existing trends such as GRU-RNN, AIS, KALIS, and DNN in anomaly detection, mitigation, and issue solving in Cloud IoT networks SDN in terms of accuracy, detection rate, sensitivity, specificity, and precision.;;en_US;Declined;0;2021;2021-05-05 5:33:02
113768;Swati   Kadlag;;Micro Crack Solar Cell Detection Based on Cluster and Region-Based Segmentation;Solar cell degradation diminishes the conversion energy, and this leads to the loss of efficiency in PV. Thus, image-based detection techniques for checking solar cells’ micro-cracks are out coming in recent years. Despite, effective micro-crack detection in the complex background is challenging for Solar Cell. In this paper, Micro Crack Detection using KMeans Dijkstra Shortest (KMDS) Path Algorithm is used to determine micro-crack pixels efficiently by selecting the best boundary. In addition, the efficient Contrast Enhancement filter is used to minimize the effect on background inhomogeneity by removing the interruption of finger noise. Thus, the shape of the line, curve, and star of micro cracks pixel are detected accurately. Despite quantitive evaluation for the accuracy of the proposed segmentation technique in terms of F- measure and the proved our proposed method is better than the existing segmentation methods. They are GMM Gabor, Otsu Canny, and Watershed.;;en_US;Declined;0;2021;2021-05-05 7:15:39
113953;Junia Maisa de Oliveira   Pereira;;Smart Donation: fairer and more comprehensive donations through efficient management;This article describes the development of the platform, the elaboration of the flow, and the impacts o fan innovative donation management platform used by philanthropic entities that help needy families in the city of Conselheiro Lafaiete, Minas Gerais - Brazil. The platform enables efficient resource management, generating fair and comprehensive donations, recognizing the real needs of each family assisted by the entities. The platform demonstrates that the union between entities that wish to exercise philanthropy in the region impacts the survival of the neediest. The project was evaluated from May to December 2020, in which 37 entities were assembled,941 registered families, families from 94 different neighborhoods, totaling 1285 donations.;Innovation, Donation, Modeling, Covid;en_US;Declined;0;2021;2021-05-12 18:41:40
114099;Arpitha   V;R V College of Engineering;A Survey on Low Power Clock Tree Design;Power is a big problem in today's circuits. Clock distributionnetworks, in general, are a critical component of synchronousdigital circuits and a major power user. Since it consumes roughlyhalf of the device's total capacity, clock power dissipation hasbecome a significant problem.In today's low-power digital circuits,Clock gating is now one of the efficient ways to save energy.Theclock tree consumes a substantial volume of chip capacity. In thissurvey paper, various methodologies adopted to design low powerclock tree is addressed and the results of these methodologies arecompared.;Clock tree, clock gating, low power design, clock tree synthesis, Clock buffer;en_US;Declined;0;2021;2021-05-18 2:05:52
114100;Vasuprada   U;Post Graduation student, Computer Science and Engineering, Rastreeya Vidyalaya College of Engineering;DASHBOARDS: CHALLENGES, TRENDS, AND PERFORMANCE MEASUREMENTS;The advent of the digital era paved way for the increasing popularity of the User Dashboard. Along with the increase in the amount of data generated every day, dashboard designs have evolved providing users with multiple opportunities to represent the data creatively. Ideally, a dashboard is developed to fulfill the goal of the user, dashboard designs have become more interactive enabling the users to view and interact with complex data in the form of visualizations. Even though dashboards are widely adopted in various domains they present a lot of challenges that prevent the user from using them to the fullest. Many dashboard designs fail to reach the purpose intended either because of cluttering of the data, or lack of visualization features which makes it difficult for a user to analyze the data in turn losing the potential customers. The research identifies the major components to be considered for designing a dashboard, analyses the latest trend in dashboard design, the challenges in building a dashboard, and performance metrics to be focused on which can effectively understand the user needs and help them in implementing successful dashboards.;Dashboards, User Interface models, Challenges, Visualization, Performance Measurements;en_US;Declined;0;2021;2021-05-18 2:34:56
114274;Fábio Júnior   Griesang;Programa de Pós-Graduação em Engenharia Elétrica (PPGEE) da Universidade Federal do Pampa (UNIPAMPA);Armazenamento de Dados em Nuvem na Administração Pública Federal: Estudo dos Limites e Possibilidades da Legislação Brasileira no que Tange à Segurança da Informação;Cloud computing, a service that allows access to content anywhere and on any computing device, with storage in data centers, has provided information technology users with better functionality in terms of data storage and access. The federal public administration, inserted in the network society, appropriated this mechanism to optimize information in its bodies, with the aim of improving data processing. However, in the context of the Marco Civil da Internet and the General Law for the Protection of Personal Data and other regulations, there is a certain lack in terms of the protection of information generated and archived in cloud services within the scope of the public service. This occurs from the contracting process, which ends up allowing the storage of data in data centers located abroad, to access to data relevant to the daily life of public departments, due to the fragility of the services offered in the national market.;Cloud computing — Federal public administration — Information security;en_US;Declined;0;2021;2021-05-28 18:06:52
114371;Giulio Guilherme   de Souza Simão;;A Library for C++ and Python Based on OpenCV for Calculating the Mahalanobis Distance, the Polynomial Mahalanobis Distance, and the Bhattacharyya Distance;In this paper, we propose a library that implements the Mahalanobis distance, the polynomial Mahalanobis distance, and the Bhattacharyya distance to aid in the development of computer vision applications. We present the importance of these distances in the context of the field of computer vision, and we attest the lack of tools for the use of these distances in computer vision applications through a systematic literature review, concluding that the library is necessary to complement the attested lack of tools. We developed the library in the C++ and Python programming languages, using the OpenCV library as a basis, due to the fact that it was the most mentioned library for both languages according to the conducted literature review. We perform a few simple experiments to demonstrate that possibilities of use of this library are in accord of what is expected.;Computer Vision, Image Segmentation, Digital Image Processing, Mahalanobis Distance, Bhattacharyya Distance, Polynomial Mahalanobis Distance;en_US;Declined;0;2021;2021-06-01 6:22:45
116330;Roderval   Marcelino;UFSC;Controlled atmosphere and dynamic controlled atmosphere for Fuzzy logic-based banana storage;New Information and Communication Technologies are increasingly inserted into many different fields of knowledge, among them agriculture. This insertion results in what is called precision agriculture. The postharvest of bananas requires the application of new technologies to increase storage time and reduce losses. Bananasare highly perishable. Losses in postharvest may vary from 20% to 80% of the crop. Therefore, the purpose of this article is to present the impact of applying new information and communication technologies on the quality and time of banana conservationin a controlled atmosphere. To meet the goals, five treatments for the cold storage process of bananas, refrigerated environment, static controlled atmosphere (2% of O2 and 7% of CO2 ), dynamic controlled atmosphere with static respiratory quotient, dynamiccontrolled atmosphere with dynamic respiratory quotient, and controlled atmosphere with intelligent control (2% of O2 and 7% of CO2) were applied. These five treatments were implemented based on a computing embedded system, sensors and actuators. The intelligent control system used was built with Fuzzy logic techniques.The system controls the respiration gases of bananas and a cold chamber controls the temperature. To validate the research, the storage of pome banana was evaluated in all the treatments to compare the fruit technical requirements and quality. As a result, wecan see the significant increase of banana storage time while maintaining fruit quality. The treatment system with dynamic and intelligent atmosphere control was also considered (2% of O2 and 7% of CO2) the most efficient, reaching achieving a 45-daystorage and thus proving that new technologies promote precision agriculture.;Artificial intelligence, Embedded systems, Postharvest, Respiratory Quotient.;en_US;Declined;0;2021;2021-06-29 17:03:59
116471;Andressa Oliveira   Souza;Universidade Técnológica Federal do Paraná - UTFPR;Aplicação de Algoritmos de Busca em problemas clássicos;In this work, it will be exposed how some search algorithms can be used to solve classical computational problems such as the eight-piece puzzle and the eight-queen problem. For the first puzzle, the algorithms Breadth-First-Search, Depth-First-Search, Greedy Search and A-Star will be used. For the eight Queens problem, we will use heuristic search with A-Star and the Hill Climbing algorithm. At the end, the results obtained and a brief comparison between the tested algorithms will be exposed.;Search Algorithms, Eight-Queens, Puzzle, Hill-Climbing, Greedy Search, Depth-first Search, Breadth-first Search, A*;en_US;Declined;0;2021;2021-07-03 10:30:21
116637;MATEUS   VENDRUSCOLO;Unoesc;IMPACTO DA LGPD PARA MICRO E PEQUENAS EMPRESAS DA REGIÃO OESTE DE SANTA CATARINA;This study evaluated the impact and implementation practices of the General Data Protection Law - LGPD, for micro and small companies in the western region of Santa Catarina. The LGPD was regulated by Law no. 13,709/2018 and amended by project Law no. 1027, of 2020, which came into force on September 18, 2020. The motivation for this research was based on the concepts of Computer and Information Security by the authors Caruso and Stefenn (2006), above all, as it is a current topic with significant relevance to issues related to the protection and confidentiality of personal data. The fact is that information technologies are increasingly enhancing the growing volume and use of information of all kinds, making it necessary to guarantee the protection of this data. To achieve the results of the study, the impacts caused on micro and small companies by the application of the new law, the General Data Protection Law, were analyzed. The application of the new law aims to increase data privacy and oversight of data by companies. Therefore, companies will have to control their data more efficiently, improving oversight and the company's role in the use and control of their corporate data, especially those that contain information from their customers and business partners. Next, a field survey was carried out in which interviews were carried out using an electronic questionnaire, where IT professionals from different segments were willing to respond. The survey showed that 80% of those interviewed knew the new law, but only 55.6% fully complied with the requirements.;;en_US;Declined;0;2021;2021-07-09 9:35:20
117059;Kavitha   M;;DERMOSCOPIC SKIN LESION IMAGE SEGMENTATION USING CLUSTERING WITH COLOUR TRANSFORMATION SALIENCY;Skin cancer is a vital bind in the majority of Western nations including Europe, Australia and America. The huge risk factors related are skin concealing, inadequacy of Sun-lights, climate, age, and inherited. Early identification of skin malignancy can avoid death. Finding of the skin illness depends upon the of the atypical skin region. Various sorts of skin ailment exist now-a-days. Melanoma is the sort skin threat which has grows the greater part of death rate. The early identification and intercession of melanoma include higher changes of fix. Melanoma is recognized by shape, size, concealing and surface of the skin injury of melanoma in the early periods. This paper exhibits how the traditional clustering technique in particular Fuzzy Clustering technique is acted in this skin melanoma picture. This strategy segregates this melanoma in the dermoscopic images effectively. The presentation of this strategy is assessed as far as pixel grouped and time intricacy.;;en_US;Declined;0;2021;2021-07-23 6:11:43
117100;Marco   Inacio;ICenter of Excellence in Analytics, Boa Vista Serviços S.A., BrazilUniversity of São PauloFederal University of São CarlosBudapest University of Technology and Economics, Hungary;Monte Carlo simulation studies on Python using the sstudy package with SQL databases as storage;Performance assessment is a key issue in the process of proposing new machine learning/statistical estimators.A possible method to complete such a task is by using Monte Carlo simulation studies, which can be defined as the procedure of estimating and comparing properties (such as predictive power) of estimators (and other statistics) by averaging over many replications given a true distribution i.e.: generating a dataset, fitting the estimator, calculating and storing the predictive power, and then repeating the procedure many times and finally averaging over the stored predictive powers.Given that, in this paper, we present \textit{sstudy}: a Python package designed to simplify the preparation of simulation studies using SQL database engines as the storage system more specifically, we present its basic features, usage examples and references to the its documentation.We also present a short statistical description of the simulation study procedure with a simplified explanation of what is being estimated by it, as well as some examples of applications.;simulation studies --- machine learning --- python --- sstudy;en_US;Declined;0;2021;2021-07-26 11:16:47
117191;Joshi Shraddha   Diapkkumar;;A Survey on Blockchain Based DDOS Attack for Iot Depend on Software Defined Networking; Internet of Things (IoT) is based on the integration of several processes, like networking, sensing, identification, and computation. Billions of Internet-of-Things (IoT) devices are connected to make available creative ubiquitous services and simplify our everyday tasks (e.g., smart healthcare, smart homes). The effect of Distributed Denial-of-Service (DDoS) attacks is expanding as the number of vulnerable IoT devices. It continues to increase New technologies, such as Blockchain and SDN, creates new possibilities for reliable, cost-effective, scalable, and efficient DDoS attacks to work together in the IoT world. In this paper software-defined DDoS attack affects the online transaction in the Blockchain. Decentralized payments, wealth management, healthcare, and cloud computing, among other applications, have all benefited from blockchain technology. The various types of DDOS attacks in the IoT are identified and defined in this survey. For the first time, we present an extensive and systematic study on the use of blockchain technology in the Internet of Things and explore the advantages of SDN in this paper. Finally, some critical concerns and research problems were addressed in this paper.;;en_US;Declined;0;2021;2021-07-29 2:04:37
118305;Rayana Souza   Rocha;;Preventive Monitoring of Trust in Value Chain Transactions;Value networks represent business models between companies or organizations that generate value for consumers through networked relationships. With advances in market needs, companies have adopted a new value creation strategy. The consequences of these needs led to a notion of creating value in a network, for the co-production of value among stakeholders. The e3value methodology was developed to model a value network composed of actors who create, exchange and consume things of economic value, which is based on the principle of the meaning of economic reciprocity, a "give and take" approach, between actors who exchange objects with an economic value. Trust is a very important component in inter-business relationships. The study and analysis of trust within business networks is prudent, considering that it is an essential component among companies to share knowledge, even if their systems are connected and there is technology sharing, as the modeling used by e3value does not deal with subjective values, as is the case with trust, because of the difficulty of accurately quantifying the economic return of the stakeholders involved.;;en_US;Declined;0;2021;2021-09-12 11:01:53
118998;Ronny   Santana;Universidad de Guayaquil, EcuadorEscuela Superior Politécnica del Litoral, EcuadorUniversidad Nacional de La Plata, Argentina;User Experience Challenges of Smart Glasses in STEM Students: A Systematic Literature Review;This study aimed to systematically investigate the studies in which smart glasses was used on STEM educational settings through a systematic literature review (SLR) that identified gaps and opportunities for future research related to Human-computer interaction. This SLR is a complementary study to a systematic mapping study (SMS) that focuses on the collection, analysis and summaries of papers we have recently conducted. To this end, we conducted a SLR of studies published between 2014 and 2020, the obtained data were analyzed by researchers using content analysis method, initially identifying a total of 485 studies. After meticulously reviewing and analyzing this pool of studies, 51 studies were selected and then classified based on their research, contribution and educational setting. Our systematic review also confirmed that the vast majority of studies with smart glasses—both within and outside educational settings, has focused on medical education, telemedicine and medical training. This suggests that there is potential for exploiting smart glasses and related technologies in a larger variety of educational settings. The implications of this review are expected to open a gateway for many productive research works in the field of HCI concerning on UX with smart glasses within the context of STEM education.;Human-computer interaction, Smart glasses, STEM students, User experience, Systematic literature review;en_US;Declined;0;2021;2021-10-02 21:56:58
120096;Kavitha   M;;FCM LEVEL SET TECHNIQUE FOR SEGMENTATION ON DERMOSCOPIC SKIN LESION IMAGES;-   As of late, a plethora of patients with melanoma a harmful skin cancer has increased dramatically. Henceforward, it is required to establish a computer-aided diagnosis model to make more efficient its primary detection for effectual treatment. Nowadays, myriad hospitals and medical specialty clinics are using the computer-based identification systems for detection of either carcinoma or melanoma. Image segmentation is vital task in analysing dermoscopy image, since the skin lesion border extraction provides significant signs for precise designation. Melanoma is the sort skin threat which has grows the greater part of death rate. It is recognized by shape, size, concealing and surface of the skin injury of melanoma in the early stages. This paper exhibits about the Fuzzy Clustering technique and then Level set method is acted in this skin melanoma picture. This strategy segregates this melanoma in the dermoscopic images effectively than any classical clustering method. The presentation of this strategy is assessed as far as time intricacy.;Fuzzy Means, Level Set, Melanoma, Clusters, dermoscopic image;en_US;Declined;0;2021;2021-11-17 2:51:32
120186;Santiago   Tarazona;Maestro en Docencia Universitaria en la Universidad Nacional de Ingenieria Facultad de Ingenieria Industrial y de Sistemas;El Sistema de mantenimiento en el Data Center del Banco de la Nación. Administración y desarrollo del Programa de Mantenimiento, año 2018.;The maintenance system in the Data Center of the Banco de la Nación. Administration and development of the Maintenance Program, year 2018.;;en_US;Declined;0;2021;2021-11-22 12:10:28
120221;Jose Manuel   Cassola;Universidad Central "Marta Abreu" de Las Villas;Integration of Visualization Techniques in the Travelling Salesman Problem and the Vehicle Routing Problem using Genetic Algorithm;The optimization problem solving process is an ever-evolving science. The visual interaction techniques to support metaheuristic algorithms represent an attractive variant in its progress, thanks to the advantages that the analysis and interaction of a user at runtime of an algorithm can offer. This article proposes a series of interactions and visualizations integrated into a variant of the Genetic Algorithm metaheuristic with the aim of optimizing the results when solving the Travelling Salesman Problem and the Vehicle Routing Problem. This procedure resulted in the development of a software tool to which the pertinent tests were carried out, showing the efficiency of the achieved integration and the superiority of the results obtained with the assistance of the user.;Genetic algorithm, travelling salesman problem, vehicle routing problem, interaction, visualization;en_US;Declined;0;2021;2021-11-23 13:34:36
120290;Siraj Rashid   Pathan;Research scholar, Dept of Electronics & computer science engineering, Amity University Rajasthan India;Research on Computational Intelligence Algorithm in LTE Channel Estimation;Precise  modelling and accurately estimating Long-Term Evolution (LTE) Channel is essential for numerous applications like video streaming , efficient use of bandwidth and utilization of power because data traffic is increasing continuously with advancement in Internet of things   .In this paper, we design Computational Intelligence(CI) Algorithm based model which is able to  improve Channel Estimation based on received signal . we consider two different Algorithms 1) GA Known as Genetic Algorithm and 2) PSO Particle swarm optimization Algorithm  to work on Discrete as well as Continuous Long Term Evolution (LTE) drive test data, In contrast to previous work that is focused only to design model to estimate channel using traditional Minimum mean Square error (MMSE) and Least Square (LS)algorithm. In particular we consider LTE operating in 5.8 GHz range .The design model aims to Improve  Channel  estimation by reducing mean square error of  LS and complexity of MMSE respectively. Pilots are placed randomly and send along with data to obtain channel knowledge which help at the receiver to decode and estimate channel where LS,MMSE combined with Taguchi GA and PSO respectively.CI based model performance has been calculated  as of Bit Error rate (BER) ,Signal to Noise Ratio , Mean Square Error. Proposed  model BER achieve desired gain of 2.4 dB and 5.4 dB as compare to MMSE and LS algorithms, respectively;Genetic Algorithm (GA), Particle Swarm Intelligence(PSO), Long Term Evolution (LTE), Minimum Mean Square Error (MMSE), Least Square (LS);en_US;Declined;0;2021;2021-11-25 7:01:03
120358;Siraj Rashid   Pathan;Research scholar, Dept of Electronics & computer science engineering, Amity University Rajasthan India;A Novel Computational Intelligence Algorithm Based LTE Channel Estimation;Precise modelling and accurately estimating Long-Term Evolution (LTE) Channel is essential fornumerous applications like video streaming , efficient use of bandwidth and utilization of power because datatraffic is increasing continuously with advancement in Internet of things .In this paper, we designComputational Intelligence(CI) Algorithm based model which is able to improve Channel Estimation based onreceived signal . we consider two different Algorithms 1) GA Known as Genetic Algorithm and 2) PSO Particleswarm optimization Algorithm to work on Discrete as well as Continuous Long Term Evolution (LTE) drivetest data, In contrast to previous work that is focused only to design model to estimate channel using traditionalMinimum mean Square error (MMSE) and Least Square (LS)algorithm. In particular we consider LTEoperating in 5.8 GHz range .The design model aims to Improve Channel estimation by reducing mean squareerror of LS and complexity of MMSE respectively. Pilots are placed randomly and send along with data toobtain channel knowledge which help at the receiver to decode and estimate channel where LS,MMSEcombined with Taguchi GA and PSO respectively.CI based model performance has been calculated as of BitError rate (BER) ,Signal to Noise Ratio , Mean Square Error. Proposed model BER achieve desired gain of 2.4dB and 5.4 dB as compare to MMSE and LS algorithms, respectively.;Genetic Algorithm (GA), Particle Swarm Intelligence(PSO), Long Term Evolution (LTE), Minimum Mean Square Error (MMSE), Least Square (LS);en_US;Declined;0;2021;2021-11-28 6:03:01
120597;Bruno Bastos   Stoll;;Framework para Visualização de Dados através de PLN;Tools are becoming easy and functional as their processes are designed to be simple and agile. In this way, the interaction facilitated by natural texts has grown and is present in people's daily lives. However, there is still a need for developments in the academic scenario to help teachers obtain information from their classes through text-based searches. Within this context, we delimited the production of a framework with the aim of facilitating teachers to obtain information through textual expressions to consult academic data. To evaluate the proposal, four different consultation scenarios were carried out. The proposed approach preliminarily presents good results, with the possibility of having a better understanding of the courses in order to assist in making pedagogical decisions.;;en_US;Declined;0;2021;2021-12-06 13:30:50
120713;Kavitha   M;;FCM LEVEL SET TECHNIQUE FOR SEGMENTATION ON DERMOSCOPIC SKIN LESION IMAGES;As of late, a plethora of patients with melanoma a harmful skin cancer has increased dramatically. Henceforward, it is required to establish a computer-aided diagnosis model to make more efficient its primary detection for effectual treatment. Nowadays, myriad hospitals and medical specialty clinics are using the computer-based identification systems for detection of either carcinoma or melanoma. Image segmentation is vital task in analysing dermoscopy image, since the skin lesion border extraction provides significant signs for precise designation. Melanoma is the sort skin threat which has grows the greater part of death rate. It is recognized by shape, size, concealing and surface of the skin injury of melanoma in the early stages. This paper exhibits about the Fuzzy Clustering technique and then Level set method is acted in this skin melanoma picture. This strategy segregates this melanoma in the dermoscopic images effectively than any classical clustering method. The presentation of this strategy is assessed as far as time intricacy.;;en_US;Declined;0;2021;2021-12-10 4:27:48
120714;Kavitha   M;;SKIN LESION IMAGE SEGMENTATION BY JSEG WITH RKM CLUSTERING TECHNIQUES;Present have been myriad activities to represent conservative telemedicine over the world. Myriad reviews portrays that Artificial Intelligence accomplishes recovering than humanoid in certain health care task namely diagnosis of cancers. However, there are myriad challenges for Artificial Intelligence in health care field. In its quintessence, Machine Learning took care of its foundation in the investigation of pattern recognition and computational learning. Fundamentally, it portray as two sorts of methodology namely supervised and unsupervised. Detection of skin lesions border accurately is an imperative initial stage for computer aided diagnostic systems. For segmentation, unsupervised clustering methods are providing the hopeful outcomes. This paper proposes a new tactic titled as skin lesion image segmentation by JSEG with enhanced clustering techniques. The unsupervised clustering techniques namely K-Means and Robust K-Means are performed in JSEG method. This procedure has been separate out the lesion in the images properly. Experimental outcomes could be analyzed in different setups.;Cluster, K-Means, RKM, Region growing, hit ratio region, class-map, quantize, segmentation;en_US;Declined;0;2021;2021-12-10 4:41:35
120866;Emerson Severino   de Oliveira Ramos Ferreira;;Uma Revisão Sistemática sobre Avaliação do Consumo de Energia em Nuvem das Coisas;IoT devices are used in various types of industry verticals and consumer markets. In 2020 there were around 8 billion connected devices around the world, where the forecast for 2030 is to have more than 25 billion connected devices. Furthermore, the global market for IoT devices in the government sector will transact around $21 billion in 2022, where more than 50% of this amount will be for external surveillance equipment. Which represents an increase of 36% compared to 2020. Nowadays, a major research trend is the combination of Cloud Computing and Internet of Things (IoT), thus creating the concept of Cloud of Things (CoT). CoT aims to offer computing resources in a diffuse and ubiquitous way, in which IoT characteristics are offered as services through Cloud Computing. In this way, CoT acts as a middleware that interacts between things and users/applications in a transparent way, eliminating complexity, which facilitates the development of applications that interact with intelligent objects, and can be used in areas such as Healthcare, Smart Cities , Smart Home, Video Surveillance, Smart Mobility, Smart Energy, among others. In CoT environments, the large amount of communication and data transmission carried out by IoT devices degrades the energy efficiency of these environments, affecting the quality of services. In this way, this work describes a systematic review of strategies for evaluating energy consumption in the cloud of things. This systematic review aims to bring together published studies related to the assessment of energy consumption in IoT and the cloud of things, for an analysis of the methodologies used in these works and to propose future work on the assessment of energy consumption in the cloud of things.;;en_US;Declined;0;2021;2021-12-15 20:01:19
120922;Sara Guimaraes   Negreiros;;sgPIP: Management System of the Institutional Academic Permanence Program;The development of web applications has grown complementary in recent years and is mainly used to manage processes and information to streamline and automate processes. In this work, a web application with technologies such as ReacJS, nodeJS and mongoDB is proposed to manage the academic scholarships offered by UFERSA’s Institutional Academic Permanence Program (PIP). For the management of the team, it uses aspects of the Scrum agile methodology. The application of this work arose due to the PIP selection process being carried out, mainly, in presence stages. A selection of jobs therefore becomes a slow process with a high demand for manual jobs and with several redundancies. Thus, the Management System of the Institutional Academic Permanence Program (sgPIP) developed in this work proposes to integrate the facilities associated with the selection of disks and control of the selection processes in a single web application.;;en_US;Declined;0;2021;2021-12-17 15:18:33
121403;Seyed Saeed   Hamidi;Department of Computer Engineering, Sari Branch, Islamic Azad University, Sari, Iran;Diversity Efficacy on Consensus Clustering;Consensus clustering is a technique for increasing the robustness and accuracy of clustering results. Essentially, this technique generates base clusterings and combines them into a consensus solution whose quality depends on the diversity of base clusterings and the performance of the consensus function. Generating base clusterings concerning quality and diversity has a determinative role in enhancing the quality of consensus results. In this study, novel techniques were used to generate diverse base clusterings for both low and high-dimensional datasets, and also new criteria were proposed to compute the diversity of base clusterings concerning quality. The impact of different levels of diversity on consensus functions was investigated. Experimental results showed that the proposed methods generated diverse base clusterings.;Quality, Diversity, Diversity generation, Clustering ensemble, Consensus clustering;en_US;Declined;0;2022;2022-01-06 18:22:43
121450;abderrahmane   laraqui;Research in Computer Sciences Laboratory, Ibn Tofail University, Morocco;FAST MOSAICING METHOD BASED ON IMAGE RESIZING PRE-PROCESSING;In recent years, mosaic images have found great success thanks to the increasing development in the field of imaging as well as the technological evolution of computer systems (camera, mobile, etc.). Mosaic images are obtained by capturing multiple images of a scene from different exposures. The process incorporates several steps, each of which requires resources and execution time depending on the size, quality and resolution of the images used. In this paper, we propose a new image mosaic technique that significantly reduces the execution time. The idea is to apply the stages of registration and search for the best inliers, necessary for the calculation of the geometric transformation, to the miniature of images. This allows the minimization of the overall processing time without altering the quality of the results. The experiment, on a database of images, shows that the proposed algorithm provides rapid results compared to similar methods. Also, we have extended our technique to generate 360 ° panoramic images.;stitching, mosaic, fast, sift, best inliers;en_US;Declined;0;2022;2022-01-10 10:38:15
121591;Kavitha   M;;FCM LEVEL SET TECHNIQUE FOR SEGMENTATION ON DERMOSCOPIC SKIN LESION IMAGES;As of late, a plethora of patients with melanoma a harmful skin cancer has increased dramatically. Henceforward, it is required to establish a computer-aided diagnosis model to make more efficient its primary detection for effectual treatment. Nowadays, myriad hospitals and medical specialty clinics are using the computer-based identification systems for detection of either carcinoma or melanoma. Image segmentation is vital task in analysing dermoscopy image, since the skin lesion border extraction provides significant signs for precise designation. Melanoma is the sort skin threat which has grows the greater part of death rate. It is recognized by shape, size, concealing and surface of the skin injury of melanoma in the early stages. This paper exhibits about the Fuzzy Clustering technique and then Level set method is acted in this skin melanoma picture. This strategy segregates this melanoma in the dermoscopic images effectively than any classical clustering method. The presentation of this strategy is assessed as far as time intricacy.;Fuzzy Means, Level Set, Melanoma, Clusters, dermoscopic image;en_US;Declined;0;2022;2022-01-15 17:08:11
121631;Naoufal   Ainane;C3S Laboratory, CED Engineering Sciences, Hassan II University, Casablanca;Monitor Health for Smart City (MHSC);-Background: Health in the smart city is a very specific field which has experienced very significant progress using technological means such as big data and the Cloud, not to mention IOT. Hospitals are now managed by IT in all their processes. The development of smart cities can help improve the health of every individual. Sensors, mobility, digitization and big data are all tools today that can anticipate, frame and care for patients in smart cities.More and more, smart cities have many innovations to improve the lives of inhabitants but also their health, directly or indirectly. From now on, patients can consult their doctors via video (smartphone, desktop computer, tablet) benefiting from the latest 5G(1) internet technologies.-Methods: In this article, we propose a framework MHSC (Monitor Health for Smart City) for monitoring the state of health of an individual in a smart city. Thanks to this framework, the inhabitants of the city will have their state of health constantly monitored and will receive notifications about their state of health.To detect the state of health we propose a concept based on 5 parts: geolocation, facial recognition(2), voice recognition(3), IOT and artificial intelligence.Every person in smart city will receive instant notifications in the event that his health is in danger, this information will be sent at the same time to the medical profession for treatment and decision making.We will apply our framework MHSC to the COVID19(4) case in order to have very recent feedback on our methodology for observing and preventing patients in smart cities.-Results:  Until now, we have been able to set up the mobile application which will be deployed to users (via App Store or Google Play Store). Also, we have set up a web portal in order to have more cough samples anonymously. Finally, we were able to test our COVID19 detection algorithm on cough samples. Despite our initiative to collect data from COVID19 patients, we are unfortunately faced with medical confidentiality and the protection of patients' personal data, which has a visible impact on research in this field.-Conclusions: The information collected and analyzed in the proposed system is used to monitor the health status of smart city residents at home or outside their homes.We were able to test our framework, which is the detection of the state of health by analyzing the voice of the inhabitants of a smart city, taking the example of Covid19, the result was successful.;Smart city, health, facial & voice recognition, IOT, artificial intelligence;en_US;Declined;0;2022;2022-01-17 12:34:58
121907;Sara Guimaraes   Negreiros;;SysADL modeling language experience report for documentation of embedded systems with arduino;This article discusses how an embedded system was documented using the SysADL software architecture modeling language. Embedded systems are characterized by the automation of activities such as irrigation, monitoring, space exploration, for example. The embedded system presented in this article was used on a PET rocket launch pad to automate the launch and insertion of fuel into the rocket. Given the relevance of these systems, it is necessary to ensure their maintainability with appropriate documentation techniques, so with SysADL it was possible to define the structural view and the behavioral view for the system under study. In this article we present how these systems were modeled using SysADL as well as the difficulties encountered and discussions about the use of SysADL for embedded systems with Arduino.;;en_US;Declined;0;2022;2022-01-28 22:40:39
122022;Ernanny   Figueiredo;;Classification of sentiments in e-commerce customer reviews using artificial neural network;Currently millions of people openly share, on social networks and comment pages, their opinions about products, services, etc. Several segments of the business market are interested in extracting information from this medium that is relevant to their business. One type of desired information is the identification of feelings expressed by registered users in the form of opinions, as this demonstrates acceptance or rejection of the subject. Obtaining this information manually is unfeasible due to the large amount of texts and that is where machine learning techniques come in, allowing you to organize, manage and extract knowledge, allowing the user of the solution to improve their business strategy. This article proposes an approach to the text classification problem applied to sentiment analysis, to identify the polarity of the text, discovering whether the opinion is positive or negative. The literature indicates several tools with different classifiers, and those used in this work are those whose built models incorporate classifiers based on artificial neural networks. Models were built and their performance evaluated for a particular group of data with texts written in Portuguese. The impact of the text pre-processing phases on the models was also investigated.;Text classification, neural networks, machine learning;en_US;Declined;0;2022;2022-02-02 20:28:29
122098;Tarcísio José Rolim   Filho;;Performance Modeling of Big Data Applications in Private Clouds;Abstract: Cloud computing enables scalability at a lower cost to data analysis in a big data environment. This paradigm considers the dimensioning of resources to process different volumes of data, minimizing the big data handling response time. This work proposes the evaluation of the performance of big data environments in the private cloud through a methodology and a stochastic model the proposed methodology considers objective activities and performance modeling to assess Hadoop cluster performance in the private cloud. The stochastic model represents sending datasets to the Hadoop cluster with different configurations, and these infrastructures are represented through stochastic Petri nets. A case study based on the CloudStack platform and Hadoop cluster are adopted to demonstrate the feasibility of the methodology and the proposed model platform. An analysis based on the feelings of Twitter users who made posts using words that people who emerge from depression was performed to generate the workload. The capture of posts from this social network was performed according to the sentiment analysis parameters researched in the literature and on the website of the Ministry of Health of the Brazilian federal government.;Cloud Computing — Big data — Hadoop — Performance Evaluation — Stochastic Petri Net.;en_US;Declined;0;2022;2022-02-06 8:36:18
122245;Nur Aini   Rakhmawati;Department of Information Systems, Institut Teknologi Sepuluh Nopember Surabaya, Indonesia;Website Main Content Extraction Using Template-Based Approach and Naïve-Bayes Classification;Every web page will have the main content. The main content is a section, segment or block that contains text or multimedia on a single web page. Important information about local governance generally lies within the main content, thus the need for web content extractor to extract that information. To solve these problems, this research combines two approaches that already existed, template-based approach and machine learning approach using Naïve-Bayes Classifier. Generally, previous research that has been conducted is using one type of approach it is either using a template-based approach or using a machine learning approach.  The result shows that with combining two types of approaches, the model could identify or recall all nodes that contain the main content.;web content extractor, template-based, naïve Bayes;en_US;Declined;0;2022;2022-02-12 10:31:44
122275;Naoufal   Ainane;;Monitor Health for Smart City (MHSC);-Background: Health in the smart city is a very specific field which has experienced very significant progress using technological means such as big data and the Cloud, not to mention IOT. Hospitals are now managed by IT in all their processes. The development of smart cities can help improve the health of every individual. Sensors, mobility, digitization and big data are all tools today that can anticipate, frame and care for patients in smart cities.More and more, smart cities have many innovations to improve the lives of inhabitants but also their health, directly or indirectly. From now on, patients can consult their doctors via video (smartphone, desktop computer, tablet) benefiting from the latest 5G(1) internet technologies.-Methods: In this article, we propose a framework MHSC (Monitor Health for Smart City) for monitoring the state of health of an individual in a smart city. Thanks to this framework, the inhabitants of the city will have their state of health constantly monitored and will receive notifications about their state of health.To detect the state of health we propose a concept based on 5 parts: geolocation, facial recognition(2), voice recognition(3), IOT and artificial intelligence.Every person in smart city will receive instant notifications in the event that his health is in danger, this information will be sent at the same time to the medical profession for treatment and decision making.We will apply our framework MHSC to the COVID19(4) case in order to have very recent feedback on our methodology for observing and preventing patients in smart cities.-Results:  Until now, we have been able to set up the mobile application which will be deployed to users (via App Store or Google Play Store). Also, we have set up a web portal in order to have more cough samples anonymously. Finally, we were able to test our COVID19 detection algorithm on cough samples.Despite our initiative to collect data from COVID19 patients, we are unfortunately faced with medical confidentiality and the protection of patients' personal data, which has a visible impact on research in this field.-Conclusions: The information collected and analyzed in the proposed system is used to monitor the health status of smart city residents at home or outside their homes.We were able to test our framework, which is the detection of the state of health by analyzing the voice of the inhabitants of a smart city, taking the example of Covid19, the result was successful.;Smart city, health, facial & voice recognition, IOT, artificial intelligence;en_US;Declined;0;2022;2022-02-14 7:16:57
122303;Helder Mateus dos Reis   Matos;Universidade Federal do Pará;Enadevis: a web tool for performance analysis of the Computer Science course at UFPA at ENADE;This article presents the development of a web application named Enadevis, that allows to generate a performance analysis of the ENADE exam for the Computer Science bachelor course at the Federal University of Pará. The web tool aims to provide a set of information visualization panels obtained from the application of data science technologies in ENADE microdata, which facilitates the comprehension of the exam assessment to the general public concerned with the course performance throughout the years. It can be highlighted that the good understanding of ENADE's assessment results significantly contributes to the elaboration of a course pedagogical planning aligned with the national requirements, enabling the discovery of areas in need of improvements, for example. The tool can be generalized for other undergraduate courses through the pre-processing of their microdata, provided by the Ministry of Education.;Enade, Information Visualization, Computer Science, Web Application;en_US;Declined;0;2022;2022-02-15 2:40:29
122344;Matheus Yukio   Kumano;University of São Paulo;Unconstrained face recognition using Convolutional Neural Network: A comparative study;Facial recognition has attracted interest from the scientific community, it provides a discreet and non-intrusive way of facial detection, identification, or verification without the need for knowledge or individual consent. An important milestone in the development of facial recognition techniques was achieved by the introduction of a deep learning method, with emphasis on Convolutional Neural Networks. The use of  Convolutional Neural Networks for facial recognition in an uncontrolled environment has generated several works in the literature. However, there is a difficulty related to the reproducibility of these works, there is a lack of a comprehensive comparative study covering architecture that presents the advantages and limitations of each architecture for facial recognition. This article addresses six different Convolutional Neural Network architectures for facial recognition in an uncontrolled environment. The LFW database and two evaluation protocols were used. Results show that the use of Resnet50, proposed in 2015, obtained the best accuracies in both protocols.;Deep Learning, Convolutional Neural Networks, Machine Learning;en_US;Declined;0;2022;2022-02-15 22:03:13
122844;Alexandra Virgínia Valente da   Silva;Mestra em Ciências com ênfase em Matemática, Estatística e Computação pelo Instituto de Ciências Matemáticas e Computação (ICMC – USP).;INTELIGÊNCIA ARTIFICIAL NA EDUCAÇÃO: O APRENDIZADO DE ALUNOS DO DOUTORADO COM DEFICIÊNCIA VISUAL POR MEIO DE RECURSOS COM TECNOLOGIA PLN – UM ESTUDO DE CASO;The term educational “inclusion” for a student with visual impairment in Higher Education begins to have real meaning when he or she feels parcipatory. No teaching process is not enough to include in a regular institution, it requires special conditions for your stay and completion of the course. It is necessary that education be respected as conditions of accessibility of the peculiarities that a special requirement. In this panorama, a lack of special teaching resources emerges in a fundamental way, as it is taken into account that the visually impaired will certainly have their development hampered in the formation of key concepts for learning. Artificial Intelligence (AI) equipped with PLN (Natural Language Processing) technology offers an excellent opportunity to improve this situation. The objective was to verify and show the importance of AI in the learning and daily life of a visually impaired student taking an in-person course. In the data collection stage, we applied direct observation, self-report and interview. The results were evaluated by crossing more complete responses to extract more information. Results of social tools, despite some difficulties in using AI by the visually impaired, makes them more independent in studies and naization. We conclude, according to the panorama outlined, how universities invest in teacher training to deal with the demands proposed within the scope of Inclusive Education. This article is an excerpt from a doctoral thesis in Educational Sciences carried out in Ciudad del Este in Paraguay.;Accessibility for the visually impaired — Artificial Intelligence in Education — Intelligent Virtual Assistants — Natural Language Processing (NLP);en_US;Declined;0;2022;2022-04-03 23:19:26
123014;Dhiego   Araújo;Instituto Federal de Educação Ciência e Tecnologia de Brasília;Uma Rede Neural Artificial para Aproximar Superfícies Mínimas com Fronteira Fixa;Minimal surfaces appear in different contexts. In this work, we will approximate the solution of the Euler-Lagrange Equation associated with the Minimum Surfaces of Euclidean Space which are, locally, the graph of a function of two variables. Through the approach employed by Lagaris, this problem is reduced to approximating the solution of a non-linear Partial Differential Equation (PDE) with Dirichlet Boundary Conditions. This implies that the boundary of the surface to be approximated is fixed and does not vary over time. We use two known Minimum Surfaces to compare the performance of the developed algorithm and use it to determine the approximation of the solution for different fixed boundaries.;;en_US;Declined;0;2022;2022-03-21 12:23:28
123126;flavia   ximenes;ufrpe;F,X A Percepção do Professor da Educação Básica no Contexto do Pensamento Computacional;Computational Thinking (CP) is considered one of the skills necessary to live and prosper in contemporary society. It is based on Computer Science techniques, helping to solve problems. Regarding this aspect, it is necessary to understand how PC skills can be disseminated in the educational space. In this context, we sought to analyze how CP is inserted in the pedagogical practices of basic education teachers. To this end, there was a need to analyze “The perception of basic education teachers about computational thinking”. Where we seek to understand the teacher's perception in relation to PC knowledge and how they use it in their daily classroom. To this end, it was necessary to investigate whether CP is understood by teachers, since the Common National Curricular Base (BNCC) recognized the importance of working on computational language in 4 areas. Regarding this aspect, it is necessary to understand how the skills and applicability of PC can be disseminated in the educational space. Among the results identified, it can be reported that there are indications that CP is still little known and explored in the educational context analyzed. And, future actions may favor increasing the awareness of teachers who can use this knowledge in the CP theme.;;en_US;Declined;0;2022;2022-03-24 13:33:17
123542;G Jaya Raju   ;Sri Vasavi Engineering college;DEEP BELIEF NEURAL NETWORK (DBNN) BASED CATEGORIZATION OF UNCERTAIN DATA STREAMS;In the data mining era, the research field is paying much attention to data stream mining, which offers a substantial influence on a variety of applications such as networking, wireless communications, education, economics, weather prediction, financial sector, and so on. Moreover, processing of this uncertain data stream faces two major challenges which are computational difficulty and long process time of data. Thus to overcome this work proposes a technique that employs a deep belief neural network to categorize uncertain data streams. Initially, this work utilized a hybrid method that combines ensemble, grid, and density-dependent clustering approaches to acquire the local optimum value in uncertain data streams. Furthermore, for classification, a Deep Belief Neural Network (DBNN) has been used. As a result of mining, target semantics or chunks will be obtained from the classified data. The suggested technique attains well, and its effectiveness has been assessed in terms of time as well as accuracy. Thus, our proposed method outperforms compare to the existing techniques.;;en_US;Declined;0;2022;2022-04-06 7:44:33
123809;Aleksandra   Varygina;Amur State University;TECHNICAL AND ECONOMIC MODEL OF THE CONDUCTOR CROSS-SECTION FOR ACTIVE-ADAPTIVE ELECTRICAL NETWORKS;There can be observed a gradual transition of the electric power industry to the innovative technology platform Smart Grid around the world in Russia it is done on the platform of an intelligent electrical grid with an active-adaptive network, which becomes one of the most important subsystems. There are new elements of power transmission lines, among which new generation conductors (NGC) are being actively introduced. However, the high cost of innovations in the power grid complex makes their use quite slow. The conductor cross-section is the most significant parameter of the power transmission line it determines its main technical and economic indicators. The problem of choosing economically reasonable conductor cross-sections stems from the need to ensure the required level of reliability of power transmission lines, determine the most effective way to invest money and reduce the cost of electricity transportation. Modern requirements for the feasibility study of design solutions increase the economic significance of the problem to determine the economically feasible conductor cross-sections for the power transmission lines. At the same time, there is no method for choosing the optimal conductor cross-sections of NGC. An incorrect choice of the conductor brand and its cross-section can lead to unjustified costs for the construction and reconstruction of power transmission lines and increase the cost of electricity transmission. In the article there is the analysis of existing methods of project decisions feasibility it was taken as the basis to develop the technical and economic model of a conductor cross-section for active-adaptive electrical grids taking into account the thermal model of the conductor and the random nature of the change of current running through the power transmission lines.;Smart Grid, active-adaptive electrical networks, conductor cross-section, technical and economic model, discounted costs, current load;en_US;Declined;0;2022;2022-04-18 19:02:43
124738;Ge   Meng;Jiangxi University of Finance and Economics;ARTIFICIAL INTELLIGENCE OF MUSIC;In order to study the formation of the IT sector in Russia, the article identifies and discusses the main problems of introducing information technologies into the economic and social life of society: poorly developed legislative framework, institutional problems, lack of investment. Outlines the fundamental and applied values ​​of defining the essence and structure of musical intelligence, clearly outlines methodological approaches, each of which can give its own substantiation of the potential of music in the intellectual development of a person. The question is raised about the educational implications of current ideas about the structure of musical intelligence.;contemporary art, media culture, futurology, post-industrial society, artificial intelligence, music, technology, internet, music creation;en_US;Declined;0;2022;2022-05-24 17:24:28
125409;Sergey   Kuznetsov;Ulyanovsk State Technical University;RESEARCH OF INTERACTION INTERFACE OF THE INTERNET OF THINGS "MACHINE-NATURE" WITH THE ENVIRONMENT OF A SMART HOME;The interfaces of the Internet of Things represent its foundation, and due to this there are many possibilities for its use. The purpose of the work is to show, using the example of a smart home system, the relationship of objects within the system with the external environment. The end result of the research will be the indication of smart devices that operate within the system. The scientific novelty of the work lies in the fact that the Internet of Things is currently one of the world's leading trends, generating from this increased interest in itself. More and more attention is paid to this area, since the Internet of Things is important for the economy, sociology, politics, as well as for the cultural development of the country. Many of the leading countries such as China, USA, Germany, Great Britain are engaged in development in this area. Firstly, this will allow bringing world markets to a new level, and secondly, humanity will come to a new stage of its existence. Through the innovations of digital devices, we can observe how our lives and everyday life, to which we are so much accustomed, are changing. This work of mine will allow me to see how the devices that form a complete system will interact with the external environment, which in turn will give an idea of modern technologies that will change our future.;Smart city, Internet of Things, Smart home, Interface;en_US;Declined;0;2022;2022-06-22 16:50:18
125805;DrKarim   Hussein;Mustansiriyah University;a Detection and Recognition of Real-Time Hand Gestures Using Yolo and Alex Net Techniques: Real Time Hand Recognition ,YOLO and Alex Net;There are at least three thousand five hundred million people in the world who cannot hear or speak. These are what they are called deaf and dumb. Often this segment of society is partially isolated from the rest of society due to the difficulty of dealing, communicating and understanding between this segment and the rest of the healthy society. As a result of this problem, a number of solutions have been proposed that try to bridge this gap between this segment and the rest of society and as a result of the technical development of devices, especially computers and mobile phones. The science of image processing with artificial intelligence has been used to generate programs for converting natural speech into a sign language that enables people The handicapped (deaf and dumb) can understand it. Initially, a set of sign dictionaries were made in the deaf and dumb language, including the Indian Dictionary (ISL), the American Sign Language (ASL), the European Dictionary and so on, and the main reason for this is to simplify the understanding of sign language. These dictionaries depend mainly on the movement of hands, and one or both hands can be used in order to form special characters for this conversation. These dictionaries can be used after training for this segment of people. As a result of technological progress, this process can be automated using a computer and various programming languages ​​in addition to secondary connections (cameras and microphones) and advanced algorithms for artificial intelligence. This goal can be reached by building a special program for communication between people with disabilities (deaf and dumb) and healthy people, or both directions. The results obtained from the research show that the use of neural networks, especially convolutional neural networks, is very suitable in terms of accuracy, speed of performance and generality in processing the previously unused input data.;deaf and dumb, Indian Sign Language, American Sign Language, Hand gesture, artificial intelligence, Hand detection, Convolution Neural Networks.;en_US;Declined;0;2022;2022-07-10 11:08:32
125807;DrKarim   Hussein;Mustansiriyah University;An Audio Reading System for Blind Persons, Testing and Evaluation: Mobile Reading System for Blind persons;Audio Reading System is used to help blind persons to read the text based on camera as input device and speaker as output device. This paper is aims to test and evaluation the audio reading system with new dataset which consist of 161 image, 8 font size, mono and color image, and different views. The system is test and discussion from the aspects: accurate, Font size and type, and more reliable. According to the results (on our dataset (image type, 161 images)), the characteristics of the system is efficient and accurate real time system with cloud computing and the accuracy increase while the font size increase, whereas the accuracy of font size 30 is 100% and of 12 is 80%. Conclusion , mostly approved the successful adaptive of the system with size and color of fonts , adaptive with position of page , good accuracy , real time aspect and successful implementing of dataset and computational processing in the cloud rather than in the mobile device.;Audio Reading System, Blind Person, Mobile Cloud, Test System.;en_US;Declined;0;2022;2022-07-10 11:18:01
126065;Phillippy   Cardelly Albuquerque dos Santos;;Descoberta de conhecimento em base de dados de acidentes automobilísticos: identificação de pontos críticos e fatores que ocasionam acidentes fatais no estado do Maranhão;According to data from the Ministry of Justice and Public Security (MJSP), from 2017 to 2020, more than 289 thousand accidents on highways were recorded in Brazil by the Federal Highway Police. There are several causes that can lead to accidents, which makes it difficult to plan successful strategies for their mitigation. In view of this, this work presents the main causes that lead to accidents and the highways where most accidents occur in the state of Maranhão. For this, the dataset obtained from the MJSP website and the Explainable Artificial Intelligence technique using networks, the Filltradas Association Rule Networks, were used. Data were analyzed to discover which highway is the most dangerous in the state of Maranhão, as well as discovering knowledge of the main factors that generate fatal car accidents. The research brought innovation with the results as it enabled the discovery of situations that caused accidents on the roads, as well as the analysis of the impact that the COVID-19 pandemic had on the number of incidents of this nature.;Car Accidents, Data Mining, Knowledge Discovery in Databases, Filtered Association Rule Networks;en_US;Declined;0;2022;2022-07-22 18:51:40
126128;Ciro   Alexandre Olivieri Filho;;Mixture of experts using Convolutional Neural Networks applied to biometric recognition based on dorsal hand veins: A comparative study;In recent years, the research area known as deep learning, in particular, Convolutional Neural Network (CNNs), has gained importance and obtained relevant results in different areas of pattern recognition. However, there are some challenges to be overcome involving the use of CNNs, such as structural and parametric design aspects that can lead to a degradation of their performance. In this context, the Committee Machine, particularly the Mixture of experts using CNNs, presents itself as a promising alternative. On the other hand, the use of transfer learning can improve the performance of traditional classifiers using feature vectors extracted from CNNs. This paper investigates the use of different CNN architectures, the mixture of experts, and traditional machine learning techniques applied to biometric recognition based on dorsal hand veins. Jilin University database was used, which has images of the dorsal hand vein without and with partial occlusion via pigmentation or tattoo, and the database of Dr. Badawi.;;en_US;Declined;0;2022;2022-07-25 22:57:42
126129;Ciro Alexandre Olivieri   Filho;;Mixture of experts using Convolutional Neural Networks applied to biometric recognition based on dorsal hand veins: A comparative study;In recent years, the research area known as deep learning, in particular, Convolutional Neural Network (CNNs), has gained importance and obtained relevant results in different areas of pattern recognition. However, there are some challenges to be overcome involving the use of CNNs, such as structural and parametric design aspects that can lead to a degradation of their performance. In this context, the Committee Machine, particularly the Mixture of experts using CNNs, presents itself as a promising alternative. On the other hand, the use of transfer learning can improve the performance of traditional classifiers using feature vectors extracted from CNNs. This paper investigates the use of different CNN architectures, the mixture of experts, and traditional machine learning techniques applied to biometric recognition based on dorsal hand veins. Jilin University database was used, which has images of the dorsal hand vein without and with partial occlusion via pigmentation or tattoo, and the database of Dr. Badawi.;;en_US;Declined;0;2022;2022-07-25 23:19:34
126130;Alex Cecconi   de Souza;;Generative Adversarial Networks for artificial generation of motor imagery electroencephalogram signals;Electroencephalography (EEG) is one of the most used methods to capture the electrical signal from the brain in a non-invasive way, representing a modality of neuroimaging. Among its applications are diagnoses of diseases such as epilepsy, seizures, sleep disorders, stroke and other brain disorders. Another application category is the brain-computer interface (BCI) that detects neurocognitive processes using EEG signals generated by motor imagery. However, the EEG signal capture apparatus is expensive and the cost increases significantly with the increase in the number of channels. A feasible solution would be to use synthetic channels designed by generative models. With this background, this work aims to investigate the use of Generative Adversarial Networks for synthetic generation of EEG signals from motor imagery applied to the brain-computer interface.;;en_US;Declined;0;2022;2022-07-26 0:04:25
126131;Alex Cecconi   de Souza;;Generative Adversarial Network for artificial generation of motor imagery electroencephalogram signals: Generative Adversarial Network for artificial generation of motor imagery electroencephalogram signals;Electroencephalography (EEG) is one of the most used methods to capture the electrical signal from the brain in a non-invasive way, representing a modality of neuroimaging. Among its applications are diagnoses of diseases such as epilepsy, seizures, sleep disorders, stroke and other brain disorders. Another application category is the brain-computer interface (BCI) that detects neurocognitive processes using EEG signals generated by motor imagery. However, the EEG signal capture apparatus is expensive and the cost increases significantly with the increase in the number of channels. A feasible solution would be to use synthetic channels designed by generative models. With this background, this work aims to investigate the use of Generative Adversarial Networks for synthetic generation of EEG signals from motor imagery applied to the brain-computer interface.;;en_US;Declined;0;2022;2022-07-26 0:40:58
126132;Alex Cecconi   de Souza;;Generative Adversarial Networks for artificial generation of motor imagery electroencephalogram signals;Electroencephalography (EEG) is one of the most used methods to capture the electrical signal from the brain in a non-invasive way, representing a modality of neuroimaging. Among its applications are diagnoses of diseases such as epilepsy, seizures, sleep disorders, stroke and other brain disorders. Another application category is the brain-computer interface (BCI) that detects neurocognitive processes using EEG signals generated by motor imagery. However, the EEG signal capture apparatus is expensive and the cost increases significantly with the increase in the number of channels. A feasible solution would be to use synthetic channels designed by generative models. With this background, this work aims to investigate the use of Generative Adversarial Networks for synthetic generation of EEG signals from motor imagery applied to the brain-computer interface.;;en_US;Declined;0;2022;2022-07-26 0:44:25
127301;Moisés   Miranda;IFCE;The DESENVOLVIMENTO DE UM SISTEMA FUZZY PARA SELEÇÃO DE PERFIL TÉCNICO NA ÁREA DE TECNOLOGIA DA INFORMAÇÃO.;The selection process of information technology professionals to work on the development of a software is based on the evaluation of a set of technical and personal skills of each candidate. In addition to these skills, each candidate must fit a professional profileto compose the software development team. Choosing the professional that best fits aspecific position is an arduous task, as the professionals responsible for the selectionoften do not know in depth the best skills for each profile. In this sense, this work aimsto develop a computational model using the Python language and the Scikit-Fuzzylibrary that can efficiently select a professional for a given position within a softwaredevelopment team, seeking to find the balance among skills the candidate and therequirements of the available place. The computational tool will be modeled from aFuzzy Inference System to make the coherence between the most adequate skills for agiven function and which candidate’s skills best fit the requested requirements.;Fuzzy Inference System, Hardskills, Softskills, Personnel Selection;en_US;Declined;0;2022;2022-09-19 22:38:10
127397;Nancy   Zreika;Beirut Arab University;A Robust and parallel segmentation model (RPSM) for early detection of skin cancer disease using heterogeneous distributions;Melanoma is the most common dangerous type of skin cancer however, it is preventable if it is diagnosed early. Diagnosis of Melanoma would be improved if an accurate skin image segmentation model is available. Many computer vision methods have been investigated, yet the problem of finding a consistent and robust model that extracts the best threshold value, persists. This paper suggests a novel image segmentation approach using a multilevel cross entropy thresholding algorithm based on heterogeneous distributions. The proposed strategy searches the problem space by segmenting the image into several levels, and applying for each level one of the three benchmark distributions, including Gaussian, Lognormal or Gamma, which are combined to estimate the best thresholds that optimally extract the segmented regions. The classical technique of Minimum Cross Entropy Thresholding (MCET) is considered as the objective function for the applied method. Furthermore, a parallel processing algorithm is suggested to minimize the computational time of the proposed segmentation model in order to boost its performance. The efficiency of the proposed RPSM model is evaluated based on two datasets for skin cancer images: The International Skin Imaging Collaboration (ISIC) and Planet Hunters 2 (PH2). In conclusion, the proposed RPSM model shows a significant reduced processing time and reveals better accuracy and stable results, compared to other segmentation models.Design/methodology – The proposed model estimates two optimum threshold values that lead to extract optimally three segmented regions by combining the three benchmark statistical distributions: Gamma, Gaussian and lognormal.Outcomes – Based on the experimental results, the suggested segmentation methodology using MCET, could be nominated as a robust, precise and extremely reliable model with high efficiency. Novelty/utility –A novel multilevel segmentation model is developed using MCET technique and based on a combination of three statistical distributions: Gamma, Gaussian, and Lognormal. Moreover, this model is boosted by a parallelized method to reduce the processing time of the segmentation. Therefore, the suggested model should be considered as a precious mechanism in skin cancer disease detection.;Heterogeneous distributions, Minimum Cross Entropy Thresholding, Parallel processing, Skin Cancer images.;en_US;Declined;0;2022;2022-09-25 15:38:07
127532;Islame Felipe   da Costa Fenrnandes;Universidade Federal da Bahia;The A Multi-agent Transgenetic Algorithm for the Bi-objective Spanning Tree Problem;Transgenetic algorithms are evolutionary techniques successfully applied to several problems. Similar to other evolutionary algorithms, they have various parameters that influence their behaviors. Previous researches have presented arguments that a static set of parameters may be inappropriate. This study proposes a transgenetic algorithm that automatically decides about the search mechanisms used along with its execution. It also reports an application of the algorithm proposed to the Bi-objective Spanning Tree (BiST), an NP-hard extension of the Minimum Spanning Tree problem. The BiST models situations where one needs to optimize two conflicting objectives simultaneously. Computational experiments carried on 180 benchmark instances showed that the algorithm proposed in this study produces good approximation sets concerning different quality indicators.;Transgenetic Algorithm, Bi-objective Spanning Tree, Evolutionary Algorithm;en_US;Declined;0;2022;2022-09-30 14:57:32
128167;Wesley   R. Bezerra;UFSC - Federal University of Santa Catarina;A Bibliometrics Analysis on 28 years of Authentication and Threat Model Area;The large volume of publications in any research area can make it difficult for researchers to track their research areas' trends, challenges, and characteristics. Bibliometrics solves this problem by bringing statistical tools to help the analysis of selected publications from an online database. Although there are different works in security, our study aims to fill the bibliometric gap in the authentication and threat model area. As a result, a description of the dataset obtained, an overview of some selected variables, and an analysis of the ten most cited articles in this selected dataset is presented, which brings together publications from the last 28 years in these areas combined.;;en_US;Declined;0;2022;2022-10-28 18:33:36
128584;Dmitry   Prikhodko;Scientific Research Institute for System Analysis of the Russian Academy of Sciences;CLASSIFICATION OF THE CONCEPT OF OPERATION  AND MODELS OF OPERATIONAL CYCLES OF INFORMATION  SYSTEMS WITHIN THE FRAMEWORK OF LIFE CYCLE THEORY;The article considers the operation concept of in engineering systems, in relation to modern information systems. An additional specification of this concept was carried out, which makes it possible to significantly expand the views known to date. Classical models of life cycles of information systems are considered taking into account the modern content of the technical operation concept. We suggest an approach to technical operation from perspective of introduction a methodology of business accounting of an enterprise. In particular, the specific situations are detailed. Extended versions of life cycles of information systems are considered. For example, we conduct expanded research of the situation of storing an information system at the manufacturer's factory, or a situation where the product is registered to the enterprise, but is under repair or stored as an outdated model for parts or for temporary replacement in case the main product breaks down. A particular plotting of the stage of the life cycle of information systems was carried out in terms of a single copy and serial production of information system models. A special type of operation is also considered, which researchers generally do not pay attention to – the operation of an extreme sample, which is not explicitly known to modern users of technical products, while for users of modern information systems this type of technical operation is absolutely standard in view of the prevalence. For example, Google and Microsoft are actively offering modern users to take part in testing, or "experimental operation" of information systems in a simplified form for free, in return giving users some preferences. The purpose of the article is to analyze and improve the concept of operation in classical life cycle models.;;en_US;Declined;0;2022;2022-11-20 10:07:48
129296;Matheus Raffael   Simon;UNIOESTE;EVALUATION OF THE RELATIONSHIP BETWEEN THE AGE OF THE PATIENT AND THE MANDIBULAR TRABECULAR BONE STRUCTURE THROUGH DENTAL CONE BEAM TOMOGRAPHIC IMAGES BY MEANS OF A CONVOLUTIONAL NEURAL NETWORK;Osteoporosis is a systemic condition, which affects the bone mineral density in individuals, making the insertion of dental implants difficult. It mainly affects women, and it can be diagnosed by means of a DXA scan (dual-energy X-ray absorptiometry). However, a DXA scan is not easily accessible by a large portion of the Brazilian population. The Jaw System Age Group X software, which was developed in this research, aims to bring patients closer to an assessment of the trabecular bone structure of their mandibles the software will not diagnose osteoporosis, it will in fact provide the dentist with data so they can refer the patient to a doctor who will, eventually, request a DXA scan, thus optimizing the use of equipment from the Unified Health System (SUS). The end user – usually a dentist – manipulates cone beam tomographic images by selecting slices, in the coronal plane, from the region of the body of the mandible of the patients. The trabecular structure of this region of the jaw is segmented and classified by means of a convolutional neural network into age groups, taking the gender of the patient into consideration. The research made use of 137 cone beam CT scans, from which 1389 samples of mandibles from female patients and 633 from male patients were selectedto train the neural network, which is composed of 3 dense layers with 100 neurons each and ReLU activation function, with weights update by the Adam algorithm, using MaxPooling in each convolution for image classification, it uses a dense layer with 100 neurons, with softmax activation function to classify the samples into the possible classes. The training accuracy of the neural network was 98% for males and 94% for females, with area under the ROC curve (AUC) equal to 0.94 and 0.81 for the respective genders. The accuracy obtained in the CNN validation was 98% for males and 89% for females. Finally, a supervised test was performed, using 5 slices from 10 scans of the test set for each gender taking the average result into consideration, approximately 100% accuracy was obtained for both genders. Thus, this research has concluded that the proposed model can classify the samples into the proposed age groups, and it has been proved to be robust and solid in the tests. Therefore, this tool can be an alternative and low-cost instrument to assist healthcare professionals in the analysis of bone density, once it can be used as a filtering element for patients to be submitted to diagnostic tests, such as the DXA.;Imaging processing, convolutional neural network, trabecular bone structure, mandible, cone beam tomography, osteoporosis;en_US;Declined;0;2023;2023-01-06 14:35:06
130067;ahmed   ;Egyptian Space Agency;KNEE OSTEOARTHRITIS AUTOMATIC DETECTION USING U-NET;Knee osteoarthritis is one of the most common diseases that can affect the elderly and overweight people. According to Kellgren-Lawrence, knee osteoarthritis is divided into five classes one class represents a normal knee and the others represent four levels of knee osteoarthritis. In this work, we aim to automatically detect knee OA according to the Kellgren-Lawrence classification. The proposed system uses the U-Net architecture. The overall system yielded an accuracy of 96.3% during training.;;en_US;Declined;0;2023;2023-02-08 18:49:13
130078;Bruno   Da Rocha Braga;Federal Institute of Education, Science and Technology of Brasília;Classification Analysis of Social Processes: Algorithms for Implementing an Inductive, Comparative Method based on Formal Language Theory;This work proposes a method for the analysis of a category of social process based on a representative set of sequences of outcomes of decision-making events. The goal is to describe the evolutionary path of a phenomenon in its empirical setting, but in a way that structural comparisons are possible. Firstly, it presents a kind of classification task on types of events using the Quine-McCluskey algorithm, relying on Set Theory. Next, it proposes a new classification task on sequences of event outcomes using the Nevill-Manning algorithm, relying on Formal Language Theory. In the practice of research, both differ from the classification algorithms based on Information Theory and Probability Theory because of the assumptions about the nature of the phenomenon under studying in addition to the underlying mathematics used.;Classification Analysis, Configuration Analysis, Qualitative Comparative Analysis, Categorical-Generative Analysis, Process Tracing, Sequence Analysis;en_US;Declined;0;2023;2023-02-09 12:17:28
130259;Tanzilya   Burganova;Kazan State Power Engineering University;METHOD OF TWO-FACTOR AUTHENTICATION OF ELECTRONIC DOCUMENTS USING ENHANCED ENCRYPTED NON-CERTIFIED DIGITAL SIGNATURE WITH THE USE OF SECURITY TOKEN WITH BIOMETRIC DATA;The purpose of this study is to develop a method for two-factor authentication of electronic documents using an enhanced encrypted non-certified digital signature with the use of a security token with biometric data (fingerprint image). In order to achieve the goal, the method of comparative analysis was used. Existing algorithms for the electronic signature operation were studied. The method of multi-factor authentication of an electronic signature using biometric data has been studied in detail. Biometric data included: a handwritten password, an autograph, an image of a keyboard rhythm when typing a pass phrase, a facial image, an image of a keyboard rhythm when typing a free text. An external storage medium with a biometric authentication method based on a fingerprint image was also studied. Information on this media was accessed by scanning a fingerprint image. After conducting a comparative analysis and studying in detail these methods, a method for two-factor authentication of an electronic signature using a security token with biometric data was developed. The operation algorithm was as follows. Primary authentication is carried out by scanning the fingerprint image using a sensor embedded in the electronic signature token. Next, the system identifies the user and opens access to the electronic signature. Secondary authentication is performed using a password. After entering the password, an electronic signature is created and electronic documents are signed with it. This method of two-factor authentication of an electronic signature using biometric data can be used when signing documents in the internal electronic document management.;;en_US;Declined;0;2023;2023-02-17 9:06:28
130474;Anthony   Cruz;IFSC;Using Deep Learning for Blood Cells Detection;The complete blood count is one of the most important and most performed exams in the medical field. Through it, it is possible to discover important alterations in the organism and it is generally used as a first step in the assessment of patients health. Although it is a common practice, the performance of exams is difficult in laboratories because of the high cost of purchase and maintenance machinery. As an alternative to that, this project develops a computational model of Deep Learning capable of detecting cells automatically through images of blood samples. Through the use of object detection libraries, it was possible to train a model aimed at this problem and capable of detecting cells in images with satisfactory precision. Considering the identification of cells in images of blood samples in the best results obtained, it was possible to count white cells with 100% accuracy, red cells with 89% and platelets with 96%, generating subsidies to elaborate the main parts of a blood count. The elements aimed at classifying different types of white cells were not carried out due to the limitations of the dataset used. However, as it showed good results, the research can be expanded to future works that address this problem.;Complete Blood Count, Blood Test, Deep Learning, Neural Networks;en_US;Declined;0;2023;2023-02-28 16:31:50
130475;Gilberto   Perello Ricci Neto;Universidade Federal de Santa Catarina;Horizontal Cloud Image Dataset Build-up for Solar Energy Nowcasting Based on Deep Learning;Renewable energy is heavily affected by local weather conditions. Clouds cause a major impact especially in solar energy short-term forecasting. The present work focuses on build a machine learning dataset for cloud image identification at the Florianopolis/SC (Brazil) site. We used cameras pointed at the horizon in order to allow observation of the clouds’ vertical distribution. We presented a large number of images to be used on deep learning methods, such as U-net, HRnet and Detectron.;Image Segmentation, Deep Learning, Nowcasting, Photovoltaic Energy;en_US;Declined;0;2023;2023-02-28 20:06:25
130623;Carlos Eduardo   Egito Araujo;+5562993076541;Use of wearable chemical sensors in IoT: a systematic literature review;Health applications received more attention with the use of Internet of Things - IoT, due to the use of sensors for remote monitoring, not only in hospital environments, but also in domestic environments and in meditative and routine activities. Wearable chemical sensors have been proposed in the health area for the continuous monitoring of the individual's well-being, however, the challenges related to the convergence of these two areas still require a lot of research for the solutions to be effectively applied. The aim of this article is to present the results of a systematic literature review (SLR) carried out with the purpose of highlighting applications that employ the use of wearable chemical sensors in IoT contexts. The results found present several challenges and open questions of a promising research field involving IoT and wearable chemical sensors. The review was performed on the same bases used to make the original SLR, in which the period from December 2021 to February 2023 was adopted as an interval. As a result, in addition to the 15 (fifteen) studies found in the previous SLR, 7 (seven) new articles were classified as relevant, totaling 22 (twenty-two) studies. Regarding the previous.;bluetooth, chemical sensors, electrochemical sensors, wireless;en_US;Declined;0;2023;2023-03-06 20:07:23
130667;Mariana   Santos;Universidade Federal de Goiás;Machine Learning Algorithms for Peripheral Blood Cell Classification - A Hemovision Project Experience;This research explores the use of machine learning algorithms to classify nucleated peripheral blood cells. The ResNet18 convolutional neural network was used to pre-process the images and replace the dense layers and for the output, the Support Vector Machine (SVM) classifier was chosen. Images from different datasets were used for training and testing the model. Thus, the developed model achieved an accuracy and F1-Score of 99.96\%. In face of the obtained results, it was found that machine learning algorithms can be satisfactorily integrated into educational and diagnostic support processes;;en_US;Declined;0;2023;2023-03-06 23:45:07
131521;R. Anusha   Padmavathi;Assistant Professor, Department of Electronics and Communication Engineering, Government College of Engineering, Thirunelveli, Tamil Nadu, India.;A Comprehensive Review of Steganography based Data Security System;The recent information and technology developments have impacted data utilization and showed the importance of storing different data types for various purposes. The huge amount of data exchanged between systems through the web, networks, and data storage systems are prone to third-party attacks and demand an effective data-security system irrespective of the application. Researchers and developers have secured data using different steganography and cryptography techniques. Steganography uses different mediums to hide sensitive data such as images, videos, text, and audio. This review study discussed the importance of recent trends in steganography and cryptography systems in data security. This paper aims to review different techniques practiced in steganography secure systems, they are primarily used among developers and researchers in data security. Overall, developing an efficient security system based on steganography should be resilient to different types of third-party attacks and consider data integrity and data confidentiality to prevent loss of information.;;en_US;Declined;0;2023;2023-04-03 7:36:24
131873;Sandra   Meza;Universidad Cientifica del Sur;Dra. Propuesta de un modelo de gestión por procesos (BPM) para el área comercial en una empresa de servicios funerarios, Lima 2022;The objective of the following research work is to present a proposal for a process management model (BPM) for the commercial area in a Process Management funeral services company using the Business Process Management notation for the Commercial Area of ​​the company. Campo Fe. This proposal seeks to be viable and generate savings in the costs of key activities for the company. The proposal of the Process Management model aims to reduce execution times, bottlenecks and reprocessing of activities. To achieve this, a redesign of processes based on metrics and indicators is proposed to optimize the activities carried out by the commercial area. Finally, the effectiveness of the proposal was evaluated, achieving time savings in the execution of activities for the following processes: For the customer prospecting process, an optimization of 85%, for the contract generation process in future need, an optimization of 79% and for the contract generation process in immediate need, an optimization of 71%. The effectiveness of the proposal was also evaluated, achieving cost savings in the execution of activities for the following processes: For the process of generating contracts in future need, a saving of 25.94 soles per contract generated and for the process of generating contracts in immediate need, a saving of 35.17 soles per contract generated. In addition to this, the effectiveness of the proposal was evaluated, achieving a decrease in complaints per sales contract generated by 45.5% with respect to the current situation of the company.;Process management, Commercial management, Process improvement.;en_US;Declined;0;2023;2023-04-18 0:12:30
132024;Pedro   Lucas;Herbeth;Autonomous Drone Landing with Computer Vision;This article presents an autonomous drone landing system using computer vision and a specific landing signal. The system uses image processing techniques to identify the landing signal and calculate the drone's flight path in relation to the signal. A descent controller is implemented to adjust the drone's altitude and position in real-time during landing. Tests were performed under different environmental and lighting conditions, demonstrating the accuracy and efficiency of the system.;;en_US;Declined;0;2023;2023-04-25 15:40:48
132053;Bhagyashree   Talikoti;PES UNIVERSITY;DETECTION OF ADULTERATION IN FRUITS: DETECTION OF  ADULTERATION IN FRUITS;The main of this project is to detect formalin content in thefruit using the CNN which stands for Convolution NeuralNetwork. Formalin is a chemical preservative that iscommonly used to extend the shelf life of fruits, but it can alsobe harmful to human health if consumed in large amounts.This chemical is widely used in the preservation of fruits, andits use is a concern for food safety. The proposed method uses aCNN to analyze images of fruits and predict whether or not thefruit contains formalin. This model is able to find the formalincontent in fruits by analyzing the features such as area, colorequalization, and edge detection. The goal is to find theformalin content in fruits by using this model, thus ensuringthe safety of the food consumed by the people. The success ofCNNs in image classification tasks and their widespreadapplication in a range of tasks, such as object recognition andface recognition in images, are the driving forces for theiremployment in this research. By using this method, we aim toprovide a solution that can help ensure the safety of foodproducts and also ensure compliance with regulationsregarding the use of formalin in food production.;;en_US;Declined;0;2023;2023-04-26 12:03:51
132289;Chetan P Hattoor   ;PES University;Document Verification API;The document verification API is a tool that streamlines and automates the process of verifying student documents. It provides a centralized and secure storage system for universities to upload, delete, and update student documents, and enables companies to quickly and accurately verify the authenticity of these documents. By eliminating the need for manual verification and reducing errors, the document verification API saves time and hassle for both universities and companies.This project is designed to provide an efficient and secure way for universities and companies to verify student documents. By providing a centralized and secure storage system, the API ensures that student data is handled responsibly and that universities have control over which student data is made available to companies.;;en_US;Declined;0;2023;2023-05-04 4:45:50
132348;Jose Carlos   Metrôlho;R&D Unit in Digital Services Applications and Content, IPCB;Underage Citizens Monitoring Applications: A Review of The State of the Art and Guidelines for Future Implementations;The protection of children is a constant concern, whether from parents or the institutions they attend, and therefore it is important that there is constant monitoring and awareness. The aim of this project is to create an application to manage, plan and monitor the daily life of children. The aim is to keep parents up to date on where their children are and whether there is anything to worry about. In this context, a state-of-the-art analysis was carried out to identify the functionalities currently available to users of applications for this purpose. Essential features were identified through it, such as real-time location on the map, location history, marking safe areas and sending alerts. On the other hand, technological advances in several areas create space and opportunity to add value to what already exists and contribute to responding to existing problems. Therefore, in this article, in addition to the aforementioned state of the art, proposals for implementation lines for new mobile applications that may be developed in the future are also presented. The contributions of this article are, on the one hand, to present what currently exists in terms of mobile applications to support the monitoring of minors and, on the other hand, to propose lines of new functionalities that current technology can provide in new applications.;;en_US;Declined;0;2023;2023-05-08 8:30:24
132466;Mohanad   ;Al-hikma University;Wanderer Robot;Abstract ;;en_US;Declined;0;2023;2023-05-13 5:21:17
132467;Mohanad   ;Al-hikma University;Line Following robot;Abstract ;;en_US;Declined;0;2023;2023-05-13 5:27:19
132640;Mariana   Santos;Universidade Federal de Goiás;Machine Learning Algorithms for Peripheral Blood Cell Classification - A Hemovision Project Experience;This research explores the use of machine learning algorithms to classify nucleated peripheral bloodcells. The ResNet18 convolutional neural network was used to pre-process the images and replace the denselayers and for the output, the Support Vector Machine (SVM) classifier was chosen. Images from differentdatasets were used for training and testing the model. Thus, the developed model achieved an accuracy andF1-Score of 99.96%. In face of the obtained results, it was found that machine learning algorithms can besatisfactorily integrated into educational and diagnostic support processes.;;en_US;Declined;0;2023;2023-05-21 0:10:17
132675;Anusree   T K;TKM College Of Engineering, Kollam, Kerala, India;A Comparative Study of Paraphrasing Using Combination of CNN-LSTM And Transformer-based model for Detecting Plagiarism;Plagiarism is the act of using or presenting someone else's work, ideas, or words as your own without giving proper credit or acknowledgment to the source. It is considered a serious academic and ethical offense in most settings, including academia, journalism, and creative industries. The procedure of human-based plagiarism detection is time-consuming, inaccurate, and difficult. This paper proposes a plagiarismdetection based on two deep learning models: A combination of Long Short-Term Memory (LSTM) andConvolutional Neural Network (CNN), and a Transformer-based model. In terms of outcomes, research has demonstrated that deep learning models can accurately identify plagiarism. One study, for instance, employed a combination of the CNN-LSTM model to detect plagiarism and had a 99.51% success rate. Another study, for instance, employed a transformer-based model to detect plagiarism and had a high accuracy rate such as 99.61%.;Plagiarism detection plagiarism detection tools deep learning Long Short-Term  Memory (LSTM) Convolutional Neural Network (CNN) & Transformer based model, paraphrasing;en_US;Declined;0;2023;2023-05-23 4:49:55
133129;Mohanad   ;Al-hikma University;Moving object;Abstract ;;en_US;Declined;0;2023;2023-06-11 8:20:12
133169;Diones   Silva Rodrigues;UNEMAT - Universidade do Estado de Mato Grosso;Performance Analysis of Ethernet Networks Through Quality of Service (QoS) Metrics Using Real and Virtual Machines: Analise De Desempenho De Redes Ethernet Através De Métricas De Quality of Service ´(Qos) Utilizando Maquinas Reais e Virtuais;The Quality of Service (QoS) comprises technologies used in computer networks to ensure reliable application performance. This work aims to analyze the performance of a controlled network with real and virtual machine traffic sources, including testing on a public server to simulate a real QoS scenario. Iperf3 with the UDP protocol will generate the traffic. Test results will be compared through graphs to profile network usage, distinguishing services that require high throughput from those with minimal latency needs. The QoS metrics employed in this research encompass throughput, end-to-end latency, jitter, and packet loss rate. Results emphasize the importance of minimizing packet loss for efficient communication, particularly in packet loss-sensitive services like email delivery and file transfer. Environment 2 demonstrated significantly better performance in terms of packet loss rate, indicating high data transmission reliability. This study introduces the concept of QoS and conducts an experiment comparing QoS between virtual and real machines. A notable contribution is highlighting that QoS is not only a technology but also a means of evaluating network quality and reliability, with emphasis on metrics and the use of the Iperf3 tool for generating analyzable results.;;en_US;Declined;0;2023;2023-06-12 21:09:05
133172;Jorge   Guerra Pires;JovemPesquisador.com;SnakeFace: a transfer learning based app for snake classification;Introduction: deep learning emerged in 2012 as one of the most important machine learning technologies, reducing image identification error from 25\% to 5\%. This article has two goals: 1) to demonstrate to the general public the ease of building state-of-the-art machine learning models without coding expertise 2) to present a basic model adaptable to any biological image identification, such as species identification. Method: We present three test concept models that showcase distinct perspectives of the app. The models aim at separating images into classes such as genus, species, and subspecies, and the input image can be easily adapted for different cases. We have applied deep learning and transfer learning using Teachable Machine. Results: Our basic models demonstrate high accuracy in identifying different species based on images, highlighting the potential for this method to be applied in biology. Discussions: the presented models showcase the ease of using machine learning nowadays for image identification. Furthermore, the adaptability of this method to various species and genuses emphasizes its importance in the biological fields, as root for inspiring collaborations with computer science. Future collaborations could lead to increasingly accurate and efficient models in this arena using well-curated datasets.;Bioinformática, tensorflow, JavaScript, snakes, biology, Deep Learning, transfer learning;en_US;Declined;0;2023;2023-06-13 7:34:22
133204;Enzo   Crivellaro;PUCSP;Exploring the potential of Artificial Intelligence in creating Art based on Deep Learning;There has been a increasing adoption of Artificial Intelligence (AI) by the general public, especiallydue to the availability of advanced templates such as ChatGPT and DALL-E 2 which are capable of generatingstunning text and images. These technologies have aroused interest in several areas, including advertising andfilm production. However, controversies have arisen regarding the role of AI in art, raising questions about artistsubstitution and the lack of creativity of machines. Despite this, AI has the potential to assist artists in composingimages, identifying patterns and trends, and improving artistic efficiency and quality. The integration of AI withhuman creativity can break new ground and enable innovative forms of artistic expression. This article exploresthe use of Generative Adversary Networks (GANs) and the Pix2Pix model in the field of art, presenting thedevelopment of an AI network for sketch-based rendering of three-dimensional images. The study seeks toidentify effective methodologies and analyze the practical applications of this model.;Deep Learning, GAN, Pix2Pix, Artificial Neural Network, Art;en_US;Declined;0;2023;2023-06-14 1:30:11
133262;Geetanjali   Sawant;Mumbai;Age-Adaptive Multimodal Biometric Authentication System with Blockchain-based Re-enrollment;In the long run, a significant time gap between enrollment and probe image challenges the model's prediction ability when it has been trained on variant biometric traits. Since variant biometric traits change over time, it is sensible to construct a multimodal biometric authentication system that must include at least one invariant trait, such as the iris. The emergence of Deep learning has enabled developers to build classifiers on synthesized age-progressive images, particularly face images, to search for individuals who have been missing for many years, to avail a comprehensive portrayal of their appearance. However, in sensitive areas such as the military and banks, where security and confidentiality are of utmost importance, models should be built using real samples, and any variations in biometric traits should trigger an alert for the system and notify the subject about re-enrollment. This paper proposes an algorithm for age adaptation of biometric classifiers using multimodal channels which securely update the biometric traits while logging the transactions on the blockchain. It emphasizes confidence-score-based re-enrolment of individual subjects when the authenticator module becomes less effective with a particular subject's probe image. This reduces the time, cost, and memory involved in periodic re-enrolment of all subjects. The classifier deployed on the blockchain invokes appropriate smart contracts and completes this process securely.;Variant/Invariant Biometric trait, Confidence-score, smart contract, Blockchain;en_US;Declined;0;2023;2023-06-16 13:10:37
133622;Liannett   Conde;Servicio Nacional de Aprendizaje - SENA;Diseño de un sistema de monitorización de signos vitales en pacientes críticos con atención domiciliaria;A remote monitoring system for critical patients ventilated with home care has been designed and developed using free software and hardware technologies so that these patients can have medical care 24 hours a day, because currently in this type of care the doctor only makes visits. occasional visits to the patient to measure the patient's vital signs. That is why this research was developed, which will allow the modernization and improvement of the medical processes carried out in the so-called “Home Care”, since the use of hardware and free software platforms means that the economic investment is minimal. and Feasible at the time of the development of the research. To carry out the development of the research, the following objectives were set: design and develop a system for remote monitoring of vital signs in critically ventilated patients with home care, using hardware and Free software technologies. Determine the appropriate free hardware and software technologies for monitoring vital signs in chronic patients. Develop the Web application according to the identification of functional requirements and system modeling and validate the remote vital signs motorization system through a functional prototype. The research methodology was divided into four phases called analysis, design, development and validation, from which the results were the analysis and identification of the system requirements, the design of the diagrams required for the development of the Software,;;en_US;Declined;0;2023;2023-06-30 17:28:35
133801;Luis   Barata;Instituto Politécnico de Castelo Branco;Predictive Maintenance based on Log Analysis: A Systematic Review;In today’s industries, the Maintenance process of machines and assets implies a significant part of thetotal operating cost. Many efforts have been made to reduce this cost by optimizing the process and evolvingmethods that allow information collection on equipment status, avoiding redundant interventions, and predictingthe exact moment to perform a maintenance intervention. Using “intelligent” systems that collect data from theoperation and remote management systems allows us to gather all the data and apply some methodologiescapable of identifying expected behaviors based on past operations.We present a survey of technologies, techniques, and methodologies to give the knowledge background todevelop a framework to minimize the occurrence of failures and optimize the process of Predictive Maintenance(PdM) based on the analysis of Log files collected from the various industrial equipment. Generally, these logscontain many records, and many of these records do not directly contribute to evaluating the operation’s machinestatus.Most of the studies included in this survey use machine learning techniques and focus a significant part of theirresearch on data preprocessing, uniformization and clarification.;Predictive Maintenance, Log analysis, Log files, Predictive algorithms, Predictive Maintenance based on Log Analysis;en_US;Declined;0;2023;2023-07-08 12:00:55
133880;Pablo   Lolatto;UNOESC;O  Nas Ruas: Aplicativo para registros de locais públicos em situações precárias;The NAS RUAS application, an innovative system developed to record and create reports on public places in precarious situations. Aiming to promote citizenship and collaborative oversight, the app allows users to document and report problems encountered in public spaces, such as damaged infrastructure, lack of maintenance, security issues and other concerning situations. The application was developed in Flutter and offers an intuitive and user-friendly interface, allowing users to take photos, make notes and mark the exact location of identified problems. Additionally, the app offers the option to add a detailed description of the issue and provide additional relevant information.;Information Registration, Application, Collaborative Inspection.;en_US;Declined;0;2023;2023-07-11 11:56:26
134202;Bharti   Bisht;MRIIRS;Empirical Validation of Variable Method Interaction  Cohesion Metric (VMICM) for Enhancing Reusability of  Object-Oriented (O-O) Software;Any object-oriented (O-O) module's primary goal is to build classes with a high level of coherent interaction between variables and methods. To increase the quality of O-O (Object-Oriented) software, various metrics with an emphasis on cohesiveness have been established so far. These metrics operate on both the design and the code levels. However, these metrics still fall short of fully measuring the cohesion of object-oriented (O-O) software. Based on several concepts ofcohesive interlinkages between variables and procedures, the study proposed an enhanced cohesion metric. The four forms of cohesive linkages (VMRv, VMMv, VMRTv, and VMOv) between variables and procedures were the focus of this study. The axiomatic frame of reference was employed for theoretical validation, and univariate logistic regression was applied in the MATLAB environment for empirical validation. The approach of univariate logistic regression has been adopted because it provides incredibly accurate data and can even be applied to datasets that can be linearly separated. The proposedmetric exhibits high cohesion, which is the ultimate perspective of a highly reusable Object-Oriented (O-O) module, as evidenced by the testing phase and even training the real dataset with reusability prediction in terms of high values of precision, recall, R2, and low value of RSME of VMICM metric. The study results demonstrated that the proposed metric can act as a measure for predicting the reusability of the Object-Oriented (O-O) system;;en_US;Declined;0;2023;2023-07-25 7:55:03
134230;Mahesh Ashok Mahant   ;Koneru Lakshmaiah  Education Foundation;A Survey in Predictive Data Analytics Framework for Child and Pregnant Women Health Care Systems Based on Data Sources;Predictive data analytics is essential for enhancing the performance of medical facilities, notably in the field of baby & pregnant women's medical treatment. This survey intends to look into the various data sources utilized in frameworks for predictive data analytics for the healthcare systems for children and pregnant women. The survey begins by describing the value of predictive analytics in enhancing the results of children and pregnancy and then focuses on locating and classifying different data sources that contribute to the predictive analytics framework. It also provides an in-depth review of previous research projects and studies that have used these data sources in predictive analytics models for the health care systems for children and pregnant women. The survey concludes with a discussion of the existing trends and future directions in using various data sources for predictive data analytics in the care of children and pregnant women. To enable the efficient use of these data sources, it highlights the need for standardized data gathering and sharing practices, ethical considerations, and technological improvements in the use of electronic data.;;en_US;Declined;0;2023;2023-07-26 3:30:42
134402;Elena   Kokoreva;Siberian State University of Telecommunications and Information Science;5G INTERNET OF THINGS ANALYTICAL CHARACTERISTICS;The Smart City concept is especially relevant in the era of 5G technologies, since only the speeds provided by the IMT-2020 standard can provide the possibility of machine-to-machine interaction with instantaneous signal transmission and instantaneous response to it. At the heart of Smart Technologies is the joint use of infocommunication networks and the Internet of Things. An important task is to assess the quality of service and efficiency of the Internet of Things for home and production. In this paper the methodology of network time-probability characteristics analytical modeling using the mathematical apparatus of closed homogeneous Markov queueing networks, which has proved to be most suitable for modeling infocommunication systems of any dimension, complexity and purpose, is considered. The authors developed the conceptual, algorithmic and software models of the Smart Enterprise system and obtained the quality of service indicators’ values, which allow to evaluate the effectiveness of the studied system from the standpoint of a subscriber or developer. The results of the study can be applied in the planning of the smart systems based on the Internet of Things technology in the 5G network or in the existing systems’ improvement.;;en_US;Declined;0;2023;2023-07-29 10:27:08
134547;Bharti   Bisht;MRIIRS;Data Mining Techniques to Enhance Reusability of O-O (Object-Oriented) Systems: A Systematic Review;There was a need to reduce the effort and time spent throughout the process of developing software due to the quick evolution of the software industry. It is crucial to guarantee product quality while designing products and services to increase their market worth. Leveraging software reuse to achieve quality and productivity goals is advised. Reusability is a crucial measure that may be utilized to raise the overall level of software quality in lesser time and effort. Various data mining approaches used in this work provide insight into several literature studies on reusing O-O (Object-Oriented) software. Even a comparative analysis of several methods for improving the reusability of O-O (Object-Oriented) software systems has been conducted in this paper. It would also help to better understand the necessity of enhancing the reusability of O-O (Object-Oriented) systems using data mining approaches.;;en_US;Declined;0;2023;2023-08-04 4:19:12
134619;Alexander   Chesalin;MIREA – Russian Technological University;CASCADE CLASSIFICATION ALGORITHMS  FOR PROCESSING BIG DATA IN CYBERSECURITY;The problem of improving algorithms for big data processing in the field of cybersecurity based on the use of cascade classification algorithms is investigated. Modern anomaly detection systems process huge arrays of heterogeneous rapidly changing information, which requires huge computing power and optimized data processing algorithms. The purpose of the article is to show the possibilities of improving the efficiency of data processing systems in (pseudo) real time by using cascade algorithms that can be used on top of gradient boosting algorithms, neural networks and other algorithms. It is shown that the use of cascade algorithms in anomaly detection can significantly (more than twice) reduce the number of classifiers used to achieve a given accuracy. Recommendations on the use of cascading algorithms are also given, prospects and some difficulties of their use in real-time processing of big data in other areas are considered.;;en_US;Declined;0;2023;2023-08-08 8:56:45
135743;Alexander   Geyda;St. Petersburg Federal Research Center of the Russian Academy of Sciences;PROGRESS RELATED PURPOSEFUL CHANGES RESULTS  ESTIMATION WITH REGARD TO INFORMATION APPLICATION:  CONCEPT, MODELS AND DIRECTIONS FOR RESEARCH;It is shown in the article that multidisciplinary problem of progress related purposeful changes research with regard of information processing aspects of human’s activity exist. It is shown, that to solve the problem specified mathematical formalisms in the form of mathematical models of multi-level changes due to possible information obtained in possible changing conditions should be built. The reason why such models was not yet built is complex nature of multi-level changes and cause-and effect relationships which happens when information applied to systems functioning. The result of such modelling shall be the complex of functional dependencies between suggested quality measures (which describe changing functioning in changing conditions) and variables and parameters of the decided problems of progress related purposeful changes with regard of information processing aspects of human’s activity. To obtain such mathematical models of progress related purposeful changes with regard of information processing author suggested sequences of diagrammatic and formal models as well as (based on them) quantitative probabilistic measures. They can be used for measuring success information application for actions in systems. Deciding multidisciplinary problems, discovered by author as interrelated research directions, devoted to possible purposeful alternating of systems and their functioning under changing conditions, now possible. Such problems, described in the article, can be now researched based on models and methods suggested.;;en_US;Declined;0;2023;2023-09-24 16:01:30
